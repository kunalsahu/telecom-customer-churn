{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7f3214",
   "metadata": {
    "papermill": {
     "duration": 0.036252,
     "end_time": "2021-08-13T07:16:36.548737",
     "exception": false,
     "start_time": "2021-08-13T07:16:36.512485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Telecom Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9290ee78",
   "metadata": {
    "papermill": {
     "duration": 0.034552,
     "end_time": "2021-08-13T07:16:36.690028",
     "exception": false,
     "start_time": "2021-08-13T07:16:36.655476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 0. Problem statement\n",
    "\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "\n",
    "For many incumbent operators, retaining high profitable customers is the number one business\n",
    "goal. To reduce customer churn, telecom companies need to predict which customers are at high risk of churn. In this project, you will analyze customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn, and identify the main indicators of churn.\n",
    "\n",
    "In this competition, your goal is *to build a machine learning model that is able to predict churning customers based on the features provided for their usage.*\n",
    "\n",
    "**Customer behaviour during churn:**\n",
    "\n",
    "Customers usually do not decide to switch to another competitor instantly, but rather over a\n",
    "period of time (this is especially applicable to high-value customers). In churn prediction, we\n",
    "assume that there are three phases of customer lifecycle :\n",
    "\n",
    "1. <u>The ‘good’ phase:</u> In this phase, the customer is happy with the service and behaves as usual.\n",
    "\n",
    "2. <u>The ‘action’ phase:</u> The customer experience starts to sore in this phase, for e.g. he/she gets a compelling offer from a competitor, faces unjust charges, becomes unhappy with service quality etc. In this phase, the customer usually shows different behaviour than the ‘good’ months. It is crucial to identify high-churn-risk customers in this phase, since some corrective actions can be taken at this point (such as matching the competitor’s offer/improving the service quality etc.)\n",
    "\n",
    "3. <u>The ‘churn’ phase:</u> In this phase, the customer is said to have churned. In this case, since you are working over a four-month window, the first two months are the ‘good’ phase, the third month is the ‘action’ phase, while the fourth month (September) is the ‘churn’ phase.\n",
    "\n",
    "# 1. Objective:\n",
    "\n",
    "The main goal of the case study is to build ML models to predict churn. The predictive model that you’re going to build will the following purposes:\n",
    "\n",
    "1. It will be used to predict whether a high-value customer will churn or not, in near future (i.e. churn phase). By knowing this, the company can take action steps such as providing special plans, discounts on recharge etc.\n",
    "\n",
    "2. It will be used to identify important variables that are strong predictors of churn. These variables may also indicate why customers choose to switch to other networks.\n",
    "\n",
    "3. Even though overall accuracy will be your primary evaluation metric, you should also mention other metrics like precision, recall, etc. for the different models that can be used for evaluation purposes based on different business objectives. For example, in this problem statement, one business goal can be to build an ML model that identifies customers who'll definitely churn with more accuracy as compared to the ones who'll not churn. Make sure you mention which metric can be used in such scenarios.\n",
    "\n",
    "4. Recommend strategies to manage customer churn based on your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da713b1",
   "metadata": {
    "papermill": {
     "duration": 0.034501,
     "end_time": "2021-08-13T07:16:36.760335",
     "exception": false,
     "start_time": "2021-08-13T07:16:36.725834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1. Data Loading, Cleaning and Understadning\n",
    "\n",
    "Lets start by loading our dependencies. We can keep adding any imports to this cell block, as we write mode and mode code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e47254e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:16:36.838077Z",
     "iopub.status.busy": "2021-08-13T07:16:36.837038Z",
     "iopub.status.idle": "2021-08-13T07:16:38.158096Z",
     "shell.execute_reply": "2021-08-13T07:16:38.157302Z"
    },
    "papermill": {
     "duration": 1.362112,
     "end_time": "2021-08-13T07:16:38.158342",
     "exception": false,
     "start_time": "2021-08-13T07:16:36.796230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/kunalsahu/anaconda3/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: scipy in /Users/kunalsahu/anaconda3/lib/python3.10/site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in /Users/kunalsahu/anaconda3/lib/python3.10/site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: imbalanced-learn in /Users/kunalsahu/anaconda3/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/kunalsahu/anaconda3/lib/python3.10/site-packages (from imbalanced-learn) (1.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/kunalsahu/anaconda3/lib/python3.10/site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/kunalsahu/anaconda3/lib/python3.10/site-packages (from imbalanced-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/kunalsahu/anaconda3/lib/python3.10/site-packages (from imbalanced-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/kunalsahu/anaconda3/lib/python3.10/site-packages (from imbalanced-learn) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "#Data Structures\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "#Sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "!pip install xgboost\n",
    "!pip install -U imbalanced-learn\n",
    "import xgboost as xgb  # Load this xgboost\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "#Others\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1737b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing display limit of dataframe (optional cell to run)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Setting style for seaonrn\n",
    "sns.color_palette(\"seismic\", 50)\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5046d0",
   "metadata": {
    "papermill": {
     "duration": 0.03468,
     "end_time": "2021-08-13T07:16:38.240579",
     "exception": false,
     "start_time": "2021-08-13T07:16:38.205899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we load our datasets and the data dictionary file.\n",
    "\n",
    "The **train.csv** file contains both dependent and independent features, while the **test.csv** contains only the independent variables. \n",
    "\n",
    "So, for model selection, I will create our own train/test dataset from the **train.csv** and use the model to predict the solution using the features in unseen test.csv data for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b94d1d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:16:38.396407Z",
     "iopub.status.busy": "2021-08-13T07:16:38.395775Z",
     "iopub.status.idle": "2021-08-13T07:16:40.947829Z",
     "shell.execute_reply": "2021-08-13T07:16:40.948376Z"
    },
    "papermill": {
     "duration": 2.591587,
     "end_time": "2021-08-13T07:16:40.948543",
     "exception": false,
     "start_time": "2021-08-13T07:16:38.356956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69999, 172)\n",
      "(30000, 171)\n",
      "(30000, 2)\n",
      "(36, 2)\n"
     ]
    }
   ],
   "source": [
    "#Loading the data\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "sample = pd.read_csv(\"sample.csv\")\n",
    "data_dict = pd.read_csv(\"data_dictionary.csv\")\n",
    "#data = pd.read_csv(\"/kaggle/input/telecom-churn-case-study-hackathon-c55/train.csv\")\n",
    "#test = pd.read_csv(\"/kaggle/input/telecom-churn-case-study-hackathon-c55/test.csv\")\n",
    "#sample = pd.read_csv(\"/kaggle/input/telecom-churn-case-study-hackathon-c55/sample.csv\")\n",
    "#data_dict = pd.read_csv(\"/kaggle/input/telecom-churn-case-study-hackathon-c55/data_dictionary.csv\")\n",
    "\n",
    "print(data.shape)\n",
    "print(test.shape)\n",
    "print(sample.shape)\n",
    "print(data_dict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85af1ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69999 entries, 0 to 69998\n",
      "Data columns (total 172 columns):\n",
      " #    Column                    Dtype  \n",
      "---   ------                    -----  \n",
      " 0    id                        int64  \n",
      " 1    circle_id                 int64  \n",
      " 2    loc_og_t2o_mou            float64\n",
      " 3    std_og_t2o_mou            float64\n",
      " 4    loc_ic_t2o_mou            float64\n",
      " 5    last_date_of_month_6      object \n",
      " 6    last_date_of_month_7      object \n",
      " 7    last_date_of_month_8      object \n",
      " 8    arpu_6                    float64\n",
      " 9    arpu_7                    float64\n",
      " 10   arpu_8                    float64\n",
      " 11   onnet_mou_6               float64\n",
      " 12   onnet_mou_7               float64\n",
      " 13   onnet_mou_8               float64\n",
      " 14   offnet_mou_6              float64\n",
      " 15   offnet_mou_7              float64\n",
      " 16   offnet_mou_8              float64\n",
      " 17   roam_ic_mou_6             float64\n",
      " 18   roam_ic_mou_7             float64\n",
      " 19   roam_ic_mou_8             float64\n",
      " 20   roam_og_mou_6             float64\n",
      " 21   roam_og_mou_7             float64\n",
      " 22   roam_og_mou_8             float64\n",
      " 23   loc_og_t2t_mou_6          float64\n",
      " 24   loc_og_t2t_mou_7          float64\n",
      " 25   loc_og_t2t_mou_8          float64\n",
      " 26   loc_og_t2m_mou_6          float64\n",
      " 27   loc_og_t2m_mou_7          float64\n",
      " 28   loc_og_t2m_mou_8          float64\n",
      " 29   loc_og_t2f_mou_6          float64\n",
      " 30   loc_og_t2f_mou_7          float64\n",
      " 31   loc_og_t2f_mou_8          float64\n",
      " 32   loc_og_t2c_mou_6          float64\n",
      " 33   loc_og_t2c_mou_7          float64\n",
      " 34   loc_og_t2c_mou_8          float64\n",
      " 35   loc_og_mou_6              float64\n",
      " 36   loc_og_mou_7              float64\n",
      " 37   loc_og_mou_8              float64\n",
      " 38   std_og_t2t_mou_6          float64\n",
      " 39   std_og_t2t_mou_7          float64\n",
      " 40   std_og_t2t_mou_8          float64\n",
      " 41   std_og_t2m_mou_6          float64\n",
      " 42   std_og_t2m_mou_7          float64\n",
      " 43   std_og_t2m_mou_8          float64\n",
      " 44   std_og_t2f_mou_6          float64\n",
      " 45   std_og_t2f_mou_7          float64\n",
      " 46   std_og_t2f_mou_8          float64\n",
      " 47   std_og_t2c_mou_6          float64\n",
      " 48   std_og_t2c_mou_7          float64\n",
      " 49   std_og_t2c_mou_8          float64\n",
      " 50   std_og_mou_6              float64\n",
      " 51   std_og_mou_7              float64\n",
      " 52   std_og_mou_8              float64\n",
      " 53   isd_og_mou_6              float64\n",
      " 54   isd_og_mou_7              float64\n",
      " 55   isd_og_mou_8              float64\n",
      " 56   spl_og_mou_6              float64\n",
      " 57   spl_og_mou_7              float64\n",
      " 58   spl_og_mou_8              float64\n",
      " 59   og_others_6               float64\n",
      " 60   og_others_7               float64\n",
      " 61   og_others_8               float64\n",
      " 62   total_og_mou_6            float64\n",
      " 63   total_og_mou_7            float64\n",
      " 64   total_og_mou_8            float64\n",
      " 65   loc_ic_t2t_mou_6          float64\n",
      " 66   loc_ic_t2t_mou_7          float64\n",
      " 67   loc_ic_t2t_mou_8          float64\n",
      " 68   loc_ic_t2m_mou_6          float64\n",
      " 69   loc_ic_t2m_mou_7          float64\n",
      " 70   loc_ic_t2m_mou_8          float64\n",
      " 71   loc_ic_t2f_mou_6          float64\n",
      " 72   loc_ic_t2f_mou_7          float64\n",
      " 73   loc_ic_t2f_mou_8          float64\n",
      " 74   loc_ic_mou_6              float64\n",
      " 75   loc_ic_mou_7              float64\n",
      " 76   loc_ic_mou_8              float64\n",
      " 77   std_ic_t2t_mou_6          float64\n",
      " 78   std_ic_t2t_mou_7          float64\n",
      " 79   std_ic_t2t_mou_8          float64\n",
      " 80   std_ic_t2m_mou_6          float64\n",
      " 81   std_ic_t2m_mou_7          float64\n",
      " 82   std_ic_t2m_mou_8          float64\n",
      " 83   std_ic_t2f_mou_6          float64\n",
      " 84   std_ic_t2f_mou_7          float64\n",
      " 85   std_ic_t2f_mou_8          float64\n",
      " 86   std_ic_t2o_mou_6          float64\n",
      " 87   std_ic_t2o_mou_7          float64\n",
      " 88   std_ic_t2o_mou_8          float64\n",
      " 89   std_ic_mou_6              float64\n",
      " 90   std_ic_mou_7              float64\n",
      " 91   std_ic_mou_8              float64\n",
      " 92   total_ic_mou_6            float64\n",
      " 93   total_ic_mou_7            float64\n",
      " 94   total_ic_mou_8            float64\n",
      " 95   spl_ic_mou_6              float64\n",
      " 96   spl_ic_mou_7              float64\n",
      " 97   spl_ic_mou_8              float64\n",
      " 98   isd_ic_mou_6              float64\n",
      " 99   isd_ic_mou_7              float64\n",
      " 100  isd_ic_mou_8              float64\n",
      " 101  ic_others_6               float64\n",
      " 102  ic_others_7               float64\n",
      " 103  ic_others_8               float64\n",
      " 104  total_rech_num_6          int64  \n",
      " 105  total_rech_num_7          int64  \n",
      " 106  total_rech_num_8          int64  \n",
      " 107  total_rech_amt_6          int64  \n",
      " 108  total_rech_amt_7          int64  \n",
      " 109  total_rech_amt_8          int64  \n",
      " 110  max_rech_amt_6            int64  \n",
      " 111  max_rech_amt_7            int64  \n",
      " 112  max_rech_amt_8            int64  \n",
      " 113  date_of_last_rech_6       object \n",
      " 114  date_of_last_rech_7       object \n",
      " 115  date_of_last_rech_8       object \n",
      " 116  last_day_rch_amt_6        int64  \n",
      " 117  last_day_rch_amt_7        int64  \n",
      " 118  last_day_rch_amt_8        int64  \n",
      " 119  date_of_last_rech_data_6  object \n",
      " 120  date_of_last_rech_data_7  object \n",
      " 121  date_of_last_rech_data_8  object \n",
      " 122  total_rech_data_6         float64\n",
      " 123  total_rech_data_7         float64\n",
      " 124  total_rech_data_8         float64\n",
      " 125  max_rech_data_6           float64\n",
      " 126  max_rech_data_7           float64\n",
      " 127  max_rech_data_8           float64\n",
      " 128  count_rech_2g_6           float64\n",
      " 129  count_rech_2g_7           float64\n",
      " 130  count_rech_2g_8           float64\n",
      " 131  count_rech_3g_6           float64\n",
      " 132  count_rech_3g_7           float64\n",
      " 133  count_rech_3g_8           float64\n",
      " 134  av_rech_amt_data_6        float64\n",
      " 135  av_rech_amt_data_7        float64\n",
      " 136  av_rech_amt_data_8        float64\n",
      " 137  vol_2g_mb_6               float64\n",
      " 138  vol_2g_mb_7               float64\n",
      " 139  vol_2g_mb_8               float64\n",
      " 140  vol_3g_mb_6               float64\n",
      " 141  vol_3g_mb_7               float64\n",
      " 142  vol_3g_mb_8               float64\n",
      " 143  arpu_3g_6                 float64\n",
      " 144  arpu_3g_7                 float64\n",
      " 145  arpu_3g_8                 float64\n",
      " 146  arpu_2g_6                 float64\n",
      " 147  arpu_2g_7                 float64\n",
      " 148  arpu_2g_8                 float64\n",
      " 149  night_pck_user_6          float64\n",
      " 150  night_pck_user_7          float64\n",
      " 151  night_pck_user_8          float64\n",
      " 152  monthly_2g_6              int64  \n",
      " 153  monthly_2g_7              int64  \n",
      " 154  monthly_2g_8              int64  \n",
      " 155  sachet_2g_6               int64  \n",
      " 156  sachet_2g_7               int64  \n",
      " 157  sachet_2g_8               int64  \n",
      " 158  monthly_3g_6              int64  \n",
      " 159  monthly_3g_7              int64  \n",
      " 160  monthly_3g_8              int64  \n",
      " 161  sachet_3g_6               int64  \n",
      " 162  sachet_3g_7               int64  \n",
      " 163  sachet_3g_8               int64  \n",
      " 164  fb_user_6                 float64\n",
      " 165  fb_user_7                 float64\n",
      " 166  fb_user_8                 float64\n",
      " 167  aon                       int64  \n",
      " 168  aug_vbc_3g                float64\n",
      " 169  jul_vbc_3g                float64\n",
      " 170  jun_vbc_3g                float64\n",
      " 171  churn_probability         int64  \n",
      "dtypes: float64(135), int64(28), object(9)\n",
      "memory usage: 91.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info(verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9818060f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/22/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/12/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/8/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/11/2014</td>\n",
       "      <td>7/22/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/15/2014</td>\n",
       "      <td>7/21/2014</td>\n",
       "      <td>8/25/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/26/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/23/2014</td>\n",
       "      <td>8/20/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69994</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/18/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/21/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/28/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/27/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/30/2014</td>\n",
       "      <td>8/29/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/19/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>6/17/2014</td>\n",
       "      <td>7/13/2014</td>\n",
       "      <td>8/14/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>6/19/2014</td>\n",
       "      <td>7/27/2014</td>\n",
       "      <td>8/25/2014</td>\n",
       "      <td>6/19/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/8/2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69999 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "0                6/30/2014            7/31/2014            8/31/2014   \n",
       "1                6/30/2014            7/31/2014            8/31/2014   \n",
       "2                6/30/2014            7/31/2014            8/31/2014   \n",
       "3                6/30/2014            7/31/2014            8/31/2014   \n",
       "4                6/30/2014            7/31/2014            8/31/2014   \n",
       "...                    ...                  ...                  ...   \n",
       "69994            6/30/2014            7/31/2014            8/31/2014   \n",
       "69995            6/30/2014            7/31/2014            8/31/2014   \n",
       "69996            6/30/2014            7/31/2014            8/31/2014   \n",
       "69997            6/30/2014            7/31/2014            8/31/2014   \n",
       "69998            6/30/2014            7/31/2014            8/31/2014   \n",
       "\n",
       "      date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8  \\\n",
       "0               6/22/2014           7/10/2014           8/24/2014   \n",
       "1               6/12/2014           7/10/2014           8/26/2014   \n",
       "2               6/11/2014           7/22/2014           8/24/2014   \n",
       "3               6/15/2014           7/21/2014           8/25/2014   \n",
       "4               6/25/2014           7/26/2014           8/30/2014   \n",
       "...                   ...                 ...                 ...   \n",
       "69994           6/18/2014           7/31/2014           8/31/2014   \n",
       "69995           6/28/2014           7/31/2014           8/27/2014   \n",
       "69996           6/25/2014           7/30/2014           8/29/2014   \n",
       "69997           6/29/2014           7/19/2014           8/26/2014   \n",
       "69998           6/19/2014           7/27/2014           8/25/2014   \n",
       "\n",
       "      date_of_last_rech_data_6 date_of_last_rech_data_7  \\\n",
       "0                          NaN                      NaN   \n",
       "1                          NaN                 7/8/2014   \n",
       "2                          NaN                      NaN   \n",
       "3                          NaN                      NaN   \n",
       "4                    6/25/2014                7/23/2014   \n",
       "...                        ...                      ...   \n",
       "69994                      NaN                7/31/2014   \n",
       "69995                      NaN                      NaN   \n",
       "69996                      NaN                      NaN   \n",
       "69997                6/17/2014                7/13/2014   \n",
       "69998                6/19/2014                      NaN   \n",
       "\n",
       "      date_of_last_rech_data_8  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                    8/20/2014  \n",
       "...                        ...  \n",
       "69994                8/21/2014  \n",
       "69995                      NaN  \n",
       "69996                      NaN  \n",
       "69997                8/14/2014  \n",
       "69998                 8/8/2014  \n",
       "\n",
       "[69999 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat = data.select_dtypes(include='object')\n",
    "data_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710643d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69999</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>91.882</td>\n",
       "      <td>65.330</td>\n",
       "      <td>64.445</td>\n",
       "      <td>31.78</td>\n",
       "      <td>20.23</td>\n",
       "      <td>23.11</td>\n",
       "      <td>60.16</td>\n",
       "      <td>32.16</td>\n",
       "      <td>34.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.88</td>\n",
       "      <td>20.23</td>\n",
       "      <td>21.06</td>\n",
       "      <td>18.13</td>\n",
       "      <td>10.89</td>\n",
       "      <td>8.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>43.01</td>\n",
       "      <td>44.71</td>\n",
       "      <td>29.43</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>42.03</td>\n",
       "      <td>7.68</td>\n",
       "      <td>26.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.93</td>\n",
       "      <td>7.68</td>\n",
       "      <td>28.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.94</td>\n",
       "      <td>52.39</td>\n",
       "      <td>57.94</td>\n",
       "      <td>30.33</td>\n",
       "      <td>37.56</td>\n",
       "      <td>21.98</td>\n",
       "      <td>10.21</td>\n",
       "      <td>4.59</td>\n",
       "      <td>9.53</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.81</td>\n",
       "      <td>42.16</td>\n",
       "      <td>31.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.34</td>\n",
       "      <td>41.73</td>\n",
       "      <td>43.56</td>\n",
       "      <td>36.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>6/21/2014</td>\n",
       "      <td>7/26/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1692</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>414.168</td>\n",
       "      <td>515.568</td>\n",
       "      <td>360.868</td>\n",
       "      <td>75.51</td>\n",
       "      <td>41.21</td>\n",
       "      <td>19.84</td>\n",
       "      <td>474.34</td>\n",
       "      <td>621.84</td>\n",
       "      <td>394.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.51</td>\n",
       "      <td>41.21</td>\n",
       "      <td>19.84</td>\n",
       "      <td>473.61</td>\n",
       "      <td>598.08</td>\n",
       "      <td>377.26</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>549.86</td>\n",
       "      <td>639.29</td>\n",
       "      <td>397.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.76</td>\n",
       "      <td>17.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.76</td>\n",
       "      <td>17.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>549.86</td>\n",
       "      <td>663.06</td>\n",
       "      <td>415.59</td>\n",
       "      <td>19.99</td>\n",
       "      <td>26.95</td>\n",
       "      <td>2.61</td>\n",
       "      <td>160.19</td>\n",
       "      <td>122.29</td>\n",
       "      <td>184.81</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>181.69</td>\n",
       "      <td>149.24</td>\n",
       "      <td>187.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>296.33</td>\n",
       "      <td>339.64</td>\n",
       "      <td>281.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114.63</td>\n",
       "      <td>177.88</td>\n",
       "      <td>94.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>6/19/2014</td>\n",
       "      <td>7/16/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2533</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70001</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>329.844</td>\n",
       "      <td>434.884</td>\n",
       "      <td>746.239</td>\n",
       "      <td>7.54</td>\n",
       "      <td>7.86</td>\n",
       "      <td>8.40</td>\n",
       "      <td>16.98</td>\n",
       "      <td>45.81</td>\n",
       "      <td>45.04</td>\n",
       "      <td>22.81</td>\n",
       "      <td>103.38</td>\n",
       "      <td>26.08</td>\n",
       "      <td>24.53</td>\n",
       "      <td>53.68</td>\n",
       "      <td>54.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/27/2014</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>525.61</td>\n",
       "      <td>758.41</td>\n",
       "      <td>241.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70002</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>43.550</td>\n",
       "      <td>171.390</td>\n",
       "      <td>24.400</td>\n",
       "      <td>5.31</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.04</td>\n",
       "      <td>205.01</td>\n",
       "      <td>24.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.94</td>\n",
       "      <td>98.61</td>\n",
       "      <td>20.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.26</td>\n",
       "      <td>98.61</td>\n",
       "      <td>22.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.09</td>\n",
       "      <td>94.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.09</td>\n",
       "      <td>96.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.03</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.36</td>\n",
       "      <td>207.18</td>\n",
       "      <td>24.01</td>\n",
       "      <td>58.11</td>\n",
       "      <td>54.64</td>\n",
       "      <td>23.04</td>\n",
       "      <td>487.94</td>\n",
       "      <td>449.83</td>\n",
       "      <td>506.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.64</td>\n",
       "      <td>546.06</td>\n",
       "      <td>504.86</td>\n",
       "      <td>531.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.63</td>\n",
       "      <td>11.88</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.63</td>\n",
       "      <td>16.14</td>\n",
       "      <td>8.83</td>\n",
       "      <td>555.69</td>\n",
       "      <td>522.44</td>\n",
       "      <td>549.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.43</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/30/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70003</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>306.854</td>\n",
       "      <td>406.289</td>\n",
       "      <td>413.329</td>\n",
       "      <td>450.93</td>\n",
       "      <td>609.03</td>\n",
       "      <td>700.68</td>\n",
       "      <td>60.94</td>\n",
       "      <td>23.84</td>\n",
       "      <td>74.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.78</td>\n",
       "      <td>14.56</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.66</td>\n",
       "      <td>10.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.44</td>\n",
       "      <td>25.51</td>\n",
       "      <td>450.48</td>\n",
       "      <td>608.24</td>\n",
       "      <td>686.11</td>\n",
       "      <td>58.54</td>\n",
       "      <td>21.18</td>\n",
       "      <td>63.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>509.03</td>\n",
       "      <td>629.43</td>\n",
       "      <td>749.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.39</td>\n",
       "      <td>4.96</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.79</td>\n",
       "      <td>638.28</td>\n",
       "      <td>779.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9.91</td>\n",
       "      <td>10.13</td>\n",
       "      <td>9.23</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.13</td>\n",
       "      <td>9.59</td>\n",
       "      <td>17.61</td>\n",
       "      <td>29.71</td>\n",
       "      <td>92.36</td>\n",
       "      <td>107.39</td>\n",
       "      <td>13.88</td>\n",
       "      <td>13.96</td>\n",
       "      <td>32.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.59</td>\n",
       "      <td>106.33</td>\n",
       "      <td>141.48</td>\n",
       "      <td>53.73</td>\n",
       "      <td>115.93</td>\n",
       "      <td>159.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>356</td>\n",
       "      <td>490</td>\n",
       "      <td>546</td>\n",
       "      <td>90</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/29/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "      <td>50</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>462</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0  69999        109             0.0             0.0             0.0   \n",
       "1  70000        109             0.0             0.0             0.0   \n",
       "2  70001        109             0.0             0.0             0.0   \n",
       "3  70002        109             0.0             0.0             0.0   \n",
       "4  70003        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8   arpu_6  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   91.882   \n",
       "1            6/30/2014            7/31/2014            8/31/2014  414.168   \n",
       "2            6/30/2014            7/31/2014            8/31/2014  329.844   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   43.550   \n",
       "4            6/30/2014            7/31/2014            8/31/2014  306.854   \n",
       "\n",
       "    arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  \\\n",
       "0   65.330   64.445        31.78        20.23        23.11         60.16   \n",
       "1  515.568  360.868        75.51        41.21        19.84        474.34   \n",
       "2  434.884  746.239         7.54         7.86         8.40         16.98   \n",
       "3  171.390   24.400         5.31         2.16         0.00         40.04   \n",
       "4  406.289  413.329       450.93       609.03       700.68         60.94   \n",
       "\n",
       "   offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "0         32.16         34.83           0.00           0.00           0.00   \n",
       "1        621.84        394.94           0.00           0.00           0.00   \n",
       "2         45.81         45.04          22.81         103.38          26.08   \n",
       "3        205.01         24.01           0.00           0.00           0.00   \n",
       "4         23.84         74.16           0.00           0.00           0.00   \n",
       "\n",
       "   roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  loc_og_t2t_mou_6  \\\n",
       "0           0.00           0.00           0.00             24.88   \n",
       "1           0.00           0.00           0.00             75.51   \n",
       "2          24.53          53.68          54.44              0.00   \n",
       "3           0.00           0.00           0.00              5.31   \n",
       "4           0.00           0.00           0.00              0.45   \n",
       "\n",
       "   loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  loc_og_t2m_mou_7  \\\n",
       "0             20.23             21.06             18.13             10.89   \n",
       "1             41.21             19.84            473.61            598.08   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              0.00              0.00              2.94             98.61   \n",
       "4              0.78             14.56              2.39              2.66   \n",
       "\n",
       "   loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  \\\n",
       "0              8.36              0.00             13.58              0.00   \n",
       "1            377.26              0.73              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             20.51              0.00              0.00              2.35   \n",
       "4             10.94              0.00              0.00              0.00   \n",
       "\n",
       "   loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_mou_6  \\\n",
       "0               0.0              0.00              0.03         43.01   \n",
       "1               0.0              0.00              0.00        549.86   \n",
       "2               0.0              0.00              0.00          0.00   \n",
       "3               0.0              6.18              0.00          8.26   \n",
       "4               0.0              0.00              0.00          2.84   \n",
       "\n",
       "   loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  std_og_t2t_mou_7  \\\n",
       "0         44.71         29.43              6.90              0.00   \n",
       "1        639.29        397.11              0.00              0.00   \n",
       "2          0.00          0.00              0.00              0.00   \n",
       "3         98.61         22.86              0.00              2.16   \n",
       "4          3.44         25.51            450.48            608.24   \n",
       "\n",
       "   std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  std_og_t2m_mou_8  \\\n",
       "0              2.05             42.03              7.68             26.43   \n",
       "1              0.00              0.00             23.76             17.68   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              0.00             37.09             94.36              0.00   \n",
       "4            686.11             58.54             21.18             63.18   \n",
       "\n",
       "   std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2c_mou_6  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_mou_6  std_og_mou_7  \\\n",
       "0               0.0               0.0         48.93          7.68   \n",
       "1               0.0               0.0          0.00         23.76   \n",
       "2               0.0               0.0          0.00          0.00   \n",
       "3               0.0               0.0         37.09         96.53   \n",
       "4               0.0               0.0        509.03        629.43   \n",
       "\n",
       "   std_og_mou_8  isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  \\\n",
       "0         28.48           0.0           0.0           0.0          0.00   \n",
       "1         17.68           0.0           0.0           0.8          0.00   \n",
       "2          0.00           0.0           0.0           0.0          0.00   \n",
       "3          0.00           0.0           0.0           0.0          0.00   \n",
       "4        749.29           0.0           0.0           0.0          0.71   \n",
       "\n",
       "   spl_og_mou_7  spl_og_mou_8  og_others_6  og_others_7  og_others_8  \\\n",
       "0          0.00          0.03          0.0          0.0          0.0   \n",
       "1          0.00          0.00          0.0          0.0          0.0   \n",
       "2          0.00          0.00          0.0          0.0          0.0   \n",
       "3         12.03          1.15          0.0          0.0          0.0   \n",
       "4          5.39          4.96          2.2          0.0          0.0   \n",
       "\n",
       "   total_og_mou_6  total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  \\\n",
       "0           91.94           52.39           57.94             30.33   \n",
       "1          549.86          663.06          415.59             19.99   \n",
       "2            0.00            0.00            0.00              0.00   \n",
       "3           45.36          207.18           24.01             58.11   \n",
       "4          514.79          638.28          779.78              0.00   \n",
       "\n",
       "   loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  \\\n",
       "0             37.56             21.98             10.21              4.59   \n",
       "1             26.95              2.61            160.19            122.29   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             54.64             23.04            487.94            449.83   \n",
       "4              0.36              9.91             10.13              9.23   \n",
       "\n",
       "   loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  \\\n",
       "0              9.53              0.26              0.00              0.00   \n",
       "1            184.81              1.49              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3            506.94              0.00              0.38              1.64   \n",
       "4              7.69              0.00              0.00              0.00   \n",
       "\n",
       "   loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  \\\n",
       "0         40.81         42.16         31.51              0.00   \n",
       "1        181.69        149.24        187.43              0.00   \n",
       "2          0.00          0.00          0.00              0.00   \n",
       "3        546.06        504.86        531.64              0.00   \n",
       "4         10.13          9.59         17.61             29.71   \n",
       "\n",
       "   std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  \\\n",
       "0              0.00              0.00              0.36              1.04   \n",
       "1              0.00              0.00              0.00             12.51   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3              4.26              0.00              9.63             11.88   \n",
       "4             92.36            107.39             13.88             13.96   \n",
       "\n",
       "   std_ic_t2m_mou_8  std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  \\\n",
       "0              4.34               0.0               0.0              0.00   \n",
       "1              0.00               0.0               0.0              0.00   \n",
       "2              0.00               0.0               0.0              0.00   \n",
       "3              8.83               0.0               0.0              0.00   \n",
       "4             32.46               0.0               0.0              1.61   \n",
       "\n",
       "   std_ic_t2o_mou_6  std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_mou_6  \\\n",
       "0               0.0               0.0               0.0          0.36   \n",
       "1               0.0               0.0               0.0          0.00   \n",
       "2               0.0               0.0               0.0          0.00   \n",
       "3               0.0               0.0               0.0          9.63   \n",
       "4               0.0               0.0               0.0         43.59   \n",
       "\n",
       "   std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  total_ic_mou_8  \\\n",
       "0          1.04          4.34           41.73           43.56           36.26   \n",
       "1         12.51          0.00          296.33          339.64          281.66   \n",
       "2          0.00          0.00            0.00            0.00            0.00   \n",
       "3         16.14          8.83          555.69          522.44          549.13   \n",
       "4        106.33        141.48           53.73          115.93          159.26   \n",
       "\n",
       "   spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "0          0.54          0.34          0.39          0.00          0.00   \n",
       "1          0.00          0.00          0.00        114.63        177.88   \n",
       "2          0.00          0.00          0.00          0.00          0.00   \n",
       "3          0.00          0.00          0.00          0.00          1.43   \n",
       "4          0.00          0.00          0.00          0.00          0.00   \n",
       "\n",
       "   isd_ic_mou_8  ic_others_6  ic_others_7  ic_others_8  total_rech_num_6  \\\n",
       "0          0.00          0.0          0.0         0.00                 5   \n",
       "1         94.23          0.0          0.0         0.00                 5   \n",
       "2          0.00          0.0          0.0         0.00                 6   \n",
       "3          8.65          0.0          0.0         0.00                 3   \n",
       "4          0.00          0.0          0.0         0.16                11   \n",
       "\n",
       "   total_rech_num_7  total_rech_num_8  total_rech_amt_6  total_rech_amt_7  \\\n",
       "0                 5                 4               103                90   \n",
       "1                 4                 5               500               500   \n",
       "2                 9                 5               500              1000   \n",
       "3                 5                 2               110               260   \n",
       "4                 7                 8               356               490   \n",
       "\n",
       "   total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  max_rech_amt_8  \\\n",
       "0                60              50              30              30   \n",
       "1               500             250             250             250   \n",
       "2              1000             300             500             500   \n",
       "3                 0             110             150               0   \n",
       "4               546              90             130             130   \n",
       "\n",
       "  date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8  \\\n",
       "0           6/21/2014           7/26/2014           8/24/2014   \n",
       "1           6/19/2014           7/16/2014           8/24/2014   \n",
       "2           6/29/2014           7/27/2014           8/28/2014   \n",
       "3           6/25/2014           7/30/2014           8/24/2014   \n",
       "4           6/29/2014           7/29/2014           8/30/2014   \n",
       "\n",
       "   last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "0                  30                  30                   0   \n",
       "1                 250                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                 110                 150                   0   \n",
       "4                  50                 130                 130   \n",
       "\n",
       "  date_of_last_rech_data_6 date_of_last_rech_data_7 date_of_last_rech_data_8  \\\n",
       "0                      NaN                      NaN                      NaN   \n",
       "1                      NaN                      NaN                      NaN   \n",
       "2                      NaN                      NaN                      NaN   \n",
       "3                      NaN                      NaN                      NaN   \n",
       "4                      NaN                      NaN                      NaN   \n",
       "\n",
       "   total_rech_data_6  total_rech_data_7  total_rech_data_8  max_rech_data_6  \\\n",
       "0                NaN                NaN                NaN              NaN   \n",
       "1                NaN                NaN                NaN              NaN   \n",
       "2                NaN                NaN                NaN              NaN   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4                NaN                NaN                NaN              NaN   \n",
       "\n",
       "   max_rech_data_7  max_rech_data_8  count_rech_2g_6  count_rech_2g_7  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   count_rech_2g_8  count_rech_3g_6  count_rech_3g_7  count_rech_3g_8  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   av_rech_amt_data_6  av_rech_amt_data_7  av_rech_amt_data_8  vol_2g_mb_6  \\\n",
       "0                 NaN                 NaN                 NaN          0.0   \n",
       "1                 NaN                 NaN                 NaN          0.0   \n",
       "2                 NaN                 NaN                 NaN          0.0   \n",
       "3                 NaN                 NaN                 NaN          0.0   \n",
       "4                 NaN                 NaN                 NaN          0.0   \n",
       "\n",
       "   vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  vol_3g_mb_7  vol_3g_mb_8  arpu_3g_6  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "1          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "2          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "3          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "4          0.0          0.0          0.0          0.0          0.0        NaN   \n",
       "\n",
       "   arpu_3g_7  arpu_3g_8  arpu_2g_6  arpu_2g_7  arpu_2g_8  night_pck_user_6  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "1        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "4        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "\n",
       "   night_pck_user_7  night_pck_user_8  monthly_2g_6  monthly_2g_7  \\\n",
       "0               NaN               NaN             0             0   \n",
       "1               NaN               NaN             0             0   \n",
       "2               NaN               NaN             0             0   \n",
       "3               NaN               NaN             0             0   \n",
       "4               NaN               NaN             0             0   \n",
       "\n",
       "   monthly_2g_8  sachet_2g_6  sachet_2g_7  sachet_2g_8  monthly_3g_6  \\\n",
       "0             0            0            0            0             0   \n",
       "1             0            0            0            0             0   \n",
       "2             0            0            0            0             0   \n",
       "3             0            0            0            0             0   \n",
       "4             0            0            0            0             0   \n",
       "\n",
       "   monthly_3g_7  monthly_3g_8  sachet_3g_6  sachet_3g_7  sachet_3g_8  \\\n",
       "0             0             0            0            0            0   \n",
       "1             0             0            0            0            0   \n",
       "2             0             0            0            0            0   \n",
       "3             0             0            0            0            0   \n",
       "4             0             0            0            0            0   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \n",
       "0        NaN        NaN        NaN  1692        0.00        0.00        0.00  \n",
       "1        NaN        NaN        NaN  2533        0.00        0.00        0.00  \n",
       "2        NaN        NaN        NaN   277      525.61      758.41      241.84  \n",
       "3        NaN        NaN        NaN  1244        0.00        0.00        0.00  \n",
       "4        NaN        NaN        NaN   462        0.00        0.00        0.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a600b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that 9 columns we have as a string which is date and will be converted to datetype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "860fa8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.0</td>\n",
       "      <td>69297.0</td>\n",
       "      <td>69297.0</td>\n",
       "      <td>69297.0</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.0</td>\n",
       "      <td>67312.0</td>\n",
       "      <td>66296.0</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.0</td>\n",
       "      <td>67312.0</td>\n",
       "      <td>66296.0</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.00000</td>\n",
       "      <td>69999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34999.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283.134365</td>\n",
       "      <td>278.185912</td>\n",
       "      <td>278.858826</td>\n",
       "      <td>133.153275</td>\n",
       "      <td>133.894438</td>\n",
       "      <td>132.978257</td>\n",
       "      <td>198.874771</td>\n",
       "      <td>197.153383</td>\n",
       "      <td>196.543577</td>\n",
       "      <td>9.765435</td>\n",
       "      <td>7.014568</td>\n",
       "      <td>7.004892</td>\n",
       "      <td>14.186457</td>\n",
       "      <td>9.842191</td>\n",
       "      <td>9.771783</td>\n",
       "      <td>46.904854</td>\n",
       "      <td>46.166503</td>\n",
       "      <td>45.686109</td>\n",
       "      <td>93.238231</td>\n",
       "      <td>90.799240</td>\n",
       "      <td>91.121447</td>\n",
       "      <td>3.743179</td>\n",
       "      <td>3.777031</td>\n",
       "      <td>3.661652</td>\n",
       "      <td>1.126025</td>\n",
       "      <td>1.361052</td>\n",
       "      <td>1.420840</td>\n",
       "      <td>143.893585</td>\n",
       "      <td>140.750120</td>\n",
       "      <td>140.476486</td>\n",
       "      <td>80.619382</td>\n",
       "      <td>83.775851</td>\n",
       "      <td>83.471486</td>\n",
       "      <td>88.152110</td>\n",
       "      <td>91.538615</td>\n",
       "      <td>90.586999</td>\n",
       "      <td>1.126377</td>\n",
       "      <td>1.084062</td>\n",
       "      <td>1.057739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.900601</td>\n",
       "      <td>176.401217</td>\n",
       "      <td>175.118852</td>\n",
       "      <td>0.845763</td>\n",
       "      <td>0.811100</td>\n",
       "      <td>0.841648</td>\n",
       "      <td>3.958619</td>\n",
       "      <td>4.976783</td>\n",
       "      <td>5.045027</td>\n",
       "      <td>0.462581</td>\n",
       "      <td>0.024425</td>\n",
       "      <td>0.033059</td>\n",
       "      <td>306.451436</td>\n",
       "      <td>310.572674</td>\n",
       "      <td>304.513065</td>\n",
       "      <td>48.043255</td>\n",
       "      <td>47.882736</td>\n",
       "      <td>47.256388</td>\n",
       "      <td>107.152439</td>\n",
       "      <td>106.489856</td>\n",
       "      <td>108.154731</td>\n",
       "      <td>12.050672</td>\n",
       "      <td>12.563665</td>\n",
       "      <td>11.716763</td>\n",
       "      <td>167.255126</td>\n",
       "      <td>166.945103</td>\n",
       "      <td>167.136761</td>\n",
       "      <td>9.476958</td>\n",
       "      <td>9.873468</td>\n",
       "      <td>9.910217</td>\n",
       "      <td>20.734858</td>\n",
       "      <td>21.685359</td>\n",
       "      <td>21.089042</td>\n",
       "      <td>2.146273</td>\n",
       "      <td>2.199395</td>\n",
       "      <td>2.075179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.360632</td>\n",
       "      <td>33.760809</td>\n",
       "      <td>33.077030</td>\n",
       "      <td>199.710640</td>\n",
       "      <td>201.878029</td>\n",
       "      <td>198.486034</td>\n",
       "      <td>0.061932</td>\n",
       "      <td>0.033371</td>\n",
       "      <td>0.040392</td>\n",
       "      <td>7.394167</td>\n",
       "      <td>8.171162</td>\n",
       "      <td>8.348424</td>\n",
       "      <td>0.854063</td>\n",
       "      <td>1.019680</td>\n",
       "      <td>0.963214</td>\n",
       "      <td>7.566522</td>\n",
       "      <td>7.706667</td>\n",
       "      <td>7.224932</td>\n",
       "      <td>328.139788</td>\n",
       "      <td>322.376363</td>\n",
       "      <td>323.846355</td>\n",
       "      <td>104.569265</td>\n",
       "      <td>104.137573</td>\n",
       "      <td>107.540351</td>\n",
       "      <td>63.426949</td>\n",
       "      <td>59.294218</td>\n",
       "      <td>62.489478</td>\n",
       "      <td>2.467612</td>\n",
       "      <td>2.679989</td>\n",
       "      <td>2.652441</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>126.402071</td>\n",
       "      <td>125.374925</td>\n",
       "      <td>1.865323</td>\n",
       "      <td>2.056311</td>\n",
       "      <td>2.016018</td>\n",
       "      <td>0.602288</td>\n",
       "      <td>0.623678</td>\n",
       "      <td>0.636423</td>\n",
       "      <td>192.831096</td>\n",
       "      <td>201.455940</td>\n",
       "      <td>196.815792</td>\n",
       "      <td>51.773924</td>\n",
       "      <td>51.240204</td>\n",
       "      <td>50.127506</td>\n",
       "      <td>122.171882</td>\n",
       "      <td>128.934444</td>\n",
       "      <td>135.486541</td>\n",
       "      <td>90.069931</td>\n",
       "      <td>89.115767</td>\n",
       "      <td>90.618564</td>\n",
       "      <td>86.863900</td>\n",
       "      <td>85.846074</td>\n",
       "      <td>86.348404</td>\n",
       "      <td>0.025273</td>\n",
       "      <td>0.024069</td>\n",
       "      <td>0.021013</td>\n",
       "      <td>0.079287</td>\n",
       "      <td>0.083401</td>\n",
       "      <td>0.080930</td>\n",
       "      <td>0.388863</td>\n",
       "      <td>0.441406</td>\n",
       "      <td>0.449492</td>\n",
       "      <td>0.075815</td>\n",
       "      <td>0.077730</td>\n",
       "      <td>0.081958</td>\n",
       "      <td>0.075344</td>\n",
       "      <td>0.081444</td>\n",
       "      <td>0.085487</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.909544</td>\n",
       "      <td>0.890319</td>\n",
       "      <td>1220.639709</td>\n",
       "      <td>68.108597</td>\n",
       "      <td>65.935830</td>\n",
       "      <td>60.07674</td>\n",
       "      <td>0.101887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20207.115084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.213918</td>\n",
       "      <td>344.366927</td>\n",
       "      <td>351.924315</td>\n",
       "      <td>299.963093</td>\n",
       "      <td>311.277193</td>\n",
       "      <td>311.896596</td>\n",
       "      <td>316.818355</td>\n",
       "      <td>322.482226</td>\n",
       "      <td>324.089234</td>\n",
       "      <td>57.374429</td>\n",
       "      <td>55.960985</td>\n",
       "      <td>53.408135</td>\n",
       "      <td>73.469261</td>\n",
       "      <td>58.511894</td>\n",
       "      <td>64.618388</td>\n",
       "      <td>150.971758</td>\n",
       "      <td>154.739002</td>\n",
       "      <td>153.716880</td>\n",
       "      <td>162.046699</td>\n",
       "      <td>153.852597</td>\n",
       "      <td>152.997805</td>\n",
       "      <td>13.319542</td>\n",
       "      <td>13.568110</td>\n",
       "      <td>13.009193</td>\n",
       "      <td>5.741811</td>\n",
       "      <td>7.914113</td>\n",
       "      <td>6.542202</td>\n",
       "      <td>252.034597</td>\n",
       "      <td>246.313148</td>\n",
       "      <td>245.342359</td>\n",
       "      <td>255.098355</td>\n",
       "      <td>266.693254</td>\n",
       "      <td>267.021929</td>\n",
       "      <td>255.771554</td>\n",
       "      <td>267.532089</td>\n",
       "      <td>270.032002</td>\n",
       "      <td>8.136645</td>\n",
       "      <td>8.325206</td>\n",
       "      <td>7.696853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.046600</td>\n",
       "      <td>409.299501</td>\n",
       "      <td>410.697098</td>\n",
       "      <td>29.747486</td>\n",
       "      <td>29.220073</td>\n",
       "      <td>29.563367</td>\n",
       "      <td>15.854529</td>\n",
       "      <td>22.229842</td>\n",
       "      <td>17.708507</td>\n",
       "      <td>4.768437</td>\n",
       "      <td>1.716430</td>\n",
       "      <td>2.232547</td>\n",
       "      <td>465.502866</td>\n",
       "      <td>479.131770</td>\n",
       "      <td>477.936832</td>\n",
       "      <td>140.499757</td>\n",
       "      <td>147.761124</td>\n",
       "      <td>141.249368</td>\n",
       "      <td>168.455999</td>\n",
       "      <td>165.452459</td>\n",
       "      <td>166.223461</td>\n",
       "      <td>39.416076</td>\n",
       "      <td>43.495179</td>\n",
       "      <td>38.606895</td>\n",
       "      <td>252.576231</td>\n",
       "      <td>254.688718</td>\n",
       "      <td>249.288410</td>\n",
       "      <td>51.664472</td>\n",
       "      <td>56.137824</td>\n",
       "      <td>54.248186</td>\n",
       "      <td>80.294236</td>\n",
       "      <td>87.314510</td>\n",
       "      <td>81.534344</td>\n",
       "      <td>16.522232</td>\n",
       "      <td>16.171533</td>\n",
       "      <td>15.865403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.381082</td>\n",
       "      <td>114.142230</td>\n",
       "      <td>108.469864</td>\n",
       "      <td>290.114823</td>\n",
       "      <td>296.771338</td>\n",
       "      <td>288.336731</td>\n",
       "      <td>0.164823</td>\n",
       "      <td>0.137322</td>\n",
       "      <td>0.148417</td>\n",
       "      <td>60.951165</td>\n",
       "      <td>63.604165</td>\n",
       "      <td>63.097570</td>\n",
       "      <td>12.149144</td>\n",
       "      <td>13.225373</td>\n",
       "      <td>11.697686</td>\n",
       "      <td>7.041452</td>\n",
       "      <td>7.050614</td>\n",
       "      <td>7.195597</td>\n",
       "      <td>404.211068</td>\n",
       "      <td>411.070120</td>\n",
       "      <td>426.181405</td>\n",
       "      <td>121.407701</td>\n",
       "      <td>120.782543</td>\n",
       "      <td>124.396750</td>\n",
       "      <td>97.954876</td>\n",
       "      <td>95.429492</td>\n",
       "      <td>101.996729</td>\n",
       "      <td>2.794610</td>\n",
       "      <td>3.073472</td>\n",
       "      <td>3.101265</td>\n",
       "      <td>109.352573</td>\n",
       "      <td>109.459266</td>\n",
       "      <td>109.648799</td>\n",
       "      <td>2.566377</td>\n",
       "      <td>2.799916</td>\n",
       "      <td>2.728246</td>\n",
       "      <td>1.279297</td>\n",
       "      <td>1.401230</td>\n",
       "      <td>1.457058</td>\n",
       "      <td>190.623115</td>\n",
       "      <td>198.346141</td>\n",
       "      <td>192.280532</td>\n",
       "      <td>212.513909</td>\n",
       "      <td>211.114667</td>\n",
       "      <td>213.101403</td>\n",
       "      <td>554.869965</td>\n",
       "      <td>554.096072</td>\n",
       "      <td>568.310234</td>\n",
       "      <td>193.600413</td>\n",
       "      <td>195.826990</td>\n",
       "      <td>189.907986</td>\n",
       "      <td>171.321203</td>\n",
       "      <td>178.067280</td>\n",
       "      <td>170.297094</td>\n",
       "      <td>0.156958</td>\n",
       "      <td>0.153269</td>\n",
       "      <td>0.143432</td>\n",
       "      <td>0.294719</td>\n",
       "      <td>0.304802</td>\n",
       "      <td>0.299254</td>\n",
       "      <td>1.494206</td>\n",
       "      <td>1.651012</td>\n",
       "      <td>1.632450</td>\n",
       "      <td>0.358905</td>\n",
       "      <td>0.383189</td>\n",
       "      <td>0.381821</td>\n",
       "      <td>0.573003</td>\n",
       "      <td>0.634547</td>\n",
       "      <td>0.680035</td>\n",
       "      <td>0.276907</td>\n",
       "      <td>0.286842</td>\n",
       "      <td>0.312501</td>\n",
       "      <td>952.426321</td>\n",
       "      <td>269.328659</td>\n",
       "      <td>267.899034</td>\n",
       "      <td>257.22681</td>\n",
       "      <td>0.302502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2258.709000</td>\n",
       "      <td>-1289.715000</td>\n",
       "      <td>-945.808000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-20.380000</td>\n",
       "      <td>-26.040000</td>\n",
       "      <td>-24.490000</td>\n",
       "      <td>-35.830000</td>\n",
       "      <td>-13.090000</td>\n",
       "      <td>-55.830000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17499.500000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.581000</td>\n",
       "      <td>86.714000</td>\n",
       "      <td>84.095000</td>\n",
       "      <td>7.410000</td>\n",
       "      <td>6.675000</td>\n",
       "      <td>6.410000</td>\n",
       "      <td>34.860000</td>\n",
       "      <td>32.240000</td>\n",
       "      <td>31.575000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>10.090000</td>\n",
       "      <td>9.830000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.235000</td>\n",
       "      <td>17.590000</td>\n",
       "      <td>17.237500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.780000</td>\n",
       "      <td>42.910000</td>\n",
       "      <td>38.710000</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>3.260000</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>17.390000</td>\n",
       "      <td>18.610000</td>\n",
       "      <td>18.940000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.630000</td>\n",
       "      <td>32.710000</td>\n",
       "      <td>32.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>38.640000</td>\n",
       "      <td>41.340000</td>\n",
       "      <td>38.290000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34999.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.484000</td>\n",
       "      <td>191.588000</td>\n",
       "      <td>192.234000</td>\n",
       "      <td>34.110000</td>\n",
       "      <td>32.280000</td>\n",
       "      <td>32.100000</td>\n",
       "      <td>96.480000</td>\n",
       "      <td>91.885000</td>\n",
       "      <td>91.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.910000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>11.740000</td>\n",
       "      <td>41.030000</td>\n",
       "      <td>40.170000</td>\n",
       "      <td>40.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.190000</td>\n",
       "      <td>63.430000</td>\n",
       "      <td>63.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.730000</td>\n",
       "      <td>11.260000</td>\n",
       "      <td>10.505000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>145.280000</td>\n",
       "      <td>141.230000</td>\n",
       "      <td>138.360000</td>\n",
       "      <td>15.740000</td>\n",
       "      <td>15.830000</td>\n",
       "      <td>16.040000</td>\n",
       "      <td>56.460000</td>\n",
       "      <td>56.930000</td>\n",
       "      <td>58.210000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>92.430000</td>\n",
       "      <td>92.510000</td>\n",
       "      <td>93.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.910000</td>\n",
       "      <td>5.980000</td>\n",
       "      <td>5.830000</td>\n",
       "      <td>114.780000</td>\n",
       "      <td>116.330000</td>\n",
       "      <td>114.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>868.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52498.500000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370.791000</td>\n",
       "      <td>365.369500</td>\n",
       "      <td>369.909000</td>\n",
       "      <td>119.390000</td>\n",
       "      <td>115.837500</td>\n",
       "      <td>115.060000</td>\n",
       "      <td>232.990000</td>\n",
       "      <td>227.630000</td>\n",
       "      <td>229.345000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.740000</td>\n",
       "      <td>39.760000</td>\n",
       "      <td>39.895000</td>\n",
       "      <td>110.430000</td>\n",
       "      <td>107.540000</td>\n",
       "      <td>109.245000</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>167.880000</td>\n",
       "      <td>163.932500</td>\n",
       "      <td>165.615000</td>\n",
       "      <td>31.020000</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>30.760000</td>\n",
       "      <td>53.745000</td>\n",
       "      <td>54.640000</td>\n",
       "      <td>52.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.335000</td>\n",
       "      <td>151.645000</td>\n",
       "      <td>149.015000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>3.660000</td>\n",
       "      <td>4.002500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>374.305000</td>\n",
       "      <td>380.045000</td>\n",
       "      <td>370.895000</td>\n",
       "      <td>46.980000</td>\n",
       "      <td>45.690000</td>\n",
       "      <td>46.280000</td>\n",
       "      <td>132.020000</td>\n",
       "      <td>131.010000</td>\n",
       "      <td>134.380000</td>\n",
       "      <td>8.140000</td>\n",
       "      <td>8.230000</td>\n",
       "      <td>8.090000</td>\n",
       "      <td>208.325000</td>\n",
       "      <td>205.530000</td>\n",
       "      <td>208.060000</td>\n",
       "      <td>4.060000</td>\n",
       "      <td>4.180000</td>\n",
       "      <td>4.052500</td>\n",
       "      <td>14.960000</td>\n",
       "      <td>15.830000</td>\n",
       "      <td>15.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.780000</td>\n",
       "      <td>28.160000</td>\n",
       "      <td>27.615000</td>\n",
       "      <td>251.070000</td>\n",
       "      <td>249.470000</td>\n",
       "      <td>249.710000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>120.860000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1813.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>62998.200000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619.993800</td>\n",
       "      <td>615.661400</td>\n",
       "      <td>614.994600</td>\n",
       "      <td>345.080000</td>\n",
       "      <td>347.908000</td>\n",
       "      <td>343.695000</td>\n",
       "      <td>482.030000</td>\n",
       "      <td>482.071000</td>\n",
       "      <td>486.980000</td>\n",
       "      <td>11.950000</td>\n",
       "      <td>5.039000</td>\n",
       "      <td>5.210000</td>\n",
       "      <td>22.710000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.270000</td>\n",
       "      <td>104.510000</td>\n",
       "      <td>101.039000</td>\n",
       "      <td>101.385000</td>\n",
       "      <td>233.640000</td>\n",
       "      <td>228.207000</td>\n",
       "      <td>230.930000</td>\n",
       "      <td>9.530000</td>\n",
       "      <td>9.590000</td>\n",
       "      <td>9.270000</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>356.090000</td>\n",
       "      <td>345.721000</td>\n",
       "      <td>347.920000</td>\n",
       "      <td>217.060000</td>\n",
       "      <td>226.337000</td>\n",
       "      <td>226.010000</td>\n",
       "      <td>237.490000</td>\n",
       "      <td>247.229000</td>\n",
       "      <td>248.950000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.240000</td>\n",
       "      <td>556.755000</td>\n",
       "      <td>553.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.660000</td>\n",
       "      <td>13.130000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>785.230000</td>\n",
       "      <td>806.250000</td>\n",
       "      <td>792.858000</td>\n",
       "      <td>107.260000</td>\n",
       "      <td>105.589000</td>\n",
       "      <td>105.310000</td>\n",
       "      <td>254.290000</td>\n",
       "      <td>252.260000</td>\n",
       "      <td>255.160000</td>\n",
       "      <td>30.210000</td>\n",
       "      <td>30.410000</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>392.610000</td>\n",
       "      <td>387.560000</td>\n",
       "      <td>389.410000</td>\n",
       "      <td>19.910000</td>\n",
       "      <td>20.680000</td>\n",
       "      <td>20.480000</td>\n",
       "      <td>47.610000</td>\n",
       "      <td>49.810000</td>\n",
       "      <td>48.830000</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.710000</td>\n",
       "      <td>77.939000</td>\n",
       "      <td>76.640000</td>\n",
       "      <td>467.030000</td>\n",
       "      <td>468.524000</td>\n",
       "      <td>464.508000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>4.910000</td>\n",
       "      <td>6.590000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>735.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>734.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>353.300000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>103.514000</td>\n",
       "      <td>97.410000</td>\n",
       "      <td>93.290000</td>\n",
       "      <td>302.810000</td>\n",
       "      <td>335.372000</td>\n",
       "      <td>372.540000</td>\n",
       "      <td>246.159000</td>\n",
       "      <td>244.140000</td>\n",
       "      <td>248.556000</td>\n",
       "      <td>223.773000</td>\n",
       "      <td>220.036000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>160.444000</td>\n",
       "      <td>136.272000</td>\n",
       "      <td>110.32800</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>66498.100000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.022700</td>\n",
       "      <td>823.236700</td>\n",
       "      <td>828.464700</td>\n",
       "      <td>617.185000</td>\n",
       "      <td>628.437500</td>\n",
       "      <td>620.240000</td>\n",
       "      <td>735.985000</td>\n",
       "      <td>747.558000</td>\n",
       "      <td>738.017500</td>\n",
       "      <td>41.350000</td>\n",
       "      <td>23.199000</td>\n",
       "      <td>23.990000</td>\n",
       "      <td>69.455000</td>\n",
       "      <td>42.599000</td>\n",
       "      <td>42.110000</td>\n",
       "      <td>176.635000</td>\n",
       "      <td>174.299000</td>\n",
       "      <td>174.630000</td>\n",
       "      <td>355.220000</td>\n",
       "      <td>348.440000</td>\n",
       "      <td>347.700000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>19.019000</td>\n",
       "      <td>18.280000</td>\n",
       "      <td>6.360000</td>\n",
       "      <td>7.354500</td>\n",
       "      <td>7.852500</td>\n",
       "      <td>538.985000</td>\n",
       "      <td>530.052500</td>\n",
       "      <td>528.757500</td>\n",
       "      <td>465.765000</td>\n",
       "      <td>496.777500</td>\n",
       "      <td>491.360000</td>\n",
       "      <td>462.825000</td>\n",
       "      <td>486.712500</td>\n",
       "      <td>486.945000</td>\n",
       "      <td>4.310000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>888.810000</td>\n",
       "      <td>924.753000</td>\n",
       "      <td>921.027500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.560000</td>\n",
       "      <td>23.380000</td>\n",
       "      <td>23.832500</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1171.188000</td>\n",
       "      <td>1193.257000</td>\n",
       "      <td>1174.552000</td>\n",
       "      <td>174.410000</td>\n",
       "      <td>173.534500</td>\n",
       "      <td>171.177500</td>\n",
       "      <td>372.260000</td>\n",
       "      <td>365.808000</td>\n",
       "      <td>371.767500</td>\n",
       "      <td>57.060000</td>\n",
       "      <td>58.884500</td>\n",
       "      <td>55.617500</td>\n",
       "      <td>568.035000</td>\n",
       "      <td>562.325500</td>\n",
       "      <td>568.242500</td>\n",
       "      <td>40.900000</td>\n",
       "      <td>42.149000</td>\n",
       "      <td>42.250000</td>\n",
       "      <td>86.815000</td>\n",
       "      <td>90.160000</td>\n",
       "      <td>88.545000</td>\n",
       "      <td>8.480000</td>\n",
       "      <td>8.550000</td>\n",
       "      <td>8.310000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.820000</td>\n",
       "      <td>138.566000</td>\n",
       "      <td>136.515000</td>\n",
       "      <td>668.240000</td>\n",
       "      <td>676.904000</td>\n",
       "      <td>665.435000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>24.375000</td>\n",
       "      <td>28.140000</td>\n",
       "      <td>29.980000</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>2.619000</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>998.000000</td>\n",
       "      <td>986.100000</td>\n",
       "      <td>988.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>327.241000</td>\n",
       "      <td>318.672000</td>\n",
       "      <td>302.284000</td>\n",
       "      <td>831.189000</td>\n",
       "      <td>866.464000</td>\n",
       "      <td>899.073000</td>\n",
       "      <td>424.806500</td>\n",
       "      <td>427.222000</td>\n",
       "      <td>424.498000</td>\n",
       "      <td>420.826000</td>\n",
       "      <td>423.174000</td>\n",
       "      <td>411.958000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3108.000000</td>\n",
       "      <td>464.277000</td>\n",
       "      <td>446.353000</td>\n",
       "      <td>400.13400</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>69298.020000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1400.276640</td>\n",
       "      <td>1414.891380</td>\n",
       "      <td>1445.054800</td>\n",
       "      <td>1447.098000</td>\n",
       "      <td>1478.540900</td>\n",
       "      <td>1472.480500</td>\n",
       "      <td>1546.471000</td>\n",
       "      <td>1545.104000</td>\n",
       "      <td>1522.474000</td>\n",
       "      <td>219.649000</td>\n",
       "      <td>153.006700</td>\n",
       "      <td>159.714000</td>\n",
       "      <td>290.851000</td>\n",
       "      <td>221.866800</td>\n",
       "      <td>213.816500</td>\n",
       "      <td>548.148000</td>\n",
       "      <td>530.900600</td>\n",
       "      <td>526.527500</td>\n",
       "      <td>744.779000</td>\n",
       "      <td>723.735800</td>\n",
       "      <td>733.398500</td>\n",
       "      <td>54.515000</td>\n",
       "      <td>55.754500</td>\n",
       "      <td>54.884000</td>\n",
       "      <td>20.287000</td>\n",
       "      <td>23.606700</td>\n",
       "      <td>24.342500</td>\n",
       "      <td>1154.437000</td>\n",
       "      <td>1130.439500</td>\n",
       "      <td>1108.476500</td>\n",
       "      <td>1232.315000</td>\n",
       "      <td>1281.418500</td>\n",
       "      <td>1283.875000</td>\n",
       "      <td>1250.527000</td>\n",
       "      <td>1275.198200</td>\n",
       "      <td>1235.259500</td>\n",
       "      <td>25.530000</td>\n",
       "      <td>24.504500</td>\n",
       "      <td>23.950500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1881.720000</td>\n",
       "      <td>1915.989900</td>\n",
       "      <td>1924.505000</td>\n",
       "      <td>8.430000</td>\n",
       "      <td>8.424500</td>\n",
       "      <td>6.911000</td>\n",
       "      <td>51.403000</td>\n",
       "      <td>61.277800</td>\n",
       "      <td>60.500500</td>\n",
       "      <td>6.930000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2235.611000</td>\n",
       "      <td>2275.607000</td>\n",
       "      <td>2242.854800</td>\n",
       "      <td>488.360000</td>\n",
       "      <td>486.412700</td>\n",
       "      <td>468.482500</td>\n",
       "      <td>760.310000</td>\n",
       "      <td>750.332500</td>\n",
       "      <td>764.276500</td>\n",
       "      <td>165.016000</td>\n",
       "      <td>173.836700</td>\n",
       "      <td>158.084000</td>\n",
       "      <td>1154.640000</td>\n",
       "      <td>1169.551200</td>\n",
       "      <td>1144.103000</td>\n",
       "      <td>140.525000</td>\n",
       "      <td>150.930000</td>\n",
       "      <td>152.297500</td>\n",
       "      <td>272.089000</td>\n",
       "      <td>282.568000</td>\n",
       "      <td>282.967500</td>\n",
       "      <td>40.731000</td>\n",
       "      <td>42.486700</td>\n",
       "      <td>38.730500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.449000</td>\n",
       "      <td>419.468200</td>\n",
       "      <td>413.210000</td>\n",
       "      <td>1366.030000</td>\n",
       "      <td>1382.071400</td>\n",
       "      <td>1353.297000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>165.436000</td>\n",
       "      <td>174.872300</td>\n",
       "      <td>176.070000</td>\n",
       "      <td>14.887000</td>\n",
       "      <td>16.627800</td>\n",
       "      <td>16.463500</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1683.020000</td>\n",
       "      <td>1712.000000</td>\n",
       "      <td>1706.020000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>498.300000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>910.000000</td>\n",
       "      <td>951.000000</td>\n",
       "      <td>951.000000</td>\n",
       "      <td>995.815200</td>\n",
       "      <td>999.260200</td>\n",
       "      <td>986.360000</td>\n",
       "      <td>2179.583200</td>\n",
       "      <td>2235.606000</td>\n",
       "      <td>2327.368000</td>\n",
       "      <td>873.556000</td>\n",
       "      <td>865.608800</td>\n",
       "      <td>851.514000</td>\n",
       "      <td>780.900700</td>\n",
       "      <td>793.058000</td>\n",
       "      <td>778.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3651.000000</td>\n",
       "      <td>1226.659800</td>\n",
       "      <td>1254.279000</td>\n",
       "      <td>1188.26780</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69998.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27731.088000</td>\n",
       "      <td>35145.834000</td>\n",
       "      <td>33543.624000</td>\n",
       "      <td>7376.710000</td>\n",
       "      <td>8157.780000</td>\n",
       "      <td>10752.560000</td>\n",
       "      <td>8362.360000</td>\n",
       "      <td>7043.980000</td>\n",
       "      <td>14007.340000</td>\n",
       "      <td>2850.980000</td>\n",
       "      <td>4155.830000</td>\n",
       "      <td>4169.810000</td>\n",
       "      <td>3775.110000</td>\n",
       "      <td>2812.040000</td>\n",
       "      <td>5337.040000</td>\n",
       "      <td>6431.330000</td>\n",
       "      <td>7400.660000</td>\n",
       "      <td>10752.560000</td>\n",
       "      <td>4696.830000</td>\n",
       "      <td>4557.140000</td>\n",
       "      <td>4961.330000</td>\n",
       "      <td>617.580000</td>\n",
       "      <td>815.330000</td>\n",
       "      <td>588.290000</td>\n",
       "      <td>342.860000</td>\n",
       "      <td>916.240000</td>\n",
       "      <td>351.830000</td>\n",
       "      <td>10643.380000</td>\n",
       "      <td>7674.780000</td>\n",
       "      <td>11039.910000</td>\n",
       "      <td>7366.580000</td>\n",
       "      <td>8133.660000</td>\n",
       "      <td>8014.430000</td>\n",
       "      <td>8314.760000</td>\n",
       "      <td>6622.540000</td>\n",
       "      <td>13950.040000</td>\n",
       "      <td>628.560000</td>\n",
       "      <td>465.790000</td>\n",
       "      <td>354.160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8432.990000</td>\n",
       "      <td>8155.530000</td>\n",
       "      <td>13980.060000</td>\n",
       "      <td>5900.660000</td>\n",
       "      <td>5490.280000</td>\n",
       "      <td>5681.540000</td>\n",
       "      <td>1023.210000</td>\n",
       "      <td>2372.510000</td>\n",
       "      <td>1075.080000</td>\n",
       "      <td>800.890000</td>\n",
       "      <td>270.240000</td>\n",
       "      <td>394.930000</td>\n",
       "      <td>10674.030000</td>\n",
       "      <td>8285.640000</td>\n",
       "      <td>14043.060000</td>\n",
       "      <td>5315.590000</td>\n",
       "      <td>9324.660000</td>\n",
       "      <td>10696.230000</td>\n",
       "      <td>4450.740000</td>\n",
       "      <td>4455.830000</td>\n",
       "      <td>6274.190000</td>\n",
       "      <td>1872.340000</td>\n",
       "      <td>1983.010000</td>\n",
       "      <td>1676.580000</td>\n",
       "      <td>7454.630000</td>\n",
       "      <td>9669.910000</td>\n",
       "      <td>10830.160000</td>\n",
       "      <td>3336.380000</td>\n",
       "      <td>4708.710000</td>\n",
       "      <td>3930.240000</td>\n",
       "      <td>5647.160000</td>\n",
       "      <td>6141.880000</td>\n",
       "      <td>5512.760000</td>\n",
       "      <td>1351.110000</td>\n",
       "      <td>1136.080000</td>\n",
       "      <td>1394.890000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5712.110000</td>\n",
       "      <td>6745.760000</td>\n",
       "      <td>5658.740000</td>\n",
       "      <td>7716.140000</td>\n",
       "      <td>9699.010000</td>\n",
       "      <td>10830.380000</td>\n",
       "      <td>19.760000</td>\n",
       "      <td>13.460000</td>\n",
       "      <td>16.860000</td>\n",
       "      <td>6789.410000</td>\n",
       "      <td>5289.540000</td>\n",
       "      <td>4127.010000</td>\n",
       "      <td>1362.940000</td>\n",
       "      <td>1495.940000</td>\n",
       "      <td>1209.860000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>35190.000000</td>\n",
       "      <td>40335.000000</td>\n",
       "      <td>45320.000000</td>\n",
       "      <td>4010.000000</td>\n",
       "      <td>3299.000000</td>\n",
       "      <td>4449.000000</td>\n",
       "      <td>4010.000000</td>\n",
       "      <td>3100.000000</td>\n",
       "      <td>4449.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>5920.000000</td>\n",
       "      <td>4365.000000</td>\n",
       "      <td>4076.000000</td>\n",
       "      <td>10285.900000</td>\n",
       "      <td>7873.550000</td>\n",
       "      <td>11117.610000</td>\n",
       "      <td>45735.400000</td>\n",
       "      <td>28144.120000</td>\n",
       "      <td>30036.060000</td>\n",
       "      <td>5054.370000</td>\n",
       "      <td>4980.900000</td>\n",
       "      <td>3716.900000</td>\n",
       "      <td>5054.350000</td>\n",
       "      <td>4809.360000</td>\n",
       "      <td>3483.170000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4337.000000</td>\n",
       "      <td>12916.220000</td>\n",
       "      <td>9165.600000</td>\n",
       "      <td>11166.21000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  \\\n",
       "count  69999.000000    69999.0         69297.0         69297.0   \n",
       "mean   34999.000000      109.0             0.0             0.0   \n",
       "std    20207.115084        0.0             0.0             0.0   \n",
       "min        0.000000      109.0             0.0             0.0   \n",
       "25%    17499.500000      109.0             0.0             0.0   \n",
       "50%    34999.000000      109.0             0.0             0.0   \n",
       "75%    52498.500000      109.0             0.0             0.0   \n",
       "90%    62998.200000      109.0             0.0             0.0   \n",
       "95%    66498.100000      109.0             0.0             0.0   \n",
       "99%    69298.020000      109.0             0.0             0.0   \n",
       "max    69998.000000      109.0             0.0             0.0   \n",
       "\n",
       "       loc_ic_t2o_mou        arpu_6        arpu_7        arpu_8   onnet_mou_6  \\\n",
       "count         69297.0  69999.000000  69999.000000  69999.000000  67231.000000   \n",
       "mean              0.0    283.134365    278.185912    278.858826    133.153275   \n",
       "std               0.0    334.213918    344.366927    351.924315    299.963093   \n",
       "min               0.0  -2258.709000  -1289.715000   -945.808000      0.000000   \n",
       "25%               0.0     93.581000     86.714000     84.095000      7.410000   \n",
       "50%               0.0    197.484000    191.588000    192.234000     34.110000   \n",
       "75%               0.0    370.791000    365.369500    369.909000    119.390000   \n",
       "90%               0.0    619.993800    615.661400    614.994600    345.080000   \n",
       "95%               0.0    832.022700    823.236700    828.464700    617.185000   \n",
       "99%               0.0   1400.276640   1414.891380   1445.054800   1447.098000   \n",
       "max               0.0  27731.088000  35145.834000  33543.624000   7376.710000   \n",
       "\n",
       "        onnet_mou_7   onnet_mou_8  offnet_mou_6  offnet_mou_7  offnet_mou_8  \\\n",
       "count  67312.000000  66296.000000  67231.000000  67312.000000  66296.000000   \n",
       "mean     133.894438    132.978257    198.874771    197.153383    196.543577   \n",
       "std      311.277193    311.896596    316.818355    322.482226    324.089234   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        6.675000      6.410000     34.860000     32.240000     31.575000   \n",
       "50%       32.280000     32.100000     96.480000     91.885000     91.800000   \n",
       "75%      115.837500    115.060000    232.990000    227.630000    229.345000   \n",
       "90%      347.908000    343.695000    482.030000    482.071000    486.980000   \n",
       "95%      628.437500    620.240000    735.985000    747.558000    738.017500   \n",
       "99%     1478.540900   1472.480500   1546.471000   1545.104000   1522.474000   \n",
       "max     8157.780000  10752.560000   8362.360000   7043.980000  14007.340000   \n",
       "\n",
       "       roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  roam_og_mou_6  \\\n",
       "count   67231.000000   67312.000000   66296.000000   67231.000000   \n",
       "mean        9.765435       7.014568       7.004892      14.186457   \n",
       "std        57.374429      55.960985      53.408135      73.469261   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "90%        11.950000       5.039000       5.210000      22.710000   \n",
       "95%        41.350000      23.199000      23.990000      69.455000   \n",
       "99%       219.649000     153.006700     159.714000     290.851000   \n",
       "max      2850.980000    4155.830000    4169.810000    3775.110000   \n",
       "\n",
       "       roam_og_mou_7  roam_og_mou_8  loc_og_t2t_mou_6  loc_og_t2t_mou_7  \\\n",
       "count   67312.000000   66296.000000      67231.000000      67312.000000   \n",
       "mean        9.842191       9.771783         46.904854         46.166503   \n",
       "std        58.511894      64.618388        150.971758        154.739002   \n",
       "min         0.000000       0.000000          0.000000          0.000000   \n",
       "25%         0.000000       0.000000          1.660000          1.650000   \n",
       "50%         0.000000       0.000000         11.910000         11.580000   \n",
       "75%         0.000000       0.000000         40.740000         39.760000   \n",
       "90%         9.900000       9.270000        104.510000        101.039000   \n",
       "95%        42.599000      42.110000        176.635000        174.299000   \n",
       "99%       221.866800     213.816500        548.148000        530.900600   \n",
       "max      2812.040000    5337.040000       6431.330000       7400.660000   \n",
       "\n",
       "       loc_og_t2t_mou_8  loc_og_t2m_mou_6  loc_og_t2m_mou_7  loc_og_t2m_mou_8  \\\n",
       "count      66296.000000      67231.000000      67312.000000      66296.000000   \n",
       "mean          45.686109         93.238231         90.799240         91.121447   \n",
       "std          153.716880        162.046699        153.852597        152.997805   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            1.610000          9.920000         10.090000          9.830000   \n",
       "50%           11.740000         41.030000         40.170000         40.350000   \n",
       "75%           39.895000        110.430000        107.540000        109.245000   \n",
       "90%          101.385000        233.640000        228.207000        230.930000   \n",
       "95%          174.630000        355.220000        348.440000        347.700000   \n",
       "99%          526.527500        744.779000        723.735800        733.398500   \n",
       "max        10752.560000       4696.830000       4557.140000       4961.330000   \n",
       "\n",
       "       loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  loc_og_t2c_mou_6  \\\n",
       "count      67231.000000      67312.000000      66296.000000      67231.000000   \n",
       "mean           3.743179          3.777031          3.661652          1.126025   \n",
       "std           13.319542         13.568110         13.009193          5.741811   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          0.000000   \n",
       "50%            0.000000          0.000000          0.000000          0.000000   \n",
       "75%            2.060000          2.080000          2.030000          0.000000   \n",
       "90%            9.530000          9.590000          9.270000          2.430000   \n",
       "95%           18.750000         19.019000         18.280000          6.360000   \n",
       "99%           54.515000         55.754500         54.884000         20.287000   \n",
       "max          617.580000        815.330000        588.290000        342.860000   \n",
       "\n",
       "       loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_mou_6  loc_og_mou_7  \\\n",
       "count      67312.000000      66296.000000  67231.000000  67312.000000   \n",
       "mean           1.361052          1.420840    143.893585    140.750120   \n",
       "std            7.914113          6.542202    252.034597    246.313148   \n",
       "min            0.000000          0.000000      0.000000      0.000000   \n",
       "25%            0.000000          0.000000     17.235000     17.590000   \n",
       "50%            0.000000          0.000000     65.190000     63.430000   \n",
       "75%            0.000000          0.000000    167.880000    163.932500   \n",
       "90%            3.030000          3.410000    356.090000    345.721000   \n",
       "95%            7.354500          7.852500    538.985000    530.052500   \n",
       "99%           23.606700         24.342500   1154.437000   1130.439500   \n",
       "max          916.240000        351.830000  10643.380000   7674.780000   \n",
       "\n",
       "       loc_og_mou_8  std_og_t2t_mou_6  std_og_t2t_mou_7  std_og_t2t_mou_8  \\\n",
       "count  66296.000000      67231.000000      67312.000000      66296.000000   \n",
       "mean     140.476486         80.619382         83.775851         83.471486   \n",
       "std      245.342359        255.098355        266.693254        267.021929   \n",
       "min        0.000000          0.000000          0.000000          0.000000   \n",
       "25%       17.237500          0.000000          0.000000          0.000000   \n",
       "50%       63.520000          0.000000          0.000000          0.000000   \n",
       "75%      165.615000         31.020000         31.300000         30.760000   \n",
       "90%      347.920000        217.060000        226.337000        226.010000   \n",
       "95%      528.757500        465.765000        496.777500        491.360000   \n",
       "99%     1108.476500       1232.315000       1281.418500       1283.875000   \n",
       "max    11039.910000       7366.580000       8133.660000       8014.430000   \n",
       "\n",
       "       std_og_t2m_mou_6  std_og_t2m_mou_7  std_og_t2m_mou_8  std_og_t2f_mou_6  \\\n",
       "count      67231.000000      67312.000000      66296.000000      67231.000000   \n",
       "mean          88.152110         91.538615         90.586999          1.126377   \n",
       "std          255.771554        267.532089        270.032002          8.136645   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          0.000000   \n",
       "50%            3.980000          3.710000          3.300000          0.000000   \n",
       "75%           53.745000         54.640000         52.660000          0.000000   \n",
       "90%          237.490000        247.229000        248.950000          0.660000   \n",
       "95%          462.825000        486.712500        486.945000          4.310000   \n",
       "99%         1250.527000       1275.198200       1235.259500         25.530000   \n",
       "max         8314.760000       6622.540000      13950.040000        628.560000   \n",
       "\n",
       "       std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2c_mou_6  std_og_t2c_mou_7  \\\n",
       "count      67312.000000      66296.000000           67231.0           67312.0   \n",
       "mean           1.084062          1.057739               0.0               0.0   \n",
       "std            8.325206          7.696853               0.0               0.0   \n",
       "min            0.000000          0.000000               0.0               0.0   \n",
       "25%            0.000000          0.000000               0.0               0.0   \n",
       "50%            0.000000          0.000000               0.0               0.0   \n",
       "75%            0.000000          0.000000               0.0               0.0   \n",
       "90%            0.460000          0.460000               0.0               0.0   \n",
       "95%            3.880000          3.900000               0.0               0.0   \n",
       "99%           24.504500         23.950500               0.0               0.0   \n",
       "max          465.790000        354.160000               0.0               0.0   \n",
       "\n",
       "       std_og_t2c_mou_8  std_og_mou_6  std_og_mou_7  std_og_mou_8  \\\n",
       "count           66296.0  67231.000000  67312.000000  66296.000000   \n",
       "mean                0.0    169.900601    176.401217    175.118852   \n",
       "std                 0.0    392.046600    409.299501    410.697098   \n",
       "min                 0.0      0.000000      0.000000      0.000000   \n",
       "25%                 0.0      0.000000      0.000000      0.000000   \n",
       "50%                 0.0     11.730000     11.260000     10.505000   \n",
       "75%                 0.0    146.335000    151.645000    149.015000   \n",
       "90%                 0.0    531.240000    556.755000    553.760000   \n",
       "95%                 0.0    888.810000    924.753000    921.027500   \n",
       "99%                 0.0   1881.720000   1915.989900   1924.505000   \n",
       "max                 0.0   8432.990000   8155.530000  13980.060000   \n",
       "\n",
       "       isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  spl_og_mou_7  \\\n",
       "count  67231.000000  67312.000000  66296.000000  67231.000000  67312.000000   \n",
       "mean       0.845763      0.811100      0.841648      3.958619      4.976783   \n",
       "std       29.747486     29.220073     29.563367     15.854529     22.229842   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      2.400000      3.660000   \n",
       "90%        0.000000      0.000000      0.000000     10.660000     13.130000   \n",
       "95%        0.000000      0.000000      0.000000     19.560000     23.380000   \n",
       "99%        8.430000      8.424500      6.911000     51.403000     61.277800   \n",
       "max     5900.660000   5490.280000   5681.540000   1023.210000   2372.510000   \n",
       "\n",
       "       spl_og_mou_8   og_others_6   og_others_7   og_others_8  total_og_mou_6  \\\n",
       "count  66296.000000  67231.000000  67312.000000  66296.000000    69999.000000   \n",
       "mean       5.045027      0.462581      0.024425      0.033059      306.451436   \n",
       "std       17.708507      4.768437      1.716430      2.232547      465.502866   \n",
       "min        0.000000      0.000000      0.000000      0.000000        0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000       44.780000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      145.280000   \n",
       "75%        4.002500      0.000000      0.000000      0.000000      374.305000   \n",
       "90%       13.600000      1.280000      0.000000      0.000000      785.230000   \n",
       "95%       23.832500      2.710000      0.000000      0.000000     1171.188000   \n",
       "99%       60.500500      6.930000      0.000000      0.000000     2235.611000   \n",
       "max     1075.080000    800.890000    270.240000    394.930000    10674.030000   \n",
       "\n",
       "       total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  loc_ic_t2t_mou_7  \\\n",
       "count    69999.000000    69999.000000      67231.000000      67312.000000   \n",
       "mean       310.572674      304.513065         48.043255         47.882736   \n",
       "std        479.131770      477.936832        140.499757        147.761124   \n",
       "min          0.000000        0.000000          0.000000          0.000000   \n",
       "25%         42.910000       38.710000          3.030000          3.260000   \n",
       "50%        141.230000      138.360000         15.740000         15.830000   \n",
       "75%        380.045000      370.895000         46.980000         45.690000   \n",
       "90%        806.250000      792.858000        107.260000        105.589000   \n",
       "95%       1193.257000     1174.552000        174.410000        173.534500   \n",
       "99%       2275.607000     2242.854800        488.360000        486.412700   \n",
       "max       8285.640000    14043.060000       5315.590000       9324.660000   \n",
       "\n",
       "       loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  \\\n",
       "count      66296.000000      67231.000000      67312.000000      66296.000000   \n",
       "mean          47.256388        107.152439        106.489856        108.154731   \n",
       "std          141.249368        168.455999        165.452459        166.223461   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            3.280000         17.390000         18.610000         18.940000   \n",
       "50%           16.040000         56.460000         56.930000         58.210000   \n",
       "75%           46.280000        132.020000        131.010000        134.380000   \n",
       "90%          105.310000        254.290000        252.260000        255.160000   \n",
       "95%          171.177500        372.260000        365.808000        371.767500   \n",
       "99%          468.482500        760.310000        750.332500        764.276500   \n",
       "max        10696.230000       4450.740000       4455.830000       6274.190000   \n",
       "\n",
       "       loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  loc_ic_mou_6  \\\n",
       "count      67231.000000      67312.000000      66296.000000  67231.000000   \n",
       "mean          12.050672         12.563665         11.716763    167.255126   \n",
       "std           39.416076         43.495179         38.606895    252.576231   \n",
       "min            0.000000          0.000000          0.000000      0.000000   \n",
       "25%            0.000000          0.000000          0.000000     30.630000   \n",
       "50%            0.880000          0.910000          0.930000     92.430000   \n",
       "75%            8.140000          8.230000          8.090000    208.325000   \n",
       "90%           30.210000         30.410000         28.750000    392.610000   \n",
       "95%           57.060000         58.884500         55.617500    568.035000   \n",
       "99%          165.016000        173.836700        158.084000   1154.640000   \n",
       "max         1872.340000       1983.010000       1676.580000   7454.630000   \n",
       "\n",
       "       loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  std_ic_t2t_mou_7  \\\n",
       "count  67312.000000  66296.000000      67231.000000      67312.000000   \n",
       "mean     166.945103    167.136761          9.476958          9.873468   \n",
       "std      254.688718    249.288410         51.664472         56.137824   \n",
       "min        0.000000      0.000000          0.000000          0.000000   \n",
       "25%       32.710000     32.810000          0.000000          0.000000   \n",
       "50%       92.510000     93.890000          0.000000          0.000000   \n",
       "75%      205.530000    208.060000          4.060000          4.180000   \n",
       "90%      387.560000    389.410000         19.910000         20.680000   \n",
       "95%      562.325500    568.242500         40.900000         42.149000   \n",
       "99%     1169.551200   1144.103000        140.525000        150.930000   \n",
       "max     9669.910000  10830.160000       3336.380000       4708.710000   \n",
       "\n",
       "       std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  std_ic_t2m_mou_8  \\\n",
       "count      66296.000000      67231.000000      67312.000000      66296.000000   \n",
       "mean           9.910217         20.734858         21.685359         21.089042   \n",
       "std           54.248186         80.294236         87.314510         81.534344   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          0.000000   \n",
       "50%            0.000000          2.040000          2.060000          2.030000   \n",
       "75%            4.052500         14.960000         15.830000         15.310000   \n",
       "90%           20.480000         47.610000         49.810000         48.830000   \n",
       "95%           42.250000         86.815000         90.160000         88.545000   \n",
       "99%          152.297500        272.089000        282.568000        282.967500   \n",
       "max         3930.240000       5647.160000       6141.880000       5512.760000   \n",
       "\n",
       "       std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  std_ic_t2o_mou_6  \\\n",
       "count      67231.000000      67312.000000      66296.000000           67231.0   \n",
       "mean           2.146273          2.199395          2.075179               0.0   \n",
       "std           16.522232         16.171533         15.865403               0.0   \n",
       "min            0.000000          0.000000          0.000000               0.0   \n",
       "25%            0.000000          0.000000          0.000000               0.0   \n",
       "50%            0.000000          0.000000          0.000000               0.0   \n",
       "75%            0.000000          0.000000          0.000000               0.0   \n",
       "90%            2.710000          2.790000          2.780000               0.0   \n",
       "95%            8.480000          8.550000          8.310000               0.0   \n",
       "99%           40.731000         42.486700         38.730500               0.0   \n",
       "max         1351.110000       1136.080000       1394.890000               0.0   \n",
       "\n",
       "       std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_mou_6  std_ic_mou_7  \\\n",
       "count           67312.0           66296.0  67231.000000  67312.000000   \n",
       "mean                0.0               0.0     32.360632     33.760809   \n",
       "std                 0.0               0.0    104.381082    114.142230   \n",
       "min                 0.0               0.0      0.000000      0.000000   \n",
       "25%                 0.0               0.0      0.000000      0.000000   \n",
       "50%                 0.0               0.0      5.910000      5.980000   \n",
       "75%                 0.0               0.0     26.780000     28.160000   \n",
       "90%                 0.0               0.0     75.710000     77.939000   \n",
       "95%                 0.0               0.0    132.820000    138.566000   \n",
       "99%                 0.0               0.0    400.449000    419.468200   \n",
       "max                 0.0               0.0   5712.110000   6745.760000   \n",
       "\n",
       "       std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  total_ic_mou_8  \\\n",
       "count  66296.000000    69999.000000    69999.000000    69999.000000   \n",
       "mean      33.077030      199.710640      201.878029      198.486034   \n",
       "std      108.469864      290.114823      296.771338      288.336731   \n",
       "min        0.000000        0.000000        0.000000        0.000000   \n",
       "25%        0.030000       38.640000       41.340000       38.290000   \n",
       "50%        5.830000      114.780000      116.330000      114.610000   \n",
       "75%       27.615000      251.070000      249.470000      249.710000   \n",
       "90%       76.640000      467.030000      468.524000      464.508000   \n",
       "95%      136.515000      668.240000      676.904000      665.435000   \n",
       "99%      413.210000     1366.030000     1382.071400     1353.297000   \n",
       "max     5658.740000     7716.140000     9699.010000    10830.380000   \n",
       "\n",
       "       spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "count  67231.000000  67312.000000  66296.000000  67231.000000  67312.000000   \n",
       "mean       0.061932      0.033371      0.040392      7.394167      8.171162   \n",
       "std        0.164823      0.137322      0.148417     60.951165     63.604165   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "90%        0.260000      0.060000      0.130000      4.910000      6.590000   \n",
       "95%        0.410000      0.240000      0.310000     24.375000     28.140000   \n",
       "99%        0.660000      0.640000      0.700000    165.436000    174.872300   \n",
       "max       19.760000     13.460000     16.860000   6789.410000   5289.540000   \n",
       "\n",
       "       isd_ic_mou_8   ic_others_6   ic_others_7   ic_others_8  \\\n",
       "count  66296.000000  67231.000000  67312.000000  66296.000000   \n",
       "mean       8.348424      0.854063      1.019680      0.963214   \n",
       "std       63.097570     12.149144     13.225373     11.697686   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000   \n",
       "90%        6.400000      0.610000      0.780000      0.750000   \n",
       "95%       29.980000      2.110000      2.619000      2.430000   \n",
       "99%      176.070000     14.887000     16.627800     16.463500   \n",
       "max     4127.010000   1362.940000   1495.940000   1209.860000   \n",
       "\n",
       "       total_rech_num_6  total_rech_num_7  total_rech_num_8  total_rech_amt_6  \\\n",
       "count      69999.000000      69999.000000      69999.000000      69999.000000   \n",
       "mean           7.566522          7.706667          7.224932        328.139788   \n",
       "std            7.041452          7.050614          7.195597        404.211068   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            3.000000          3.000000          3.000000        110.000000   \n",
       "50%            6.000000          6.000000          5.000000        229.000000   \n",
       "75%            9.000000         10.000000          9.000000        438.000000   \n",
       "90%           15.000000         15.000000         15.000000        735.000000   \n",
       "95%           20.000000         21.000000         20.000000        998.000000   \n",
       "99%           35.000000         35.000000         35.000000       1683.020000   \n",
       "max          170.000000        138.000000        138.000000      35190.000000   \n",
       "\n",
       "       total_rech_amt_7  total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  \\\n",
       "count      69999.000000      69999.000000    69999.000000    69999.000000   \n",
       "mean         322.376363        323.846355      104.569265      104.137573   \n",
       "std          411.070120        426.181405      121.407701      120.782543   \n",
       "min            0.000000          0.000000        0.000000        0.000000   \n",
       "25%          100.000000         90.000000       30.000000       30.000000   \n",
       "50%          220.000000        225.000000      110.000000      110.000000   \n",
       "75%          430.000000        436.000000      120.000000      128.000000   \n",
       "90%          730.000000        734.000000      200.000000      200.000000   \n",
       "95%          986.100000        988.000000      252.000000      252.000000   \n",
       "99%         1712.000000       1706.020000      550.000000      550.000000   \n",
       "max        40335.000000      45320.000000     4010.000000     3299.000000   \n",
       "\n",
       "       max_rech_amt_8  last_day_rch_amt_6  last_day_rch_amt_7  \\\n",
       "count    69999.000000        69999.000000        69999.000000   \n",
       "mean       107.540351           63.426949           59.294218   \n",
       "std        124.396750           97.954876           95.429492   \n",
       "min          0.000000            0.000000            0.000000   \n",
       "25%         30.000000            0.000000            0.000000   \n",
       "50%         98.000000           30.000000           30.000000   \n",
       "75%        144.000000          110.000000          110.000000   \n",
       "90%        225.000000          128.000000          130.000000   \n",
       "95%        252.000000          200.000000          200.000000   \n",
       "99%        550.000000          400.000000          398.000000   \n",
       "max       4449.000000         4010.000000         3100.000000   \n",
       "\n",
       "       last_day_rch_amt_8  total_rech_data_6  total_rech_data_7  \\\n",
       "count        69999.000000       17568.000000       17865.000000   \n",
       "mean            62.489478           2.467612           2.679989   \n",
       "std            101.996729           2.794610           3.073472   \n",
       "min              0.000000           1.000000           1.000000   \n",
       "25%              0.000000           1.000000           1.000000   \n",
       "50%             30.000000           1.000000           2.000000   \n",
       "75%            130.000000           3.000000           3.000000   \n",
       "90%            150.000000           5.000000           6.000000   \n",
       "95%            225.000000           8.000000           9.000000   \n",
       "99%            455.000000          14.000000          14.000000   \n",
       "max           4449.000000          61.000000          54.000000   \n",
       "\n",
       "       total_rech_data_8  max_rech_data_6  max_rech_data_7  max_rech_data_8  \\\n",
       "count       18417.000000     17568.000000     17865.000000     18417.000000   \n",
       "mean            2.652441       126.500000       126.402071       125.374925   \n",
       "std             3.101265       109.352573       109.459266       109.648799   \n",
       "min             1.000000         1.000000         1.000000         1.000000   \n",
       "25%             1.000000        25.000000        25.000000        25.000000   \n",
       "50%             1.000000       145.000000       145.000000       145.000000   \n",
       "75%             3.000000       177.000000       177.000000       179.000000   \n",
       "90%             6.000000       252.000000       252.000000       252.000000   \n",
       "95%             8.000000       252.000000       252.000000       252.000000   \n",
       "99%            14.000000       498.300000       455.000000       455.000000   \n",
       "max            60.000000      1555.000000      1555.000000      1555.000000   \n",
       "\n",
       "       count_rech_2g_6  count_rech_2g_7  count_rech_2g_8  count_rech_3g_6  \\\n",
       "count     17568.000000     17865.000000     18417.000000     17568.000000   \n",
       "mean          1.865323         2.056311         2.016018         0.602288   \n",
       "std           2.566377         2.799916         2.728246         1.279297   \n",
       "min           0.000000         0.000000         0.000000         0.000000   \n",
       "25%           1.000000         1.000000         1.000000         0.000000   \n",
       "50%           1.000000         1.000000         1.000000         0.000000   \n",
       "75%           2.000000         2.000000         2.000000         1.000000   \n",
       "90%           5.000000         5.000000         5.000000         2.000000   \n",
       "95%           7.000000         8.000000         8.000000         2.000000   \n",
       "99%          12.000000        13.000000        13.000000         6.000000   \n",
       "max          42.000000        48.000000        44.000000        29.000000   \n",
       "\n",
       "       count_rech_3g_7  count_rech_3g_8  av_rech_amt_data_6  \\\n",
       "count     17865.000000     18417.000000        17568.000000   \n",
       "mean          0.623678         0.636423          192.831096   \n",
       "std           1.401230         1.457058          190.623115   \n",
       "min           0.000000         0.000000            1.000000   \n",
       "25%           0.000000         0.000000           82.000000   \n",
       "50%           0.000000         0.000000          154.000000   \n",
       "75%           1.000000         1.000000          252.000000   \n",
       "90%           2.000000         2.000000          353.300000   \n",
       "95%           2.000000         2.000000          504.000000   \n",
       "99%           6.000000         6.000000          910.000000   \n",
       "max          34.000000        45.000000         5920.000000   \n",
       "\n",
       "       av_rech_amt_data_7  av_rech_amt_data_8   vol_2g_mb_6   vol_2g_mb_7  \\\n",
       "count        17865.000000        18417.000000  69999.000000  69999.000000   \n",
       "mean           201.455940          196.815792     51.773924     51.240204   \n",
       "std            198.346141          192.280532    212.513909    211.114667   \n",
       "min              1.000000            1.000000      0.000000      0.000000   \n",
       "25%             92.000000           84.000000      0.000000      0.000000   \n",
       "50%            154.000000          154.000000      0.000000      0.000000   \n",
       "75%            252.000000          252.000000      0.000000      0.000000   \n",
       "90%            394.000000          392.000000    103.514000     97.410000   \n",
       "95%            504.000000          504.000000    327.241000    318.672000   \n",
       "99%            951.000000          951.000000    995.815200    999.260200   \n",
       "max           4365.000000         4076.000000  10285.900000   7873.550000   \n",
       "\n",
       "        vol_2g_mb_8   vol_3g_mb_6   vol_3g_mb_7   vol_3g_mb_8     arpu_3g_6  \\\n",
       "count  69999.000000  69999.000000  69999.000000  69999.000000  17568.000000   \n",
       "mean      50.127506    122.171882    128.934444    135.486541     90.069931   \n",
       "std      213.101403    554.869965    554.096072    568.310234    193.600413   \n",
       "min        0.000000      0.000000      0.000000      0.000000    -20.380000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.520000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000    122.070000   \n",
       "90%       93.290000    302.810000    335.372000    372.540000    246.159000   \n",
       "95%      302.284000    831.189000    866.464000    899.073000    424.806500   \n",
       "99%      986.360000   2179.583200   2235.606000   2327.368000    873.556000   \n",
       "max    11117.610000  45735.400000  28144.120000  30036.060000   5054.370000   \n",
       "\n",
       "          arpu_3g_7     arpu_3g_8     arpu_2g_6     arpu_2g_7     arpu_2g_8  \\\n",
       "count  17865.000000  18417.000000  17568.000000  17865.000000  18417.000000   \n",
       "mean      89.115767     90.618564     86.863900     85.846074     86.348404   \n",
       "std      195.826990    189.907986    171.321203    178.067280    170.297094   \n",
       "min      -26.040000    -24.490000    -35.830000    -13.090000    -55.830000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.420000      0.840000     11.300000      8.800000      9.090000   \n",
       "75%      120.860000    122.070000    122.070000    122.070000    122.070000   \n",
       "90%      244.140000    248.556000    223.773000    220.036000    224.000000   \n",
       "95%      427.222000    424.498000    420.826000    423.174000    411.958000   \n",
       "99%      865.608800    851.514000    780.900700    793.058000    778.000000   \n",
       "max     4980.900000   3716.900000   5054.350000   4809.360000   3483.170000   \n",
       "\n",
       "       night_pck_user_6  night_pck_user_7  night_pck_user_8  monthly_2g_6  \\\n",
       "count      17568.000000      17865.000000      18417.000000  69999.000000   \n",
       "mean           0.025273          0.024069          0.021013      0.079287   \n",
       "std            0.156958          0.153269          0.143432      0.294719   \n",
       "min            0.000000          0.000000          0.000000      0.000000   \n",
       "25%            0.000000          0.000000          0.000000      0.000000   \n",
       "50%            0.000000          0.000000          0.000000      0.000000   \n",
       "75%            0.000000          0.000000          0.000000      0.000000   \n",
       "90%            0.000000          0.000000          0.000000      0.000000   \n",
       "95%            0.000000          0.000000          0.000000      1.000000   \n",
       "99%            1.000000          1.000000          1.000000      1.000000   \n",
       "max            1.000000          1.000000          1.000000      4.000000   \n",
       "\n",
       "       monthly_2g_7  monthly_2g_8   sachet_2g_6   sachet_2g_7   sachet_2g_8  \\\n",
       "count  69999.000000  69999.000000  69999.000000  69999.000000  69999.000000   \n",
       "mean       0.083401      0.080930      0.388863      0.441406      0.449492   \n",
       "std        0.304802      0.299254      1.494206      1.651012      1.632450   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "90%        0.000000      0.000000      1.000000      1.000000      1.000000   \n",
       "95%        1.000000      1.000000      2.000000      3.000000      3.000000   \n",
       "99%        1.000000      1.000000      8.000000      9.000000      8.000000   \n",
       "max        5.000000      5.000000     42.000000     48.000000     44.000000   \n",
       "\n",
       "       monthly_3g_6  monthly_3g_7  monthly_3g_8   sachet_3g_6   sachet_3g_7  \\\n",
       "count  69999.000000  69999.000000  69999.000000  69999.000000  69999.000000   \n",
       "mean       0.075815      0.077730      0.081958      0.075344      0.081444   \n",
       "std        0.358905      0.383189      0.381821      0.573003      0.634547   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "90%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "95%        1.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "99%        2.000000      2.000000      2.000000      2.000000      2.000000   \n",
       "max        9.000000     16.000000     16.000000     29.000000     33.000000   \n",
       "\n",
       "        sachet_3g_8     fb_user_6     fb_user_7     fb_user_8           aon  \\\n",
       "count  69999.000000  17568.000000  17865.000000  18417.000000  69999.000000   \n",
       "mean       0.085487      0.916325      0.909544      0.890319   1220.639709   \n",
       "std        0.680035      0.276907      0.286842      0.312501    952.426321   \n",
       "min        0.000000      0.000000      0.000000      0.000000    180.000000   \n",
       "25%        0.000000      1.000000      1.000000      1.000000    468.000000   \n",
       "50%        0.000000      1.000000      1.000000      1.000000    868.000000   \n",
       "75%        0.000000      1.000000      1.000000      1.000000   1813.000000   \n",
       "90%        0.000000      1.000000      1.000000      1.000000   2792.000000   \n",
       "95%        0.000000      1.000000      1.000000      1.000000   3108.000000   \n",
       "99%        2.000000      1.000000      1.000000      1.000000   3651.000000   \n",
       "max       41.000000      1.000000      1.000000      1.000000   4337.000000   \n",
       "\n",
       "         aug_vbc_3g    jul_vbc_3g   jun_vbc_3g  churn_probability  \n",
       "count  69999.000000  69999.000000  69999.00000       69999.000000  \n",
       "mean      68.108597     65.935830     60.07674           0.101887  \n",
       "std      269.328659    267.899034    257.22681           0.302502  \n",
       "min        0.000000      0.000000      0.00000           0.000000  \n",
       "25%        0.000000      0.000000      0.00000           0.000000  \n",
       "50%        0.000000      0.000000      0.00000           0.000000  \n",
       "75%        0.000000      0.000000      0.00000           0.000000  \n",
       "90%      160.444000    136.272000    110.32800           1.000000  \n",
       "95%      464.277000    446.353000    400.13400           1.000000  \n",
       "99%     1226.659800   1254.279000   1188.26780           1.000000  \n",
       "max    12916.220000   9165.600000  11166.21000           1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(percentiles=[.25,.5,.75,.90,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b55f49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    89.811283\n",
       "1    10.188717\n",
       "Name: churn_probability, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Classes Distribution\n",
    "data['churn_probability'].value_counts()/data.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adfb4dc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:16:41.095411Z",
     "iopub.status.busy": "2021-08-13T07:16:41.094812Z",
     "iopub.status.idle": "2021-08-13T07:16:41.123189Z",
     "shell.execute_reply": "2021-08-13T07:16:41.122683Z"
    },
    "papermill": {
     "duration": 0.067353,
     "end_time": "2021-08-13T07:16:41.123346",
     "exception": false,
     "start_time": "2021-08-13T07:16:41.055993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acronyms</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIRCLE_ID</td>\n",
       "      <td>Telecom circle area to which the customer belo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Local calls  within same telecom circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STD</td>\n",
       "      <td>STD calls  outside the calling circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IC</td>\n",
       "      <td>Incoming calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OG</td>\n",
       "      <td>Outgoing calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T2T</td>\n",
       "      <td>Operator T to T ie within same operator mobile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T2M</td>\n",
       "      <td>Operator T to other operator mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T2O</td>\n",
       "      <td>Operator T to other operator fixed line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T2F</td>\n",
       "      <td>Operator T to fixed lines of T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T2C</td>\n",
       "      <td>Operator T to its own call center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ARPU</td>\n",
       "      <td>Average revenue per user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MOU</td>\n",
       "      <td>Minutes of usage  voice calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AON</td>\n",
       "      <td>Age on network  number of days the customer is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ONNET</td>\n",
       "      <td>All kind of calls within the same operator net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OFFNET</td>\n",
       "      <td>All kind of calls outside the operator T network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ROAM</td>\n",
       "      <td>Indicates that customer is in roaming zone dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SPL</td>\n",
       "      <td>Special calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ISD</td>\n",
       "      <td>ISD calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RECH</td>\n",
       "      <td>Recharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NUM</td>\n",
       "      <td>Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AMT</td>\n",
       "      <td>Amount in local currency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MAX</td>\n",
       "      <td>Maximum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Mobile internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3G</td>\n",
       "      <td>G network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AV</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>VOL</td>\n",
       "      <td>Mobile internet usage volume in MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2G</td>\n",
       "      <td>G network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PCK</td>\n",
       "      <td>Prepaid service schemes called  PACKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NIGHT</td>\n",
       "      <td>Scheme to use during specific night hours only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MONTHLY</td>\n",
       "      <td>Service schemes with validity equivalent to a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SACHET</td>\n",
       "      <td>Service schemes with validity smaller than a m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>*.6</td>\n",
       "      <td>KPI for the month of June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>*.7</td>\n",
       "      <td>KPI for the month of July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>*.8</td>\n",
       "      <td>KPI for the month of August</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>FB_USER</td>\n",
       "      <td>Service scheme to avail services of Facebook a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>VBC</td>\n",
       "      <td>Volume based cost  when no specific scheme is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Acronyms                                        Description\n",
       "0     CIRCLE_ID  Telecom circle area to which the customer belo...\n",
       "1           LOC            Local calls  within same telecom circle\n",
       "2           STD              STD calls  outside the calling circle\n",
       "3            IC                                     Incoming calls\n",
       "4            OG                                     Outgoing calls\n",
       "5           T2T  Operator T to T ie within same operator mobile...\n",
       "6       T2M                    Operator T to other operator mobile\n",
       "7       T2O                Operator T to other operator fixed line\n",
       "8       T2F                         Operator T to fixed lines of T\n",
       "9       T2C                      Operator T to its own call center\n",
       "10     ARPU                               Average revenue per user\n",
       "11      MOU                          Minutes of usage  voice calls\n",
       "12      AON      Age on network  number of days the customer is...\n",
       "13     ONNET     All kind of calls within the same operator net...\n",
       "14   OFFNET       All kind of calls outside the operator T network\n",
       "15         ROAM  Indicates that customer is in roaming zone dur...\n",
       "16       SPL                                         Special calls\n",
       "17      ISD                                              ISD calls\n",
       "18     RECH                                               Recharge\n",
       "19      NUM                                                 Number\n",
       "20      AMT                               Amount in local currency\n",
       "21      MAX                                                Maximum\n",
       "22     DATA                                        Mobile internet\n",
       "23       3G                                              G network\n",
       "24       AV                                                Average\n",
       "25      VOL                     Mobile internet usage volume in MB\n",
       "26       2G                                              G network\n",
       "27      PCK                  Prepaid service schemes called  PACKS\n",
       "28    NIGHT         Scheme to use during specific night hours only\n",
       "29  MONTHLY      Service schemes with validity equivalent to a ...\n",
       "30    SACHET     Service schemes with validity smaller than a m...\n",
       "31      *.6                              KPI for the month of June\n",
       "32      *.7                              KPI for the month of July\n",
       "33      *.8                            KPI for the month of August\n",
       "34      FB_USER  Service scheme to avail services of Facebook a...\n",
       "35      VBC      Volume based cost  when no specific scheme is ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To have a view on data dict\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "474e850b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>31.277</td>\n",
       "      <td>87.009</td>\n",
       "      <td>7.527</td>\n",
       "      <td>48.58</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.29</td>\n",
       "      <td>32.24</td>\n",
       "      <td>96.68</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.29</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.53</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.61</td>\n",
       "      <td>46.34</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.01</td>\n",
       "      <td>18.75</td>\n",
       "      <td>80.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.09</td>\n",
       "      <td>204.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.21</td>\n",
       "      <td>221.68</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.68</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.83</td>\n",
       "      <td>21.08</td>\n",
       "      <td>16.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>24.76</td>\n",
       "      <td>24.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>7.46</td>\n",
       "      <td>19.96</td>\n",
       "      <td>14.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.46</td>\n",
       "      <td>27.58</td>\n",
       "      <td>15.18</td>\n",
       "      <td>11.84</td>\n",
       "      <td>53.04</td>\n",
       "      <td>40.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>6/22/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>122.787</td>\n",
       "      <td>42.953</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.99</td>\n",
       "      <td>30.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.01</td>\n",
       "      <td>29.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>1.68</td>\n",
       "      <td>19.09</td>\n",
       "      <td>10.53</td>\n",
       "      <td>1.41</td>\n",
       "      <td>18.68</td>\n",
       "      <td>11.09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.44</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.44</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>6/12/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/8/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>352.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>60.806</td>\n",
       "      <td>103.176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.53</td>\n",
       "      <td>15.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.99</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.64</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.94</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.94</td>\n",
       "      <td>84.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.49</td>\n",
       "      <td>99.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.51</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.49</td>\n",
       "      <td>89.86</td>\n",
       "      <td>25.18</td>\n",
       "      <td>23.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.38</td>\n",
       "      <td>31.34</td>\n",
       "      <td>30.01</td>\n",
       "      <td>11.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.21</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.38</td>\n",
       "      <td>124.29</td>\n",
       "      <td>33.83</td>\n",
       "      <td>36.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>6/11/2014</td>\n",
       "      <td>7/22/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>156.362</td>\n",
       "      <td>205.260</td>\n",
       "      <td>111.095</td>\n",
       "      <td>7.26</td>\n",
       "      <td>16.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.76</td>\n",
       "      <td>78.48</td>\n",
       "      <td>50.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>6.99</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.91</td>\n",
       "      <td>44.89</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.03</td>\n",
       "      <td>44.91</td>\n",
       "      <td>48.84</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.26</td>\n",
       "      <td>12.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.33</td>\n",
       "      <td>25.93</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.16</td>\n",
       "      <td>37.99</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>9.13</td>\n",
       "      <td>25.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.03</td>\n",
       "      <td>95.98</td>\n",
       "      <td>53.84</td>\n",
       "      <td>24.98</td>\n",
       "      <td>4.84</td>\n",
       "      <td>23.88</td>\n",
       "      <td>53.99</td>\n",
       "      <td>44.23</td>\n",
       "      <td>57.14</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86.21</td>\n",
       "      <td>49.89</td>\n",
       "      <td>81.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>95.11</td>\n",
       "      <td>50.18</td>\n",
       "      <td>83.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>240</td>\n",
       "      <td>130</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>6/15/2014</td>\n",
       "      <td>7/21/2014</td>\n",
       "      <td>8/25/2014</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>240.708</td>\n",
       "      <td>128.191</td>\n",
       "      <td>101.565</td>\n",
       "      <td>21.28</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>56.99</td>\n",
       "      <td>38.11</td>\n",
       "      <td>9.63</td>\n",
       "      <td>53.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.16</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>36.74</td>\n",
       "      <td>19.88</td>\n",
       "      <td>4.61</td>\n",
       "      <td>11.99</td>\n",
       "      <td>1.23</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.91</td>\n",
       "      <td>25.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.26</td>\n",
       "      <td>42.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>5.44</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.66</td>\n",
       "      <td>10.58</td>\n",
       "      <td>4.33</td>\n",
       "      <td>19.49</td>\n",
       "      <td>5.51</td>\n",
       "      <td>3.63</td>\n",
       "      <td>6.14</td>\n",
       "      <td>21.54</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.54</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>290</td>\n",
       "      <td>136</td>\n",
       "      <td>122</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/26/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/23/2014</td>\n",
       "      <td>8/20/2014</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>390.8</td>\n",
       "      <td>308.89</td>\n",
       "      <td>213.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0   0        109             0.0             0.0             0.0   \n",
       "1   1        109             0.0             0.0             0.0   \n",
       "2   2        109             0.0             0.0             0.0   \n",
       "3   3        109             0.0             0.0             0.0   \n",
       "4   4        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8   arpu_6  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   31.277   \n",
       "1            6/30/2014            7/31/2014            8/31/2014    0.000   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   60.806   \n",
       "3            6/30/2014            7/31/2014            8/31/2014  156.362   \n",
       "4            6/30/2014            7/31/2014            8/31/2014  240.708   \n",
       "\n",
       "    arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  \\\n",
       "0   87.009    7.527        48.58       124.38         1.29         32.24   \n",
       "1  122.787   42.953         0.00         0.00         0.00          0.00   \n",
       "2  103.176    0.000         0.53        15.93         0.00         53.99   \n",
       "3  205.260  111.095         7.26        16.01         0.00         68.76   \n",
       "4  128.191  101.565        21.28         4.83         6.13         56.99   \n",
       "\n",
       "   offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "0         96.68          2.33           0.00            0.0            0.0   \n",
       "1         25.99         30.89           0.00            0.0            0.0   \n",
       "2         82.05          0.00           0.00            0.0            0.0   \n",
       "3         78.48         50.23           0.00            0.0            0.0   \n",
       "4         38.11          9.63          53.64            0.0            0.0   \n",
       "\n",
       "   roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  loc_og_t2t_mou_6  \\\n",
       "0           0.00            0.0           0.00              2.23   \n",
       "1           0.00            0.0           0.00              0.00   \n",
       "2           0.00            0.0           0.00              0.53   \n",
       "3           0.00            0.0           1.63              6.99   \n",
       "4          15.73            0.0           0.00             10.16   \n",
       "\n",
       "   loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  loc_og_t2m_mou_7  \\\n",
       "0              0.00              0.28              5.29             16.04   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2             12.98              0.00             24.11              0.00   \n",
       "3              3.94              0.00             37.91             44.89   \n",
       "4              4.83              6.13             36.74             19.88   \n",
       "\n",
       "   loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  \\\n",
       "0              2.33              0.00              0.00              0.00   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00              0.00              0.00   \n",
       "3             23.63              0.00              0.00              0.00   \n",
       "4              4.61             11.99              1.23              5.01   \n",
       "\n",
       "   loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_mou_6  \\\n",
       "0              0.00              0.00              0.00          7.53   \n",
       "1              0.00             22.01             29.79          0.00   \n",
       "2              2.14              0.00              0.00         24.64   \n",
       "3              0.00              0.00              8.03         44.91   \n",
       "4              0.00              9.85              0.00         58.91   \n",
       "\n",
       "   loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  std_og_t2t_mou_7  \\\n",
       "0         16.04          2.61             46.34            124.38   \n",
       "1          0.00          0.00              0.00              0.00   \n",
       "2         12.98          0.00              0.00              2.94   \n",
       "3         48.84         23.63              0.26             12.06   \n",
       "4         25.94         15.76              0.00              0.00   \n",
       "\n",
       "   std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  std_og_t2m_mou_8  \\\n",
       "0              1.01             18.75             80.61               0.0   \n",
       "1              0.00              0.00              0.00               0.0   \n",
       "2              0.00             28.94             82.05               0.0   \n",
       "3              0.00             15.33             25.93               4.6   \n",
       "4              0.00              4.35              0.00               0.0   \n",
       "\n",
       "   std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2c_mou_6  \\\n",
       "0              0.00               0.0               0.0               0.0   \n",
       "1              0.00               0.0               0.0               0.0   \n",
       "2              0.00               0.0               0.0               0.0   \n",
       "3              0.56               0.0               0.0               0.0   \n",
       "4              0.00               0.0               0.0               0.0   \n",
       "\n",
       "   std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_mou_6  std_og_mou_7  \\\n",
       "0               0.0               0.0         65.09        204.99   \n",
       "1               0.0               0.0          0.00          0.00   \n",
       "2               0.0               0.0         28.94         84.99   \n",
       "3               0.0               0.0         16.16         37.99   \n",
       "4               0.0               0.0          4.35          0.00   \n",
       "\n",
       "   std_og_mou_8  isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  \\\n",
       "0          1.01           0.0           0.0           0.0          8.20   \n",
       "1          0.00           0.0           0.0           0.0          0.00   \n",
       "2          0.00           0.0           0.0           0.0          2.89   \n",
       "3          4.60           0.0           0.0           0.0         14.95   \n",
       "4          0.00           0.0           0.0           0.0          0.00   \n",
       "\n",
       "   spl_og_mou_7  spl_og_mou_8  og_others_6  og_others_7  og_others_8  \\\n",
       "0          0.63          0.00         0.38          0.0          0.0   \n",
       "1         30.73         31.66         0.00          0.0          0.0   \n",
       "2          1.38          0.00         0.00          0.0          0.0   \n",
       "3          9.13         25.61         0.00          0.0          0.0   \n",
       "4         17.00          0.00         0.00          0.0          0.0   \n",
       "\n",
       "   total_og_mou_6  total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  \\\n",
       "0           81.21          221.68            3.63              2.43   \n",
       "1            0.00           30.73           31.66              1.68   \n",
       "2           56.49           99.36            0.00              4.51   \n",
       "3           76.03           95.98           53.84             24.98   \n",
       "4           63.26           42.94           15.76              5.44   \n",
       "\n",
       "   loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  \\\n",
       "0              3.68              7.79              0.83             21.08   \n",
       "1             19.09             10.53              1.41             18.68   \n",
       "2              6.16              6.49             89.86             25.18   \n",
       "3              4.84             23.88             53.99             44.23   \n",
       "4              1.39              2.66             10.58              4.33   \n",
       "\n",
       "   loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  \\\n",
       "0             16.91              0.00              0.00              0.00   \n",
       "1             11.09              0.35              1.66              3.40   \n",
       "2             23.51              0.00              0.00              0.00   \n",
       "3             57.14              7.23              0.81              0.00   \n",
       "4             19.49              5.51              3.63              6.14   \n",
       "\n",
       "   loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  \\\n",
       "0          3.26         24.76         24.71              0.00   \n",
       "1          3.44         39.44         25.03              0.00   \n",
       "2         94.38         31.34         30.01             11.69   \n",
       "3         86.21         49.89         81.03              0.00   \n",
       "4         21.54          9.36         28.31              0.00   \n",
       "\n",
       "   std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  \\\n",
       "0              7.61              0.21              7.46             19.96   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2              0.00              0.00             18.21              2.48   \n",
       "3              0.00              0.00              8.89              0.28   \n",
       "4              0.00              0.00              0.00              0.00   \n",
       "\n",
       "   std_ic_t2m_mou_8  std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  \\\n",
       "0             14.96               0.0               0.0               0.0   \n",
       "1              0.00               0.0               0.0               0.0   \n",
       "2              6.38               0.0               0.0               0.0   \n",
       "3              2.81               0.0               0.0               0.0   \n",
       "4              0.00               0.0               0.0               0.0   \n",
       "\n",
       "   std_ic_t2o_mou_6  std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_mou_6  \\\n",
       "0               0.0               0.0               0.0          7.46   \n",
       "1               0.0               0.0               0.0          0.00   \n",
       "2               0.0               0.0               0.0         29.91   \n",
       "3               0.0               0.0               0.0          8.89   \n",
       "4               0.0               0.0               0.0          0.00   \n",
       "\n",
       "   std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  total_ic_mou_8  \\\n",
       "0         27.58         15.18           11.84           53.04           40.56   \n",
       "1          0.00          0.00            3.44           39.44           25.04   \n",
       "2          2.48          6.38          124.29           33.83           36.64   \n",
       "3          0.28          2.81           95.11           50.18           83.84   \n",
       "4          0.00          0.00           21.54            9.36           28.31   \n",
       "\n",
       "   spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "0           0.0           0.0          0.66           0.0           0.0   \n",
       "1           0.0           0.0          0.01           0.0           0.0   \n",
       "2           0.0           0.0          0.00           0.0           0.0   \n",
       "3           0.0           0.0          0.00           0.0           0.0   \n",
       "4           0.0           0.0          0.00           0.0           0.0   \n",
       "\n",
       "   isd_ic_mou_8  ic_others_6  ic_others_7  ic_others_8  total_rech_num_6  \\\n",
       "0           0.0         1.11         0.69         0.00                 3   \n",
       "1           0.0         0.00         0.00         0.00                 3   \n",
       "2           0.0         0.00         0.00         0.25                 2   \n",
       "3           0.0         0.00         0.00         0.00                 2   \n",
       "4           0.0         0.00         0.00         0.00                13   \n",
       "\n",
       "   total_rech_num_7  total_rech_num_8  total_rech_amt_6  total_rech_amt_7  \\\n",
       "0                 2                 2                77                65   \n",
       "1                 4                 5                 0               145   \n",
       "2                 4                 2                70               120   \n",
       "3                 4                 3               160               240   \n",
       "4                10                 8               290               136   \n",
       "\n",
       "   total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  max_rech_amt_8  \\\n",
       "0                10              65              65              10   \n",
       "1                50               0             145              50   \n",
       "2                 0              70              70               0   \n",
       "3               130             110             110              50   \n",
       "4               122              50              41              30   \n",
       "\n",
       "  date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8  \\\n",
       "0           6/22/2014           7/10/2014           8/24/2014   \n",
       "1           6/12/2014           7/10/2014           8/26/2014   \n",
       "2           6/11/2014           7/22/2014           8/24/2014   \n",
       "3           6/15/2014           7/21/2014           8/25/2014   \n",
       "4           6/25/2014           7/26/2014           8/30/2014   \n",
       "\n",
       "   last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "0                  65                  65                   0   \n",
       "1                   0                   0                   0   \n",
       "2                  70                  50                   0   \n",
       "3                 110                 110                  50   \n",
       "4                  25                  10                  30   \n",
       "\n",
       "  date_of_last_rech_data_6 date_of_last_rech_data_7 date_of_last_rech_data_8  \\\n",
       "0                      NaN                      NaN                      NaN   \n",
       "1                      NaN                 7/8/2014                      NaN   \n",
       "2                      NaN                      NaN                      NaN   \n",
       "3                      NaN                      NaN                      NaN   \n",
       "4                6/25/2014                7/23/2014                8/20/2014   \n",
       "\n",
       "   total_rech_data_6  total_rech_data_7  total_rech_data_8  max_rech_data_6  \\\n",
       "0                NaN                NaN                NaN              NaN   \n",
       "1                NaN                1.0                NaN              NaN   \n",
       "2                NaN                NaN                NaN              NaN   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4                7.0                7.0                6.0             25.0   \n",
       "\n",
       "   max_rech_data_7  max_rech_data_8  count_rech_2g_6  count_rech_2g_7  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1            145.0              NaN              NaN              0.0   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4             41.0             25.0              7.0              6.0   \n",
       "\n",
       "   count_rech_2g_8  count_rech_3g_6  count_rech_3g_7  count_rech_3g_8  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              1.0              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              6.0              0.0              1.0              0.0   \n",
       "\n",
       "   av_rech_amt_data_6  av_rech_amt_data_7  av_rech_amt_data_8  vol_2g_mb_6  \\\n",
       "0                 NaN                 NaN                 NaN          0.0   \n",
       "1                 NaN               145.0                 NaN          0.0   \n",
       "2                 NaN                 NaN                 NaN          0.0   \n",
       "3                 NaN                 NaN                 NaN          0.0   \n",
       "4               175.0               191.0               142.0        390.8   \n",
       "\n",
       "   vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  vol_3g_mb_7  vol_3g_mb_8  arpu_3g_6  \\\n",
       "0         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "1       352.91         0.00          0.0         3.96          0.0        NaN   \n",
       "2         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "3         0.00         0.00          0.0         0.00          0.0        NaN   \n",
       "4       308.89       213.47          0.0         0.00          0.0        0.0   \n",
       "\n",
       "   arpu_3g_7  arpu_3g_8  arpu_2g_6  arpu_2g_7  arpu_2g_8  night_pck_user_6  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "1     122.07        NaN        NaN     122.08        NaN               NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN               NaN   \n",
       "4      35.00        0.0        0.0      35.12        0.0               0.0   \n",
       "\n",
       "   night_pck_user_7  night_pck_user_8  monthly_2g_6  monthly_2g_7  \\\n",
       "0               NaN               NaN             0             0   \n",
       "1               0.0               NaN             0             0   \n",
       "2               NaN               NaN             0             0   \n",
       "3               NaN               NaN             0             0   \n",
       "4               0.0               0.0             0             0   \n",
       "\n",
       "   monthly_2g_8  sachet_2g_6  sachet_2g_7  sachet_2g_8  monthly_3g_6  \\\n",
       "0             0            0            0            0             0   \n",
       "1             0            0            0            0             0   \n",
       "2             0            0            0            0             0   \n",
       "3             0            0            0            0             0   \n",
       "4             0            7            6            6             0   \n",
       "\n",
       "   monthly_3g_7  monthly_3g_8  sachet_3g_6  sachet_3g_7  sachet_3g_8  \\\n",
       "0             0             0            0            0            0   \n",
       "1             1             0            0            0            0   \n",
       "2             0             0            0            0            0   \n",
       "3             0             0            0            0            0   \n",
       "4             0             0            0            1            0   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \\\n",
       "0        NaN        NaN        NaN  1958         0.0         0.0         0.0   \n",
       "1        NaN        1.0        NaN   710         0.0         0.0         0.0   \n",
       "2        NaN        NaN        NaN   882         0.0         0.0         0.0   \n",
       "3        NaN        NaN        NaN   982         0.0         0.0         0.0   \n",
       "4        1.0        1.0        1.0   647         0.0         0.0         0.0   \n",
       "\n",
       "   churn_probability  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9368cfbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69994</th>\n",
       "      <td>69994</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>15.760</td>\n",
       "      <td>410.924</td>\n",
       "      <td>329.136</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.36</td>\n",
       "      <td>10.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>488.46</td>\n",
       "      <td>381.64</td>\n",
       "      <td>14.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.44</td>\n",
       "      <td>7.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.64</td>\n",
       "      <td>89.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>63.09</td>\n",
       "      <td>96.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.91</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>414.61</td>\n",
       "      <td>290.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>419.53</td>\n",
       "      <td>293.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.05</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>496.68</td>\n",
       "      <td>392.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.59</td>\n",
       "      <td>33.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>172.33</td>\n",
       "      <td>223.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>199.99</td>\n",
       "      <td>257.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.99</td>\n",
       "      <td>11.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.99</td>\n",
       "      <td>11.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>221.99</td>\n",
       "      <td>269.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>397</td>\n",
       "      <td>512</td>\n",
       "      <td>50</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>6/18/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/21/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>244.59</td>\n",
       "      <td>144.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.61</td>\n",
       "      <td>48.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>221</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>69995</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>160.083</td>\n",
       "      <td>289.129</td>\n",
       "      <td>265.772</td>\n",
       "      <td>116.54</td>\n",
       "      <td>196.46</td>\n",
       "      <td>232.63</td>\n",
       "      <td>49.53</td>\n",
       "      <td>96.28</td>\n",
       "      <td>48.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.18</td>\n",
       "      <td>30.11</td>\n",
       "      <td>9.06</td>\n",
       "      <td>37.53</td>\n",
       "      <td>73.84</td>\n",
       "      <td>47.34</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.73</td>\n",
       "      <td>103.96</td>\n",
       "      <td>56.41</td>\n",
       "      <td>109.36</td>\n",
       "      <td>166.34</td>\n",
       "      <td>223.56</td>\n",
       "      <td>9.98</td>\n",
       "      <td>18.41</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.34</td>\n",
       "      <td>184.76</td>\n",
       "      <td>224.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.21</td>\n",
       "      <td>292.74</td>\n",
       "      <td>280.69</td>\n",
       "      <td>30.48</td>\n",
       "      <td>28.48</td>\n",
       "      <td>23.09</td>\n",
       "      <td>21.78</td>\n",
       "      <td>35.18</td>\n",
       "      <td>28.79</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.64</td>\n",
       "      <td>63.88</td>\n",
       "      <td>51.89</td>\n",
       "      <td>16.63</td>\n",
       "      <td>39.23</td>\n",
       "      <td>66.28</td>\n",
       "      <td>8.96</td>\n",
       "      <td>9.31</td>\n",
       "      <td>17.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.59</td>\n",
       "      <td>48.54</td>\n",
       "      <td>83.53</td>\n",
       "      <td>80.24</td>\n",
       "      <td>112.43</td>\n",
       "      <td>136.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>313</td>\n",
       "      <td>308</td>\n",
       "      <td>90</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>6/28/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/27/2014</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>712</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>69996</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>372.088</td>\n",
       "      <td>258.374</td>\n",
       "      <td>279.782</td>\n",
       "      <td>77.13</td>\n",
       "      <td>68.44</td>\n",
       "      <td>78.44</td>\n",
       "      <td>335.54</td>\n",
       "      <td>227.94</td>\n",
       "      <td>263.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.13</td>\n",
       "      <td>44.28</td>\n",
       "      <td>78.44</td>\n",
       "      <td>143.19</td>\n",
       "      <td>82.58</td>\n",
       "      <td>138.26</td>\n",
       "      <td>142.58</td>\n",
       "      <td>141.26</td>\n",
       "      <td>125.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>362.91</td>\n",
       "      <td>268.13</td>\n",
       "      <td>342.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.54</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412.68</td>\n",
       "      <td>296.39</td>\n",
       "      <td>342.29</td>\n",
       "      <td>46.41</td>\n",
       "      <td>30.29</td>\n",
       "      <td>86.53</td>\n",
       "      <td>143.94</td>\n",
       "      <td>147.01</td>\n",
       "      <td>177.73</td>\n",
       "      <td>339.11</td>\n",
       "      <td>236.16</td>\n",
       "      <td>147.74</td>\n",
       "      <td>529.48</td>\n",
       "      <td>413.48</td>\n",
       "      <td>412.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.48</td>\n",
       "      <td>542.18</td>\n",
       "      <td>416.58</td>\n",
       "      <td>414.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.14</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>626</td>\n",
       "      <td>250</td>\n",
       "      <td>397</td>\n",
       "      <td>279</td>\n",
       "      <td>250</td>\n",
       "      <td>349</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/30/2014</td>\n",
       "      <td>8/29/2014</td>\n",
       "      <td>279</td>\n",
       "      <td>250</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>879</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>69997</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>238.575</td>\n",
       "      <td>245.414</td>\n",
       "      <td>145.062</td>\n",
       "      <td>14.01</td>\n",
       "      <td>7.64</td>\n",
       "      <td>6.71</td>\n",
       "      <td>30.34</td>\n",
       "      <td>16.68</td>\n",
       "      <td>12.56</td>\n",
       "      <td>25.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.88</td>\n",
       "      <td>7.64</td>\n",
       "      <td>6.71</td>\n",
       "      <td>4.44</td>\n",
       "      <td>6.66</td>\n",
       "      <td>8.84</td>\n",
       "      <td>7.99</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.33</td>\n",
       "      <td>15.76</td>\n",
       "      <td>18.43</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.30</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.45</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.78</td>\n",
       "      <td>24.33</td>\n",
       "      <td>19.28</td>\n",
       "      <td>11.36</td>\n",
       "      <td>3.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.68</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>12.38</td>\n",
       "      <td>9.61</td>\n",
       "      <td>7.81</td>\n",
       "      <td>3.70</td>\n",
       "      <td>4.61</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2.01</td>\n",
       "      <td>7.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>6.63</td>\n",
       "      <td>9.94</td>\n",
       "      <td>18.83</td>\n",
       "      <td>16.24</td>\n",
       "      <td>17.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>379</td>\n",
       "      <td>252</td>\n",
       "      <td>145</td>\n",
       "      <td>200</td>\n",
       "      <td>252</td>\n",
       "      <td>145</td>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/19/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/17/2014</td>\n",
       "      <td>7/13/2014</td>\n",
       "      <td>8/14/2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>46.25</td>\n",
       "      <td>57.61</td>\n",
       "      <td>44.64</td>\n",
       "      <td>1253.47</td>\n",
       "      <td>1774.18</td>\n",
       "      <td>658.19</td>\n",
       "      <td>150.67</td>\n",
       "      <td>212.18</td>\n",
       "      <td>122.08</td>\n",
       "      <td>150.67</td>\n",
       "      <td>212.17</td>\n",
       "      <td>122.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>277</td>\n",
       "      <td>664.25</td>\n",
       "      <td>1402.96</td>\n",
       "      <td>990.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>69998</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>168.269</td>\n",
       "      <td>42.815</td>\n",
       "      <td>167.961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.21</td>\n",
       "      <td>4.31</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.68</td>\n",
       "      <td>38.71</td>\n",
       "      <td>31.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>5.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.33</td>\n",
       "      <td>48.81</td>\n",
       "      <td>32.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.13</td>\n",
       "      <td>65.09</td>\n",
       "      <td>33.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>50</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>50</td>\n",
       "      <td>198</td>\n",
       "      <td>6/19/2014</td>\n",
       "      <td>7/27/2014</td>\n",
       "      <td>8/25/2014</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/19/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/8/2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.0</td>\n",
       "      <td>280.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>982.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1876</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "69994  69994        109             0.0             0.0             0.0   \n",
       "69995  69995        109             0.0             0.0             0.0   \n",
       "69996  69996        109             0.0             0.0             0.0   \n",
       "69997  69997        109             0.0             0.0             0.0   \n",
       "69998  69998        109             0.0             0.0             0.0   \n",
       "\n",
       "      last_date_of_month_6 last_date_of_month_7 last_date_of_month_8   arpu_6  \\\n",
       "69994            6/30/2014            7/31/2014            8/31/2014   15.760   \n",
       "69995            6/30/2014            7/31/2014            8/31/2014  160.083   \n",
       "69996            6/30/2014            7/31/2014            8/31/2014  372.088   \n",
       "69997            6/30/2014            7/31/2014            8/31/2014  238.575   \n",
       "69998            6/30/2014            7/31/2014            8/31/2014  168.269   \n",
       "\n",
       "        arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  \\\n",
       "69994  410.924  329.136         0.00         7.36        10.93          0.00   \n",
       "69995  289.129  265.772       116.54       196.46       232.63         49.53   \n",
       "69996  258.374  279.782        77.13        68.44        78.44        335.54   \n",
       "69997  245.414  145.062        14.01         7.64         6.71         30.34   \n",
       "69998   42.815  167.961         0.00         0.00         0.00          0.00   \n",
       "\n",
       "       offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  \\\n",
       "69994        488.46        381.64          14.96            0.0   \n",
       "69995         96.28         48.06           0.00            0.0   \n",
       "69996        227.94        263.84           0.00            0.0   \n",
       "69997         16.68         12.56          25.06            0.0   \n",
       "69998          0.00          0.00           0.00            0.0   \n",
       "\n",
       "       roam_ic_mou_8  roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  \\\n",
       "69994            0.0           0.00            0.0            0.0   \n",
       "69995            0.0           0.00            0.0            0.0   \n",
       "69996            0.0           0.00            0.0            0.0   \n",
       "69997            0.0           4.58            0.0            0.0   \n",
       "69998            0.0           0.00            0.0            0.0   \n",
       "\n",
       "       loc_og_t2t_mou_6  loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  \\\n",
       "69994              0.00              2.44              7.19              0.00   \n",
       "69995              7.18             30.11              9.06             37.53   \n",
       "69996             77.13             44.28             78.44            143.19   \n",
       "69997             10.88              7.64              6.71              4.44   \n",
       "69998              0.00              0.00              0.00              0.00   \n",
       "\n",
       "       loc_og_t2m_mou_7  loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  \\\n",
       "69994             60.64             89.66              0.00              0.00   \n",
       "69995             73.84             47.34              2.01              0.00   \n",
       "69996             82.58            138.26            142.58            141.26   \n",
       "69997              6.66              8.84              7.99              1.45   \n",
       "69998              0.00              0.00              0.00              0.00   \n",
       "\n",
       "       loc_og_t2f_mou_8  loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  \\\n",
       "69994              0.00               0.0              2.43              0.86   \n",
       "69995              0.00               0.0              4.01              0.00   \n",
       "69996            125.58               0.0              4.10              0.00   \n",
       "69997              2.86               0.0              0.00              0.00   \n",
       "69998              0.00               0.0              0.00              0.00   \n",
       "\n",
       "       loc_og_mou_6  loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  \\\n",
       "69994          0.00         63.09         96.86              0.00   \n",
       "69995         46.73        103.96         56.41            109.36   \n",
       "69996        362.91        268.13        342.29              0.00   \n",
       "69997         23.33         15.76         18.43              2.15   \n",
       "69998          0.00          0.00          0.00              0.00   \n",
       "\n",
       "       std_og_t2t_mou_7  std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  \\\n",
       "69994              4.91              3.73              0.00            414.61   \n",
       "69995            166.34            223.56              9.98             18.41   \n",
       "69996             24.16              0.00              0.00              0.00   \n",
       "69997              0.00              0.00             14.30              8.56   \n",
       "69998              0.00              0.00              0.00              0.00   \n",
       "\n",
       "       std_og_t2m_mou_8  std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  \\\n",
       "69994            290.14               0.0               0.0               0.0   \n",
       "69995              0.53               0.0               0.0               0.0   \n",
       "69996              0.00               0.0               0.0               0.0   \n",
       "69997              0.85               0.0               0.0               0.0   \n",
       "69998              0.00               0.0               0.0               0.0   \n",
       "\n",
       "       std_og_t2c_mou_6  std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_mou_6  \\\n",
       "69994               0.0               0.0               0.0          0.00   \n",
       "69995               0.0               0.0               0.0        119.34   \n",
       "69996               0.0               0.0               0.0          0.00   \n",
       "69997               0.0               0.0               0.0         16.45   \n",
       "69998               0.0               0.0               0.0          0.00   \n",
       "\n",
       "       std_og_mou_7  std_og_mou_8  isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  \\\n",
       "69994        419.53        293.88          0.00           0.0           0.0   \n",
       "69995        184.76        224.09          0.00           0.0           0.0   \n",
       "69996         24.16          0.00          0.21           0.0           0.0   \n",
       "69997          8.56          0.85          0.00           0.0           0.0   \n",
       "69998          0.00          0.00          0.00           0.0           0.0   \n",
       "\n",
       "       spl_og_mou_6  spl_og_mou_7  spl_og_mou_8  og_others_6  og_others_7  \\\n",
       "69994          0.00         14.05          1.83          0.0          0.0   \n",
       "69995          0.13          4.01          0.18          0.0          0.0   \n",
       "69996         49.54          4.10          0.00          0.0          0.0   \n",
       "69997          0.00          0.00          0.00          0.0          0.0   \n",
       "69998          0.00          0.00          0.00          0.0          0.0   \n",
       "\n",
       "       og_others_8  total_og_mou_6  total_og_mou_7  total_og_mou_8  \\\n",
       "69994          0.0            0.00          496.68          392.58   \n",
       "69995          0.0          166.21          292.74          280.69   \n",
       "69996          0.0          412.68          296.39          342.29   \n",
       "69997          0.0           39.78           24.33           19.28   \n",
       "69998          0.0            0.00            0.00            0.00   \n",
       "\n",
       "       loc_ic_t2t_mou_6  loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  \\\n",
       "69994              0.00             26.59             33.84              0.00   \n",
       "69995             30.48             28.48             23.09             21.78   \n",
       "69996             46.41             30.29             86.53            143.94   \n",
       "69997             11.36              3.64              1.04              0.66   \n",
       "69998              2.21              4.31              0.96              2.68   \n",
       "\n",
       "       loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  \\\n",
       "69994            172.33            223.91              0.00              1.06   \n",
       "69995             35.18             28.79              2.38              0.21   \n",
       "69996            147.01            177.73            339.11            236.16   \n",
       "69997              1.68              3.94              0.34              4.28   \n",
       "69998             38.71             31.69              0.43              5.78   \n",
       "\n",
       "       loc_ic_t2f_mou_8  loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  \\\n",
       "69994              0.00          0.00        199.99        257.76   \n",
       "69995              0.00         54.64         63.88         51.89   \n",
       "69996            147.74        529.48        413.48        412.01   \n",
       "69997              2.81         12.38          9.61          7.81   \n",
       "69998              0.00          5.33         48.81         32.66   \n",
       "\n",
       "       std_ic_t2t_mou_6  std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2m_mou_6  \\\n",
       "69994              0.00              0.00              0.00              0.00   \n",
       "69995             16.63             39.23             66.28              8.96   \n",
       "69996              0.00              0.00              0.00              0.00   \n",
       "69997              3.70              4.61              1.30              2.74   \n",
       "69998              0.00              0.00              0.00              0.00   \n",
       "\n",
       "       std_ic_t2m_mou_7  std_ic_t2m_mou_8  std_ic_t2f_mou_6  std_ic_t2f_mou_7  \\\n",
       "69994             21.99             11.79               0.0               0.0   \n",
       "69995              9.31             17.24               0.0               0.0   \n",
       "69996              0.00              0.00               2.5               0.0   \n",
       "69997              2.01              7.36               0.0               0.0   \n",
       "69998             16.28              0.00               0.0               0.0   \n",
       "\n",
       "       std_ic_t2f_mou_8  std_ic_t2o_mou_6  std_ic_t2o_mou_7  std_ic_t2o_mou_8  \\\n",
       "69994              0.00               0.0               0.0               0.0   \n",
       "69995              0.00               0.0               0.0               0.0   \n",
       "69996              2.48               0.0               0.0               0.0   \n",
       "69997              1.28               0.0               0.0               0.0   \n",
       "69998              0.00               0.0               0.0               0.0   \n",
       "\n",
       "       std_ic_mou_6  std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  \\\n",
       "69994          0.00         21.99         11.79            0.00   \n",
       "69995         25.59         48.54         83.53           80.24   \n",
       "69996          2.50          0.00          2.48          542.18   \n",
       "69997          6.44          6.63          9.94           18.83   \n",
       "69998          0.00         16.28          0.00            8.13   \n",
       "\n",
       "       total_ic_mou_7  total_ic_mou_8  spl_ic_mou_6  spl_ic_mou_7  \\\n",
       "69994          221.99          269.56           0.0           0.0   \n",
       "69995          112.43          136.01           0.0           0.0   \n",
       "69996          416.58          414.54           0.0           0.0   \n",
       "69997           16.24           17.76           0.0           0.0   \n",
       "69998           65.09           33.58           0.0           0.0   \n",
       "\n",
       "       spl_ic_mou_8  isd_ic_mou_6  isd_ic_mou_7  isd_ic_mou_8  ic_others_6  \\\n",
       "69994           0.0          0.00           0.0          0.00         0.00   \n",
       "69995           0.5          0.00           0.0          0.00         0.00   \n",
       "69996           0.0          5.05           0.0          0.05         5.14   \n",
       "69997           0.0          0.00           0.0          0.00         0.00   \n",
       "69998           0.0          0.00           0.0          0.55         2.80   \n",
       "\n",
       "       ic_others_7  ic_others_8  total_rech_num_6  total_rech_num_7  \\\n",
       "69994         0.00         0.00                 1                17   \n",
       "69995         0.00         0.08                 5                11   \n",
       "69996         3.09         0.00                 3                 1   \n",
       "69997         0.00         0.00                 5                 3   \n",
       "69998         0.00         0.36                 2                 2   \n",
       "\n",
       "       total_rech_num_8  total_rech_amt_6  total_rech_amt_7  total_rech_amt_8  \\\n",
       "69994                13                50               397               512   \n",
       "69995                 9               200               313               308   \n",
       "69996                 4               626               250               397   \n",
       "69997                 2               379               252               145   \n",
       "69998                 2               198                50               198   \n",
       "\n",
       "       max_rech_amt_6  max_rech_amt_7  max_rech_amt_8 date_of_last_rech_6  \\\n",
       "69994              50             110             130           6/18/2014   \n",
       "69995              90              44              44           6/28/2014   \n",
       "69996             279             250             349           6/25/2014   \n",
       "69997             200             252             145           6/29/2014   \n",
       "69998             198              50             198           6/19/2014   \n",
       "\n",
       "      date_of_last_rech_7 date_of_last_rech_8  last_day_rch_amt_6  \\\n",
       "69994           7/31/2014           8/31/2014                  50   \n",
       "69995           7/31/2014           8/27/2014                  50   \n",
       "69996           7/30/2014           8/29/2014                 279   \n",
       "69997           7/19/2014           8/26/2014                   0   \n",
       "69998           7/27/2014           8/25/2014                 198   \n",
       "\n",
       "       last_day_rch_amt_7  last_day_rch_amt_8 date_of_last_rech_data_6  \\\n",
       "69994                  20                 130                      NaN   \n",
       "69995                  30                  42                      NaN   \n",
       "69996                 250                  48                      NaN   \n",
       "69997                   0                   0                6/17/2014   \n",
       "69998                   0                   0                6/19/2014   \n",
       "\n",
       "      date_of_last_rech_data_7 date_of_last_rech_data_8  total_rech_data_6  \\\n",
       "69994                7/31/2014                8/21/2014                NaN   \n",
       "69995                      NaN                      NaN                NaN   \n",
       "69996                      NaN                      NaN                NaN   \n",
       "69997                7/13/2014                8/14/2014                1.0   \n",
       "69998                      NaN                 8/8/2014                1.0   \n",
       "\n",
       "       total_rech_data_7  total_rech_data_8  max_rech_data_6  max_rech_data_7  \\\n",
       "69994                7.0                1.0              NaN             25.0   \n",
       "69995                NaN                NaN              NaN              NaN   \n",
       "69996                NaN                NaN              NaN              NaN   \n",
       "69997                1.0                1.0            179.0            252.0   \n",
       "69998                NaN                1.0            198.0              NaN   \n",
       "\n",
       "       max_rech_data_8  count_rech_2g_6  count_rech_2g_7  count_rech_2g_8  \\\n",
       "69994             17.0              NaN              6.0              1.0   \n",
       "69995              NaN              NaN              NaN              NaN   \n",
       "69996              NaN              NaN              NaN              NaN   \n",
       "69997            145.0              0.0              0.0              0.0   \n",
       "69998            198.0              1.0              NaN              1.0   \n",
       "\n",
       "       count_rech_3g_6  count_rech_3g_7  count_rech_3g_8  av_rech_amt_data_6  \\\n",
       "69994              NaN              1.0              0.0                 NaN   \n",
       "69995              NaN              NaN              NaN                 NaN   \n",
       "69996              NaN              NaN              NaN                 NaN   \n",
       "69997              1.0              1.0              1.0               179.0   \n",
       "69998              0.0              NaN              0.0               198.0   \n",
       "\n",
       "       av_rech_amt_data_7  av_rech_amt_data_8  vol_2g_mb_6  vol_2g_mb_7  \\\n",
       "69994               135.0                17.0         0.00       244.59   \n",
       "69995                 NaN                 NaN         0.00         0.00   \n",
       "69996                 NaN                 NaN         0.00         0.00   \n",
       "69997               252.0               145.0        46.25        57.61   \n",
       "69998                 NaN               198.0       280.70         0.00   \n",
       "\n",
       "       vol_2g_mb_8  vol_3g_mb_6  vol_3g_mb_7  vol_3g_mb_8  arpu_3g_6  \\\n",
       "69994       144.31         0.00         0.00         0.00        NaN   \n",
       "69995         0.00         0.00         0.00         0.00        NaN   \n",
       "69996         0.00         0.00         0.00         0.00        NaN   \n",
       "69997        44.64      1253.47      1774.18       658.19     150.67   \n",
       "69998       982.54         0.00         0.00         0.00       0.00   \n",
       "\n",
       "       arpu_3g_7  arpu_3g_8  arpu_2g_6  arpu_2g_7  arpu_2g_8  \\\n",
       "69994      21.91       0.00        NaN      60.61      48.00   \n",
       "69995        NaN        NaN        NaN        NaN        NaN   \n",
       "69996        NaN        NaN        NaN        NaN        NaN   \n",
       "69997     212.18     122.08     150.67     212.17     122.07   \n",
       "69998        NaN       0.00       0.00        NaN       0.02   \n",
       "\n",
       "       night_pck_user_6  night_pck_user_7  night_pck_user_8  monthly_2g_6  \\\n",
       "69994               NaN               0.0               0.0             0   \n",
       "69995               NaN               NaN               NaN             0   \n",
       "69996               NaN               NaN               NaN             0   \n",
       "69997               0.0               0.0               0.0             0   \n",
       "69998               0.0               NaN               0.0             1   \n",
       "\n",
       "       monthly_2g_7  monthly_2g_8  sachet_2g_6  sachet_2g_7  sachet_2g_8  \\\n",
       "69994             0             0            0            6            1   \n",
       "69995             0             0            0            0            0   \n",
       "69996             0             0            0            0            0   \n",
       "69997             0             0            0            0            0   \n",
       "69998             0             1            0            0            0   \n",
       "\n",
       "       monthly_3g_6  monthly_3g_7  monthly_3g_8  sachet_3g_6  sachet_3g_7  \\\n",
       "69994             0             0             0            0            1   \n",
       "69995             0             0             0            0            0   \n",
       "69996             0             0             0            0            0   \n",
       "69997             1             1             1            0            0   \n",
       "69998             0             0             0            0            0   \n",
       "\n",
       "       sachet_3g_8  fb_user_6  fb_user_7  fb_user_8   aon  aug_vbc_3g  \\\n",
       "69994            0        NaN        1.0        1.0   221        0.00   \n",
       "69995            0        NaN        NaN        NaN   712        0.00   \n",
       "69996            0        NaN        NaN        NaN   879        0.00   \n",
       "69997            0        1.0        1.0        1.0   277      664.25   \n",
       "69998            0        1.0        NaN        1.0  1876        0.00   \n",
       "\n",
       "       jul_vbc_3g  jun_vbc_3g  churn_probability  \n",
       "69994        0.00        0.00                  0  \n",
       "69995        0.00        0.00                  0  \n",
       "69996        0.00        0.00                  0  \n",
       "69997     1402.96      990.97                  0  \n",
       "69998        0.00        0.00                  0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f8f3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From above analysis we can see that there is no summary rows i.e headers or footers presents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fbc9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd27687a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check if there is duplicate rows\n",
    "data['id'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "992153a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets drop id column\n",
    "data.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05618365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From above analysis we can see that there is no duplicates rows present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "687e7e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the unique columns\n",
    "unique_columns = [col for col in data.columns if data[col].nunique() ==len(data)]\n",
    "unique_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78bf9239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "circle_id               1\n",
       "std_ic_t2o_mou_8        1\n",
       "std_ic_t2o_mou_7        1\n",
       "std_og_t2c_mou_8        1\n",
       "std_og_t2c_mou_7        1\n",
       "                    ...  \n",
       "total_og_mou_6      33135\n",
       "total_og_mou_7      33195\n",
       "arpu_8              60194\n",
       "arpu_7              61425\n",
       "arpu_6              61615\n",
       "Length: 171, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check if a columns is having a single value \n",
    "data.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82391d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets drop these as it will not contrubute to model building\n",
    "single_valued_cols = [col for col in data.columns if data[col].nunique() ==1]\n",
    "len(single_valued_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32251d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(single_valued_cols, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c85f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b257780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets tests if single values is present\n",
    "single_valued_cols = [col for col in data.columns if data[col].nunique() ==1]\n",
    "len(single_valued_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d844f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "349437d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn_probability        2\n",
       "night_pck_user_8         2\n",
       "night_pck_user_7         2\n",
       "night_pck_user_6         2\n",
       "fb_user_7                2\n",
       "                     ...  \n",
       "total_og_mou_6       33135\n",
       "total_og_mou_7       33195\n",
       "arpu_8               60194\n",
       "arpu_7               61425\n",
       "arpu_6               61615\n",
       "Length: 158, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check the unique columns value\n",
    "data.nunique().sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbdcc110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "av_rech_amt_data_6    0.749025\n",
       "count_rech_3g_6       0.749025\n",
       "arpu_3g_6             0.749025\n",
       "arpu_2g_6             0.749025\n",
       "max_rech_data_6       0.749025\n",
       "                        ...   \n",
       "vol_2g_mb_6           0.000000\n",
       "vol_2g_mb_7           0.000000\n",
       "vol_2g_mb_8           0.000000\n",
       "vol_3g_mb_6           0.000000\n",
       "churn_probability     0.000000\n",
       "Length: 158, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check for missing values\n",
    "(data.isnull().sum()/len(data)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "715300ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arpu_6               0.000000\n",
       "arpu_7               0.000000\n",
       "arpu_8               0.000000\n",
       "onnet_mou_6          3.954342\n",
       "onnet_mou_7          3.838626\n",
       "                       ...   \n",
       "aon                  0.000000\n",
       "aug_vbc_3g           0.000000\n",
       "jul_vbc_3g           0.000000\n",
       "jun_vbc_3g           0.000000\n",
       "churn_probability    0.000000\n",
       "Length: 158, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data_percent = 100*data.isnull().sum()/len(data)\n",
    "missing_data_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb0cac7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "av_rech_amt_data_6    0.749025\n",
       "count_rech_3g_6       0.749025\n",
       "arpu_3g_6             0.749025\n",
       "arpu_2g_6             0.749025\n",
       "max_rech_data_6       0.749025\n",
       "                        ...   \n",
       "vol_2g_mb_6           0.000000\n",
       "vol_2g_mb_7           0.000000\n",
       "vol_2g_mb_8           0.000000\n",
       "vol_3g_mb_6           0.000000\n",
       "churn_probability     0.000000\n",
       "Length: 158, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the missing value\n",
    "(data.isnull().sum()/len(data)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6345042f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_cols = missing_data_percent[missing_data_percent.ge(50)].index\n",
    "len(missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ec40893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that there are many fields which is having many null values. \n",
    "# will drop if a colums is having more than 40 % of rows are null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd8e85d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 128)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From above analysis we can see that we have more 30 such fields which is having more 40 % of data as null\n",
    "# Lets drop those them\n",
    "data.drop(missing_cols, axis=1, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15058ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "089dbf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63842, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date_of_last_rech_8    0.016807\n",
       "date_of_last_rech_6    0.008035\n",
       "date_of_last_rech_7    0.007190\n",
       "arpu_6                 0.000000\n",
       "spl_ic_mou_6           0.000000\n",
       "                         ...   \n",
       "std_og_t2f_mou_7       0.000000\n",
       "std_og_t2f_mou_6       0.000000\n",
       "std_og_t2m_mou_8       0.000000\n",
       "std_og_t2m_mou_7       0.000000\n",
       "churn_probability      0.000000\n",
       "Length: 128, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing rows with missing values with more than 10 missing values\n",
    "data.dropna(axis=0,inplace=True,thresh=data.shape[1]-10)\n",
    "# Shape of the dataframe after removing rows\n",
    "print(data.shape)\n",
    "# cehcking the misssing value again\n",
    "(data.isnull().sum()/len(data)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6712de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/22/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/12/2014</td>\n",
       "      <td>7/10/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/11/2014</td>\n",
       "      <td>7/22/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/15/2014</td>\n",
       "      <td>7/21/2014</td>\n",
       "      <td>8/25/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/26/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69994</th>\n",
       "      <td>6/18/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>6/28/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/27/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/30/2014</td>\n",
       "      <td>8/29/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/19/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>6/19/2014</td>\n",
       "      <td>7/27/2014</td>\n",
       "      <td>8/25/2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63842 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8\n",
       "0               6/22/2014           7/10/2014           8/24/2014\n",
       "1               6/12/2014           7/10/2014           8/26/2014\n",
       "2               6/11/2014           7/22/2014           8/24/2014\n",
       "3               6/15/2014           7/21/2014           8/25/2014\n",
       "4               6/25/2014           7/26/2014           8/30/2014\n",
       "...                   ...                 ...                 ...\n",
       "69994           6/18/2014           7/31/2014           8/31/2014\n",
       "69995           6/28/2014           7/31/2014           8/27/2014\n",
       "69996           6/25/2014           7/30/2014           8/29/2014\n",
       "69997           6/29/2014           7/19/2014           8/26/2014\n",
       "69998           6/19/2014           7/27/2014           8/25/2014\n",
       "\n",
       "[63842 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat = data.select_dtypes(include='object')\n",
    "data_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ea04fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date_of_last_rech_6', 'date_of_last_rech_7', 'date_of_last_rech_8']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of columns with Date datatype\n",
    "date_cols = [k for k in data.columns.to_list() if 'date' in k]\n",
    "date_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "034c94e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_of_last_rech_8    0.016807\n",
       "date_of_last_rech_6    0.008035\n",
       "date_of_last_rech_7    0.007190\n",
       "arpu_6                 0.000000\n",
       "spl_ic_mou_6           0.000000\n",
       "                         ...   \n",
       "std_og_t2f_mou_7       0.000000\n",
       "std_og_t2f_mou_6       0.000000\n",
       "std_og_t2m_mou_8       0.000000\n",
       "std_og_t2m_mou_7       0.000000\n",
       "churn_probability      0.000000\n",
       "Length: 128, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.isna().sum()/len(data)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ce0a1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63842, 128)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec5620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d529c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Lets Convert the  Date columns to datetime datatype and extracting the days before last day\n",
    "for i in date_cols:\n",
    "    data[i] = pd.to_datetime(data[i])\n",
    "    data[i] = data[i].dt.date\n",
    "    data[i] = pd.to_datetime(data[i])\n",
    "    data[i] = data[i].dt.daysinmonth - data[i].dt.day\n",
    "    \n",
    " #for test data\n",
    "for i in date_cols:\n",
    "    test[i] = pd.to_datetime(data[i])\n",
    "    test[i] = test[i].dt.date\n",
    "    test[i] = pd.to_datetime(data[i])\n",
    "    test[i] = test[i].dt.daysinmonth - test[i].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c249e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c25422e7",
   "metadata": {},
   "source": [
    "### 2. Outlier Treamemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb140e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dd7db06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>vol_2g_mb_8</td>\n",
       "      <td>23.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>ic_others_6</td>\n",
       "      <td>23.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>vol_2g_mb_7</td>\n",
       "      <td>23.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ic_others_8</td>\n",
       "      <td>23.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>vol_2g_mb_6</td>\n",
       "      <td>22.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>date_of_last_rech_6</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>og_others_8</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>og_others_7</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>aon</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Features  Percentage\n",
       "107          vol_2g_mb_8       23.72\n",
       "87           ic_others_6       23.39\n",
       "106          vol_2g_mb_7       23.30\n",
       "89           ic_others_8       23.19\n",
       "105          vol_2g_mb_6       22.69\n",
       "..                   ...         ...\n",
       "104   last_day_rch_amt_8        1.74\n",
       "99   date_of_last_rech_6        1.64\n",
       "50           og_others_8        0.45\n",
       "49           og_others_7        0.36\n",
       "123                  aon        0.06\n",
       "\n",
       "[128 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkign if outliers are there.\n",
    "# oputliers detections\n",
    "outliers_percentage={}\n",
    "for col in data.columns:\n",
    "    IQR=data[col].quantile(.75)-data[col].quantile(.25)\n",
    "    outliers_count=data[(data[col]>(data[col].quantile(.75)+1.5*IQR)) | (data[col]<(data[col].quantile(.25)-1.5*IQR))].shape[0]\n",
    "    outliers_percentage[col]=round(outliers_count/data.shape[0]*100,2)\n",
    "    \n",
    "outlier_df=pd.DataFrame({'Features':list(outliers_percentage.keys()),'Percentage':list(outliers_percentage.values())})\n",
    "outlier_df.sort_values(by=\"Percentage\", ascending=False)\n",
    "\n",
    "# for test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30c6e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority of the numeric columns have outliers\n",
    "# We will not drop outilers as it can  cause loss of information.\n",
    "# Hence reassigning fixed minimum and maximum values to those rows where feature value is outside the range of [25th percentile - 1.5 * IQR, 75th percentile + 1.5 * IQR]\n",
    "#IQR or Inter Quartile Range = Difference between 75th percentile and 25th percentile values of a feature.\n",
    "# Target column 'churn_probability' is excluded in this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "854aec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Outliers\n",
    "for col,percentage in outliers_percentage.items():\n",
    "    if col!='churn_probability':\n",
    "        IQR = data[col].quantile(.75) - data[col].quantile(.25) \n",
    "        max_value = data[col].quantile(.75)+1.5*IQR\n",
    "        min_value = data[col].quantile(.25)-1.5*IQR\n",
    "        data[col][data[col] > max_value] = max_value\n",
    "        data[col][data[col] < min_value ] = min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "806c4092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>churn_probability</td>\n",
       "      <td>5.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arpu_7</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>total_rech_amt_7</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>total_rech_amt_6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>total_rech_num_8</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>std_og_t2f_mou_7</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>std_og_t2f_mou_6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>std_og_t2m_mou_8</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>std_og_t2m_mou_7</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>loc_ic_mou_7</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Features  Percentage\n",
       "127  churn_probability        5.94\n",
       "1               arpu_7        0.00\n",
       "94    total_rech_amt_7        0.00\n",
       "93    total_rech_amt_6        0.00\n",
       "92    total_rech_num_8        0.00\n",
       "..                 ...         ...\n",
       "37    std_og_t2f_mou_7        0.00\n",
       "36    std_og_t2f_mou_6        0.00\n",
       "35    std_og_t2m_mou_8        0.00\n",
       "34    std_og_t2m_mou_7        0.00\n",
       "64        loc_ic_mou_7        0.00\n",
       "\n",
       "[128 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkign if outliers are there.\n",
    "outliers_percentage={}\n",
    "\n",
    "for col in data.columns:\n",
    "    IQR=data[col].quantile(.75)-data[col].quantile(.25)\n",
    "    outliers_count=data[(data[col]>(data[col].quantile(.75)+1.5*IQR)) | (data[col]<(data[col].quantile(.25)-1.5*IQR))].shape[0]\n",
    "    outliers_percentage[col]=round(outliers_count/data.shape[0]*100,2)\n",
    "    \n",
    "outlier_df=pd.DataFrame({'Features':list(outliers_percentage.keys()),'Percentage':list(outliers_percentage.values())})\n",
    "outlier_df.sort_values(by=\"Percentage\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081832f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d067d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hence we outler has been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b8d9ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature : Percentage of Missing Value\n",
      "=====================================\n",
      "date_of_last_rech_6 %: 1.0\n",
      "date_of_last_rech_7 %: 1.0\n",
      "date_of_last_rech_8 %: 2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['date_of_last_rech_6', 'date_of_last_rech_7', 'date_of_last_rech_8']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Feature : Percentage of Missing Value\")\n",
    "print(\"=====================================\")\n",
    "missing_val_cols=[]\n",
    "for col in data.columns:\n",
    "    if data[col].isnull().any():\n",
    "        print(col, '%:', round(data[col].isnull().sum()/data.shape[0], 2)*100)\n",
    "        missing_val_cols.append(col)\n",
    "missing_val_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91f11504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since percentage of null value is very less. we can drop them.\n",
    "data = data.dropna(subset=['date_of_last_rech_6','date_of_last_rech_7','date_of_last_rech_8'], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6848988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature : Percentage of Missing Value\n",
      "=====================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Feature : Percentage of Missing Value\")\n",
    "print(\"=====================================\")\n",
    "missing_val_cols=[]\n",
    "for col in data.columns:\n",
    "    if data[col].isnull().any():\n",
    "        print(col, ':', round(data[col].isnull().sum()/data.shape[0], 2)*100)\n",
    "        missing_val_cols.append(col)\n",
    "missing_val_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91769fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that data is clean now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2801fa",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f27e630e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 61895 entries, 0 to 69998\n",
      "Data columns (total 128 columns):\n",
      " #    Column               Dtype  \n",
      "---   ------               -----  \n",
      " 0    arpu_6               float64\n",
      " 1    arpu_7               float64\n",
      " 2    arpu_8               float64\n",
      " 3    onnet_mou_6          float64\n",
      " 4    onnet_mou_7          float64\n",
      " 5    onnet_mou_8          float64\n",
      " 6    offnet_mou_6         float64\n",
      " 7    offnet_mou_7         float64\n",
      " 8    offnet_mou_8         float64\n",
      " 9    roam_ic_mou_6        float64\n",
      " 10   roam_ic_mou_7        float64\n",
      " 11   roam_ic_mou_8        float64\n",
      " 12   roam_og_mou_6        float64\n",
      " 13   roam_og_mou_7        float64\n",
      " 14   roam_og_mou_8        float64\n",
      " 15   loc_og_t2t_mou_6     float64\n",
      " 16   loc_og_t2t_mou_7     float64\n",
      " 17   loc_og_t2t_mou_8     float64\n",
      " 18   loc_og_t2m_mou_6     float64\n",
      " 19   loc_og_t2m_mou_7     float64\n",
      " 20   loc_og_t2m_mou_8     float64\n",
      " 21   loc_og_t2f_mou_6     float64\n",
      " 22   loc_og_t2f_mou_7     float64\n",
      " 23   loc_og_t2f_mou_8     float64\n",
      " 24   loc_og_t2c_mou_6     float64\n",
      " 25   loc_og_t2c_mou_7     float64\n",
      " 26   loc_og_t2c_mou_8     float64\n",
      " 27   loc_og_mou_6         float64\n",
      " 28   loc_og_mou_7         float64\n",
      " 29   loc_og_mou_8         float64\n",
      " 30   std_og_t2t_mou_6     float64\n",
      " 31   std_og_t2t_mou_7     float64\n",
      " 32   std_og_t2t_mou_8     float64\n",
      " 33   std_og_t2m_mou_6     float64\n",
      " 34   std_og_t2m_mou_7     float64\n",
      " 35   std_og_t2m_mou_8     float64\n",
      " 36   std_og_t2f_mou_6     float64\n",
      " 37   std_og_t2f_mou_7     float64\n",
      " 38   std_og_t2f_mou_8     float64\n",
      " 39   std_og_mou_6         float64\n",
      " 40   std_og_mou_7         float64\n",
      " 41   std_og_mou_8         float64\n",
      " 42   isd_og_mou_6         float64\n",
      " 43   isd_og_mou_7         float64\n",
      " 44   isd_og_mou_8         float64\n",
      " 45   spl_og_mou_6         float64\n",
      " 46   spl_og_mou_7         float64\n",
      " 47   spl_og_mou_8         float64\n",
      " 48   og_others_6          float64\n",
      " 49   og_others_7          float64\n",
      " 50   og_others_8          float64\n",
      " 51   total_og_mou_6       float64\n",
      " 52   total_og_mou_7       float64\n",
      " 53   total_og_mou_8       float64\n",
      " 54   loc_ic_t2t_mou_6     float64\n",
      " 55   loc_ic_t2t_mou_7     float64\n",
      " 56   loc_ic_t2t_mou_8     float64\n",
      " 57   loc_ic_t2m_mou_6     float64\n",
      " 58   loc_ic_t2m_mou_7     float64\n",
      " 59   loc_ic_t2m_mou_8     float64\n",
      " 60   loc_ic_t2f_mou_6     float64\n",
      " 61   loc_ic_t2f_mou_7     float64\n",
      " 62   loc_ic_t2f_mou_8     float64\n",
      " 63   loc_ic_mou_6         float64\n",
      " 64   loc_ic_mou_7         float64\n",
      " 65   loc_ic_mou_8         float64\n",
      " 66   std_ic_t2t_mou_6     float64\n",
      " 67   std_ic_t2t_mou_7     float64\n",
      " 68   std_ic_t2t_mou_8     float64\n",
      " 69   std_ic_t2m_mou_6     float64\n",
      " 70   std_ic_t2m_mou_7     float64\n",
      " 71   std_ic_t2m_mou_8     float64\n",
      " 72   std_ic_t2f_mou_6     float64\n",
      " 73   std_ic_t2f_mou_7     float64\n",
      " 74   std_ic_t2f_mou_8     float64\n",
      " 75   std_ic_mou_6         float64\n",
      " 76   std_ic_mou_7         float64\n",
      " 77   std_ic_mou_8         float64\n",
      " 78   total_ic_mou_6       float64\n",
      " 79   total_ic_mou_7       float64\n",
      " 80   total_ic_mou_8       float64\n",
      " 81   spl_ic_mou_6         float64\n",
      " 82   spl_ic_mou_7         float64\n",
      " 83   spl_ic_mou_8         float64\n",
      " 84   isd_ic_mou_6         float64\n",
      " 85   isd_ic_mou_7         float64\n",
      " 86   isd_ic_mou_8         float64\n",
      " 87   ic_others_6          float64\n",
      " 88   ic_others_7          float64\n",
      " 89   ic_others_8          float64\n",
      " 90   total_rech_num_6     int64  \n",
      " 91   total_rech_num_7     int64  \n",
      " 92   total_rech_num_8     int64  \n",
      " 93   total_rech_amt_6     float64\n",
      " 94   total_rech_amt_7     float64\n",
      " 95   total_rech_amt_8     int64  \n",
      " 96   max_rech_amt_6       int64  \n",
      " 97   max_rech_amt_7       int64  \n",
      " 98   max_rech_amt_8       float64\n",
      " 99   date_of_last_rech_6  float64\n",
      " 100  date_of_last_rech_7  float64\n",
      " 101  date_of_last_rech_8  float64\n",
      " 102  last_day_rch_amt_6   int64  \n",
      " 103  last_day_rch_amt_7   int64  \n",
      " 104  last_day_rch_amt_8   int64  \n",
      " 105  vol_2g_mb_6          float64\n",
      " 106  vol_2g_mb_7          float64\n",
      " 107  vol_2g_mb_8          float64\n",
      " 108  vol_3g_mb_6          float64\n",
      " 109  vol_3g_mb_7          float64\n",
      " 110  vol_3g_mb_8          float64\n",
      " 111  monthly_2g_6         int64  \n",
      " 112  monthly_2g_7         int64  \n",
      " 113  monthly_2g_8         int64  \n",
      " 114  sachet_2g_6          int64  \n",
      " 115  sachet_2g_7          int64  \n",
      " 116  sachet_2g_8          int64  \n",
      " 117  monthly_3g_6         int64  \n",
      " 118  monthly_3g_7         int64  \n",
      " 119  monthly_3g_8         int64  \n",
      " 120  sachet_3g_6          int64  \n",
      " 121  sachet_3g_7          int64  \n",
      " 122  sachet_3g_8          int64  \n",
      " 123  aon                  float64\n",
      " 124  aug_vbc_3g           float64\n",
      " 125  jul_vbc_3g           float64\n",
      " 126  jun_vbc_3g           float64\n",
      " 127  churn_probability    int64  \n",
      "dtypes: float64(106), int64(22)\n",
      "memory usage: 60.9 MB\n"
     ]
    }
   ],
   "source": [
    "data.info(verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35b5c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, now all the data are in numeric format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2418b30",
   "metadata": {},
   "source": [
    "##### Derived features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70aedf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that data is clean now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5deee04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average recharge amount for June and July\n",
    "data['avg_rech_amt_6_7']=((data['total_rech_amt_6']+data['total_rech_amt_7'])/2)\n",
    "\n",
    "# Days user with company\n",
    "data['days_stayed'] = data['date_of_last_rech_8'] - data['date_of_last_rech_6']\n",
    "\n",
    "# Average 3g usage for June and July\n",
    "data['avg_3g_6_7']=((data['vol_3g_mb_6']+data['vol_3g_mb_7'])/2)\n",
    "\n",
    "# Average 2g usage for June and July\n",
    "data['avg_2g_6_7']=((data['vol_2g_mb_6']+data['vol_2g_mb_7'])/2)\n",
    "\n",
    "\n",
    "# Avergae of 6th and 7th month total usage\n",
    "data['avg_total_6_7']=((data['total_og_mou_6']+data['total_og_mou_7'])/2)\n",
    "\n",
    "# Avg. mou at action phase\n",
    "# We are taking average because there are two months(7 and 8) in action phase\n",
    "data['avg_mou_action'] = (data['total_og_mou_7'] + data['total_og_mou_8'] + data['total_ic_mou_7'] + data['total_ic_mou_8'])/2\n",
    "# ARUP in action phase\n",
    "data['avg_arpu_action'] = (data['arpu_7'] + data['arpu_8'])/2\n",
    "# Difference of good and action phase ARPU\n",
    "data['diff_arpu'] = data['avg_arpu_action'] - data['arpu_6']\n",
    "# Checking whether the arpu has decreased on the action month\n",
    "data['decrease_arpu_action'] = np.where(data['diff_arpu'] < 0, 1, 0)\n",
    "\n",
    "## For test dat\n",
    "\n",
    "# Average recharge amount for June and July\n",
    "test['avg_rech_amt_6_7']=((test['total_rech_amt_6']+test['total_rech_amt_7'])/2)\n",
    "\n",
    "# Days user with company\n",
    "test['days_stayed'] = test['date_of_last_rech_8'] - test['date_of_last_rech_6']\n",
    "\n",
    "# Average 3g usage for June and July\n",
    "test['avg_3g_6_7']=((test['vol_3g_mb_6']+test['vol_3g_mb_7'])/2)\n",
    "\n",
    "# Average 2g usage for June and July\n",
    "test['avg_2g_6_7']=((test['vol_2g_mb_6']+test['vol_2g_mb_7'])/2)\n",
    "\n",
    "\n",
    "# Avergae of 6th and 7th month total usage\n",
    "test['avg_total_6_7']=((test['total_og_mou_6']+test['total_og_mou_7'])/2)\n",
    "\n",
    "# Avg. mou at action phase\n",
    "# We are taking average because there are two months(7 and 8) in action phase\n",
    "test['avg_mou_action'] = (test['total_og_mou_7'] + test['total_og_mou_8'] + test['total_ic_mou_7'] + test['total_ic_mou_8'])/2\n",
    "# ARUP in action phase\n",
    "test['avg_arpu_action'] = (test['arpu_7'] + test['arpu_8'])/2\n",
    "# Difference of good and action phase ARPU\n",
    "test['diff_arpu'] = test['avg_arpu_action'] - test['arpu_6']\n",
    "# Checking whether the arpu has decreased on the action month\n",
    "test['decrease_arpu_action'] = np.where(test['diff_arpu'] < 0, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25311242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the high customers based on average recharge amount\n",
    "#perc_6_7=data['avg_rech_amt_6_7'].quantile(0.70)\n",
    "#data=data[data['avg_rech_amt_6_7']>=perc_6_7]\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22f5d8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arpu_6                  0.0\n",
       "total_rech_amt_7        0.0\n",
       "ic_others_7             0.0\n",
       "ic_others_8             0.0\n",
       "total_rech_num_6        0.0\n",
       "                       ... \n",
       "std_og_mou_7            0.0\n",
       "std_og_mou_6            0.0\n",
       "std_og_t2f_mou_8        0.0\n",
       "std_og_t2f_mou_7        0.0\n",
       "decrease_arpu_action    0.0\n",
       "Length: 137, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.isna().sum()/len(data)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c40ca3e",
   "metadata": {},
   "source": [
    "### 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30480e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting churn column to int in order to do aggfunc in the pivot table\n",
    "data['churn_probability'] = data['churn_probability'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f20792e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.pivot_table(values='churn_probability', index='days_stayed', aggfunc='mean').plot.bar()\n",
    "plt.ylabel('churn rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf584af5",
   "metadata": {},
   "source": [
    "##### **Average rev per user**\n",
    "Churn rate is more for the customer who stayed with company for longer time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8af03ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='churn_probability', y='decrease_arpu_action', data=data)\n",
    "plt.xlabel('Average rev per user')\n",
    "plt.ylabel('churn rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66ea090f",
   "metadata": {},
   "source": [
    "when average rev per user decreases the churn rate increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dee98fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating churn dataframe\n",
    "data_churn = data[data['churn_probability'] == 1]\n",
    "# Creating not churn dataframe\n",
    "data_non_churn = data[data['churn_probability'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02e816ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Action phase ARPU')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution plot\n",
    "ax = sns.distplot(data_churn['avg_arpu_action'],label='churn',hist=False)\n",
    "ax = sns.distplot(data_non_churn['avg_arpu_action'],label='not churn',hist=False)\n",
    "ax.set(xlabel='Action phase ARPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3ee67",
   "metadata": {},
   "source": [
    "###### **decrease_rech_amt_action**\n",
    "This column indicates whether the amount of recharge of the customer has decreased in the action phase than the good phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1b5c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg rech_amt in action phase\n",
    "data['avg_rech_amt_action'] = (data['total_rech_amt_7'] + data['total_rech_amt_8'])/2\n",
    "test['avg_rech_amt_action'] = (test['total_rech_amt_7'] + test['total_rech_amt_8'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f3110c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference of action phase rech amt and good phase rech amt\n",
    "data['diff_rech_amt'] = data['avg_rech_amt_action'] - data['total_rech_amt_6']\n",
    "test['diff_rech_amt'] = test['avg_rech_amt_action'] - test['total_rech_amt_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd7aac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if rech_amt has decreased in action phase\n",
    "data['decrease_rech_amt_action'] = np.where((data['diff_rech_amt'] < 0), 1, 0)\n",
    "test['decrease_rech_amt_action'] = np.where((test['diff_rech_amt'] < 0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8dc4aeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.pivot_table(values='churn_probability', index='decrease_rech_amt_action', aggfunc='mean').plot.bar()\n",
    "plt.ylabel('churn rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea7d49f",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "The churn rate is more for the customers, whose amount of recharge in the action phase is lesser than the amount in good phase. which means the customer is planning to churn as we can see this from his recharge behaviour\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa36b18",
   "metadata": {},
   "source": [
    "##### Deriving new column decrease_mou_action\n",
    "This column indicates whether the minutes of usage of the customer has decreased in the action phase than the good phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf130241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total mou at good phase incoming and outgoing\n",
    "data['total_mou_good'] = (data['total_og_mou_6'] + data['total_ic_mou_6'])\n",
    "test['total_mou_good'] = (test['total_og_mou_6'] + test['total_ic_mou_6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e19784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg. mou at action phase\n",
    "# We are taking average because there are two months(7 and 8) in action phase\n",
    "data['avg_mou_action'] = (data['total_og_mou_7'] + data['total_og_mou_8'] + data['total_ic_mou_7'] + data['total_ic_mou_8'])/2\n",
    "# Difference avg_mou_good and avg_mou_action\n",
    "test['avg_mou_action'] = (test['total_og_mou_7'] + test['total_og_mou_8'] + test['total_ic_mou_7'] + test['total_ic_mou_8'])/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e291ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference avg_mou_good and avg_mou_action\n",
    "data['diff_mou'] = data['avg_mou_action'] - data['total_mou_good']\n",
    "test['diff_mou'] = test['avg_mou_action'] - test['total_mou_good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a332fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the mou has decreased in action phase\n",
    "data['decrease_mou_action'] = np.where((data['diff_mou'] < 0), 1, 0)\n",
    "test['decrease_mou_action'] = np.where((test['diff_mou'] < 0), 1, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "939b3582",
   "metadata": {},
   "source": [
    "when average rev per user decreases the churn rate increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc811fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.pivot_table(values='churn_probability', index='decrease_mou_action', aggfunc='mean').plot.bar()\n",
    "plt.ylabel('churn rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1fd81d",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "\n",
    "We can see that the churn rate is more for the customers, whose minutes of usage(mou) decreased in the action phase than the good phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1dc497f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantile_70_good 395.0\n"
     ]
    }
   ],
   "source": [
    "data[\"High_valued_good\"]=data['total_rech_amt_6']\n",
    "test[\"High_valued_good\"]=test['total_rech_amt_6']\n",
    "\n",
    "data[\"High_valued_action\"]=(data['total_rech_amt_7']+data['total_rech_amt_8'])/2\n",
    "test[\"High_valued_action\"]=(test['total_rech_amt_7']+test['total_rech_amt_8'])/2\n",
    "\n",
    "quantile_70_good=data[\"High_valued_good\"].quantile(0.7)\n",
    "quantile_70_action=data[\"High_valued_action\"].quantile(0.7)\n",
    "print(\"quantile_70_good\" , quantile_70_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0df77530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define bins and labels\n",
    "bins = [0, 10, 20, 30]  # Define your own bin edges\n",
    "labels = ['Low', 'Medium', 'High']  # Define labels for each bin\n",
    "\n",
    "# Create a new column with the categorical variable\n",
    "data['Category'] = pd.cut(data['High_valued_action'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Plot the bar chart of the categorical variable\n",
    "#category_counts = data['Category'].sum().sort_index()\n",
    "category_means = data.groupby('churn_probability')['High_valued_action'].mean()\n",
    "category_means.plot(kind='bar', color='skyblue')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('churn_probability')\n",
    "plt.ylabel('Count')\n",
    "#plt.title('Categorical Plot of High_valued_Customers_action')\n",
    "\n",
    "# Display the bar chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd959e",
   "metadata": {},
   "source": [
    "###### In the action phase the high value customers are grouped in bins ,from the graph it is evident that the average high value customers are less likely to churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c447b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg rech number at action phase\n",
    "data['avg_rech_num_action'] = (data['total_rech_num_7'] + data['total_rech_num_8'])/2\n",
    "test['avg_rech_num_action'] = (test['total_rech_num_7'] + test['total_rech_num_8'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67eacd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference total_rech_num_6 and avg_rech_action\n",
    "data['diff_rech_num'] = data['avg_rech_num_action'] - data['total_rech_num_6']\n",
    "test['diff_rech_num'] = test['avg_rech_num_action'] - test['total_rech_num_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fecf73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if rech_num has decreased in action phase\n",
    "data['decrease_rech_num_action'] = np.where((data['diff_rech_num'] < 0), 1, 0)\n",
    "test['decrease_rech_num_action'] = np.where((test['diff_rech_num'] < 0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "424119a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.pivot_table(values='churn_probability', index='decrease_rech_amt_action', columns='decrease_rech_num_action', aggfunc='mean').plot.bar()\n",
    "plt.ylabel('churn rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e558739e",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "We can see from the above plot, that the churn rate is more for the customers, whose recharge amount as well as number of recharge have decreased in the action phase than the good phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340431a",
   "metadata": {},
   "source": [
    "###### Bivariate analysis\n",
    "Analysis of churn rate by the decreasing recharge amount and number of recharge in the action phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28550f6d",
   "metadata": {},
   "source": [
    "### 5. Data Prepration for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "49d08545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "      <th>avg_rech_amt_6_7</th>\n",
       "      <th>days_stayed</th>\n",
       "      <th>avg_3g_6_7</th>\n",
       "      <th>avg_2g_6_7</th>\n",
       "      <th>avg_total_6_7</th>\n",
       "      <th>avg_mou_action</th>\n",
       "      <th>avg_arpu_action</th>\n",
       "      <th>diff_arpu</th>\n",
       "      <th>decrease_arpu_action</th>\n",
       "      <th>avg_rech_amt_action</th>\n",
       "      <th>diff_rech_amt</th>\n",
       "      <th>decrease_rech_amt_action</th>\n",
       "      <th>total_mou_good</th>\n",
       "      <th>diff_mou</th>\n",
       "      <th>decrease_mou_action</th>\n",
       "      <th>High_valued_good</th>\n",
       "      <th>High_valued_action</th>\n",
       "      <th>Category</th>\n",
       "      <th>avg_rech_num_action</th>\n",
       "      <th>diff_rech_num</th>\n",
       "      <th>decrease_rech_num_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.277</td>\n",
       "      <td>87.009</td>\n",
       "      <td>7.527</td>\n",
       "      <td>48.58</td>\n",
       "      <td>124.38</td>\n",
       "      <td>1.29</td>\n",
       "      <td>32.24</td>\n",
       "      <td>96.68</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.29</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.53</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.61</td>\n",
       "      <td>46.34</td>\n",
       "      <td>77.95</td>\n",
       "      <td>1.01000</td>\n",
       "      <td>18.75</td>\n",
       "      <td>80.6100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.09</td>\n",
       "      <td>204.99000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.21</td>\n",
       "      <td>221.68</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.68</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.83</td>\n",
       "      <td>21.08</td>\n",
       "      <td>16.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.2600</td>\n",
       "      <td>24.76</td>\n",
       "      <td>24.71</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.61000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>7.46</td>\n",
       "      <td>19.96</td>\n",
       "      <td>14.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.46</td>\n",
       "      <td>27.58</td>\n",
       "      <td>15.180</td>\n",
       "      <td>11.84</td>\n",
       "      <td>53.04</td>\n",
       "      <td>40.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.445</td>\n",
       "      <td>159.455</td>\n",
       "      <td>47.2680</td>\n",
       "      <td>15.9910</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>-39.5</td>\n",
       "      <td>1</td>\n",
       "      <td>93.05</td>\n",
       "      <td>66.405</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>122.787</td>\n",
       "      <td>42.953</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.99</td>\n",
       "      <td>30.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.225</td>\n",
       "      <td>9.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>1.68</td>\n",
       "      <td>19.09</td>\n",
       "      <td>10.53</td>\n",
       "      <td>1.41</td>\n",
       "      <td>18.68</td>\n",
       "      <td>11.09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.660</td>\n",
       "      <td>3.400</td>\n",
       "      <td>3.4400</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.03</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.44</td>\n",
       "      <td>39.44</td>\n",
       "      <td>25.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.365</td>\n",
       "      <td>63.435</td>\n",
       "      <td>82.8700</td>\n",
       "      <td>82.8700</td>\n",
       "      <td>0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>97.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>59.995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.806</td>\n",
       "      <td>103.176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.53</td>\n",
       "      <td>15.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.99</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.64</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>28.94</td>\n",
       "      <td>82.0500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.94</td>\n",
       "      <td>84.99000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.380</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.49</td>\n",
       "      <td>99.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.51</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.49</td>\n",
       "      <td>89.86</td>\n",
       "      <td>25.18</td>\n",
       "      <td>23.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>94.3800</td>\n",
       "      <td>31.34</td>\n",
       "      <td>30.01</td>\n",
       "      <td>10.125</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.21</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>6.380</td>\n",
       "      <td>124.29</td>\n",
       "      <td>33.83</td>\n",
       "      <td>36.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.925</td>\n",
       "      <td>84.915</td>\n",
       "      <td>51.5880</td>\n",
       "      <td>-9.2180</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>180.78</td>\n",
       "      <td>-95.865</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156.362</td>\n",
       "      <td>205.260</td>\n",
       "      <td>111.095</td>\n",
       "      <td>7.26</td>\n",
       "      <td>16.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.76</td>\n",
       "      <td>78.48</td>\n",
       "      <td>50.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.99</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.91</td>\n",
       "      <td>44.89</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.91</td>\n",
       "      <td>48.84</td>\n",
       "      <td>23.63</td>\n",
       "      <td>0.26</td>\n",
       "      <td>12.06</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>15.33</td>\n",
       "      <td>25.9300</td>\n",
       "      <td>4.6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.16</td>\n",
       "      <td>37.99000</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>9.130</td>\n",
       "      <td>9.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.03</td>\n",
       "      <td>95.98</td>\n",
       "      <td>53.84</td>\n",
       "      <td>24.98</td>\n",
       "      <td>4.84</td>\n",
       "      <td>23.88</td>\n",
       "      <td>53.99</td>\n",
       "      <td>44.23</td>\n",
       "      <td>57.14</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.000</td>\n",
       "      <td>86.2100</td>\n",
       "      <td>49.89</td>\n",
       "      <td>81.03</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.810</td>\n",
       "      <td>95.11</td>\n",
       "      <td>50.18</td>\n",
       "      <td>83.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>160.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>130</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.005</td>\n",
       "      <td>141.920</td>\n",
       "      <td>158.1775</td>\n",
       "      <td>1.8155</td>\n",
       "      <td>0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.14</td>\n",
       "      <td>-29.220</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240.708</td>\n",
       "      <td>128.191</td>\n",
       "      <td>101.565</td>\n",
       "      <td>21.28</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>56.99</td>\n",
       "      <td>38.11</td>\n",
       "      <td>9.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.16</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>36.74</td>\n",
       "      <td>19.88</td>\n",
       "      <td>4.61</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1.230</td>\n",
       "      <td>5.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.91</td>\n",
       "      <td>25.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.225</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.26</td>\n",
       "      <td>42.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>5.44</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.66</td>\n",
       "      <td>10.58</td>\n",
       "      <td>4.33</td>\n",
       "      <td>19.49</td>\n",
       "      <td>5.51</td>\n",
       "      <td>3.630</td>\n",
       "      <td>6.140</td>\n",
       "      <td>21.5400</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.54</td>\n",
       "      <td>9.36</td>\n",
       "      <td>28.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>290.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>122</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.100</td>\n",
       "      <td>48.185</td>\n",
       "      <td>114.8780</td>\n",
       "      <td>-125.8300</td>\n",
       "      <td>1</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-161.0</td>\n",
       "      <td>1</td>\n",
       "      <td>84.80</td>\n",
       "      <td>-36.615</td>\n",
       "      <td>1</td>\n",
       "      <td>290.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69994</th>\n",
       "      <td>15.760</td>\n",
       "      <td>410.924</td>\n",
       "      <td>329.136</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.36</td>\n",
       "      <td>10.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>488.46</td>\n",
       "      <td>381.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.44</td>\n",
       "      <td>7.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.64</td>\n",
       "      <td>89.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>63.09</td>\n",
       "      <td>96.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.91</td>\n",
       "      <td>3.73000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>137.6375</td>\n",
       "      <td>124.8875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>381.63125</td>\n",
       "      <td>293.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.225</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>496.68</td>\n",
       "      <td>392.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.59</td>\n",
       "      <td>33.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>172.33</td>\n",
       "      <td>223.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.060</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>199.99</td>\n",
       "      <td>257.76</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.99</td>\n",
       "      <td>11.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.99</td>\n",
       "      <td>11.790</td>\n",
       "      <td>0.00</td>\n",
       "      <td>221.99</td>\n",
       "      <td>269.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>50.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>512</td>\n",
       "      <td>50</td>\n",
       "      <td>110</td>\n",
       "      <td>130.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>223.5</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248.340</td>\n",
       "      <td>690.405</td>\n",
       "      <td>370.0300</td>\n",
       "      <td>354.2700</td>\n",
       "      <td>0</td>\n",
       "      <td>454.5</td>\n",
       "      <td>404.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>690.405</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>454.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>160.083</td>\n",
       "      <td>289.129</td>\n",
       "      <td>265.772</td>\n",
       "      <td>116.54</td>\n",
       "      <td>196.46</td>\n",
       "      <td>232.63</td>\n",
       "      <td>49.53</td>\n",
       "      <td>96.28</td>\n",
       "      <td>48.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.18</td>\n",
       "      <td>30.11</td>\n",
       "      <td>9.06</td>\n",
       "      <td>37.53</td>\n",
       "      <td>73.84</td>\n",
       "      <td>47.34</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.73</td>\n",
       "      <td>103.96</td>\n",
       "      <td>56.41</td>\n",
       "      <td>73.60</td>\n",
       "      <td>77.95</td>\n",
       "      <td>71.61875</td>\n",
       "      <td>9.98</td>\n",
       "      <td>18.4100</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.34</td>\n",
       "      <td>184.76000</td>\n",
       "      <td>224.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>4.010</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.21</td>\n",
       "      <td>292.74</td>\n",
       "      <td>280.69</td>\n",
       "      <td>30.48</td>\n",
       "      <td>28.48</td>\n",
       "      <td>23.09</td>\n",
       "      <td>21.78</td>\n",
       "      <td>35.18</td>\n",
       "      <td>28.79</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>54.6400</td>\n",
       "      <td>63.88</td>\n",
       "      <td>51.89</td>\n",
       "      <td>10.125</td>\n",
       "      <td>10.76875</td>\n",
       "      <td>10.075</td>\n",
       "      <td>8.96</td>\n",
       "      <td>9.31</td>\n",
       "      <td>17.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.59</td>\n",
       "      <td>48.54</td>\n",
       "      <td>69.215</td>\n",
       "      <td>80.24</td>\n",
       "      <td>112.43</td>\n",
       "      <td>136.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>200.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>308</td>\n",
       "      <td>90</td>\n",
       "      <td>44</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>256.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.475</td>\n",
       "      <td>410.935</td>\n",
       "      <td>277.4505</td>\n",
       "      <td>117.3675</td>\n",
       "      <td>0</td>\n",
       "      <td>310.5</td>\n",
       "      <td>110.5</td>\n",
       "      <td>0</td>\n",
       "      <td>246.45</td>\n",
       "      <td>164.485</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>310.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>372.088</td>\n",
       "      <td>258.374</td>\n",
       "      <td>279.782</td>\n",
       "      <td>77.13</td>\n",
       "      <td>68.44</td>\n",
       "      <td>78.44</td>\n",
       "      <td>335.54</td>\n",
       "      <td>227.94</td>\n",
       "      <td>263.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.13</td>\n",
       "      <td>44.28</td>\n",
       "      <td>78.44</td>\n",
       "      <td>143.19</td>\n",
       "      <td>82.58</td>\n",
       "      <td>138.26</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.575</td>\n",
       "      <td>5.325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>362.91</td>\n",
       "      <td>268.13</td>\n",
       "      <td>342.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.16</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.16000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>4.100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412.68</td>\n",
       "      <td>296.39</td>\n",
       "      <td>342.29</td>\n",
       "      <td>46.41</td>\n",
       "      <td>30.29</td>\n",
       "      <td>86.53</td>\n",
       "      <td>143.94</td>\n",
       "      <td>147.01</td>\n",
       "      <td>177.73</td>\n",
       "      <td>21.35</td>\n",
       "      <td>22.075</td>\n",
       "      <td>21.225</td>\n",
       "      <td>482.6175</td>\n",
       "      <td>413.48</td>\n",
       "      <td>412.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.480</td>\n",
       "      <td>542.18</td>\n",
       "      <td>416.58</td>\n",
       "      <td>414.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>626.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>397</td>\n",
       "      <td>246</td>\n",
       "      <td>250</td>\n",
       "      <td>317.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>260</td>\n",
       "      <td>250</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>354.535</td>\n",
       "      <td>734.900</td>\n",
       "      <td>269.0780</td>\n",
       "      <td>-103.0100</td>\n",
       "      <td>1</td>\n",
       "      <td>323.5</td>\n",
       "      <td>-302.5</td>\n",
       "      <td>1</td>\n",
       "      <td>954.86</td>\n",
       "      <td>-219.960</td>\n",
       "      <td>1</td>\n",
       "      <td>626.0</td>\n",
       "      <td>323.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>238.575</td>\n",
       "      <td>245.414</td>\n",
       "      <td>145.062</td>\n",
       "      <td>14.01</td>\n",
       "      <td>7.64</td>\n",
       "      <td>6.71</td>\n",
       "      <td>30.34</td>\n",
       "      <td>16.68</td>\n",
       "      <td>12.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.88</td>\n",
       "      <td>7.64</td>\n",
       "      <td>6.71</td>\n",
       "      <td>4.44</td>\n",
       "      <td>6.66</td>\n",
       "      <td>8.84</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1.450</td>\n",
       "      <td>2.860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.33</td>\n",
       "      <td>15.76</td>\n",
       "      <td>18.43</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>14.30</td>\n",
       "      <td>8.5600</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.45</td>\n",
       "      <td>8.56000</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.78</td>\n",
       "      <td>24.33</td>\n",
       "      <td>19.28</td>\n",
       "      <td>11.36</td>\n",
       "      <td>3.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.68</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4.280</td>\n",
       "      <td>2.810</td>\n",
       "      <td>12.3800</td>\n",
       "      <td>9.61</td>\n",
       "      <td>7.81</td>\n",
       "      <td>3.700</td>\n",
       "      <td>4.61000</td>\n",
       "      <td>1.300</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2.01</td>\n",
       "      <td>7.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>6.63</td>\n",
       "      <td>9.940</td>\n",
       "      <td>18.83</td>\n",
       "      <td>16.24</td>\n",
       "      <td>17.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>379.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>145</td>\n",
       "      <td>200</td>\n",
       "      <td>252</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>315.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.055</td>\n",
       "      <td>38.805</td>\n",
       "      <td>195.2380</td>\n",
       "      <td>-43.3370</td>\n",
       "      <td>1</td>\n",
       "      <td>198.5</td>\n",
       "      <td>-180.5</td>\n",
       "      <td>1</td>\n",
       "      <td>58.61</td>\n",
       "      <td>-19.805</td>\n",
       "      <td>1</td>\n",
       "      <td>379.0</td>\n",
       "      <td>198.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>168.269</td>\n",
       "      <td>42.815</td>\n",
       "      <td>167.961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.21</td>\n",
       "      <td>4.31</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.68</td>\n",
       "      <td>38.71</td>\n",
       "      <td>31.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>5.780</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.3300</td>\n",
       "      <td>48.81</td>\n",
       "      <td>32.66</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.28</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.13</td>\n",
       "      <td>65.09</td>\n",
       "      <td>33.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>198.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>50</td>\n",
       "      <td>198.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>49.335</td>\n",
       "      <td>105.3880</td>\n",
       "      <td>-62.8810</td>\n",
       "      <td>1</td>\n",
       "      <td>124.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.13</td>\n",
       "      <td>41.205</td>\n",
       "      <td>0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61895 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        arpu_6   arpu_7   arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  \\\n",
       "0       31.277   87.009    7.527        48.58       124.38         1.29   \n",
       "1        0.000  122.787   42.953         0.00         0.00         0.00   \n",
       "2       60.806  103.176    0.000         0.53        15.93         0.00   \n",
       "3      156.362  205.260  111.095         7.26        16.01         0.00   \n",
       "4      240.708  128.191  101.565        21.28         4.83         6.13   \n",
       "...        ...      ...      ...          ...          ...          ...   \n",
       "69994   15.760  410.924  329.136         0.00         7.36        10.93   \n",
       "69995  160.083  289.129  265.772       116.54       196.46       232.63   \n",
       "69996  372.088  258.374  279.782        77.13        68.44        78.44   \n",
       "69997  238.575  245.414  145.062        14.01         7.64         6.71   \n",
       "69998  168.269   42.815  167.961         0.00         0.00         0.00   \n",
       "\n",
       "       offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  \\\n",
       "0             32.24         96.68          2.33            0.0            0.0   \n",
       "1              0.00         25.99         30.89            0.0            0.0   \n",
       "2             53.99         82.05          0.00            0.0            0.0   \n",
       "3             68.76         78.48         50.23            0.0            0.0   \n",
       "4             56.99         38.11          9.63            0.0            0.0   \n",
       "...             ...           ...           ...            ...            ...   \n",
       "69994          0.00        488.46        381.64            0.0            0.0   \n",
       "69995         49.53         96.28         48.06            0.0            0.0   \n",
       "69996        335.54        227.94        263.84            0.0            0.0   \n",
       "69997         30.34         16.68         12.56            0.0            0.0   \n",
       "69998          0.00          0.00          0.00            0.0            0.0   \n",
       "\n",
       "       roam_ic_mou_8  roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  \\\n",
       "0                0.0            0.0            0.0            0.0   \n",
       "1                0.0            0.0            0.0            0.0   \n",
       "2                0.0            0.0            0.0            0.0   \n",
       "3                0.0            0.0            0.0            0.0   \n",
       "4                0.0            0.0            0.0            0.0   \n",
       "...              ...            ...            ...            ...   \n",
       "69994            0.0            0.0            0.0            0.0   \n",
       "69995            0.0            0.0            0.0            0.0   \n",
       "69996            0.0            0.0            0.0            0.0   \n",
       "69997            0.0            0.0            0.0            0.0   \n",
       "69998            0.0            0.0            0.0            0.0   \n",
       "\n",
       "       loc_og_t2t_mou_6  loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2m_mou_6  \\\n",
       "0                  2.23              0.00              0.28              5.29   \n",
       "1                  0.00              0.00              0.00              0.00   \n",
       "2                  0.53             12.98              0.00             24.11   \n",
       "3                  6.99              3.94              0.00             37.91   \n",
       "4                 10.16              4.83              6.13             36.74   \n",
       "...                 ...               ...               ...               ...   \n",
       "69994              0.00              2.44              7.19              0.00   \n",
       "69995              7.18             30.11              9.06             37.53   \n",
       "69996             77.13             44.28             78.44            143.19   \n",
       "69997             10.88              7.64              6.71              4.44   \n",
       "69998              0.00              0.00              0.00              0.00   \n",
       "\n",
       "       loc_og_t2m_mou_7  loc_og_t2m_mou_8  loc_og_t2f_mou_6  loc_og_t2f_mou_7  \\\n",
       "0                 16.04              2.33              0.00             0.000   \n",
       "1                  0.00              0.00              0.00             0.000   \n",
       "2                  0.00              0.00              0.00             0.000   \n",
       "3                 44.89             23.63              0.00             0.000   \n",
       "4                 19.88              4.61              5.45             1.230   \n",
       "...                 ...               ...               ...               ...   \n",
       "69994             60.64             89.66              0.00             0.000   \n",
       "69995             73.84             47.34              2.01             0.000   \n",
       "69996             82.58            138.26              5.45             5.575   \n",
       "69997              6.66              8.84              5.45             1.450   \n",
       "69998              0.00              0.00              0.00             0.000   \n",
       "\n",
       "       loc_og_t2f_mou_8  loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  \\\n",
       "0                 0.000               0.0               0.0               0.0   \n",
       "1                 0.000               0.0               0.0               0.0   \n",
       "2                 0.000               0.0               0.0               0.0   \n",
       "3                 0.000               0.0               0.0               0.0   \n",
       "4                 5.010               0.0               0.0               0.0   \n",
       "...                 ...               ...               ...               ...   \n",
       "69994             0.000               0.0               0.0               0.0   \n",
       "69995             0.000               0.0               0.0               0.0   \n",
       "69996             5.325               0.0               0.0               0.0   \n",
       "69997             2.860               0.0               0.0               0.0   \n",
       "69998             0.000               0.0               0.0               0.0   \n",
       "\n",
       "       loc_og_mou_6  loc_og_mou_7  loc_og_mou_8  std_og_t2t_mou_6  \\\n",
       "0              7.53         16.04          2.61             46.34   \n",
       "1              0.00          0.00          0.00              0.00   \n",
       "2             24.64         12.98          0.00              0.00   \n",
       "3             44.91         48.84         23.63              0.26   \n",
       "4             58.91         25.94         15.76              0.00   \n",
       "...             ...           ...           ...               ...   \n",
       "69994          0.00         63.09         96.86              0.00   \n",
       "69995         46.73        103.96         56.41             73.60   \n",
       "69996        362.91        268.13        342.29              0.00   \n",
       "69997         23.33         15.76         18.43              2.15   \n",
       "69998          0.00          0.00          0.00              0.00   \n",
       "\n",
       "       std_og_t2t_mou_7  std_og_t2t_mou_8  std_og_t2m_mou_6  std_og_t2m_mou_7  \\\n",
       "0                 77.95           1.01000             18.75           80.6100   \n",
       "1                  0.00           0.00000              0.00            0.0000   \n",
       "2                  2.94           0.00000             28.94           82.0500   \n",
       "3                 12.06           0.00000             15.33           25.9300   \n",
       "4                  0.00           0.00000              4.35            0.0000   \n",
       "...                 ...               ...               ...               ...   \n",
       "69994              4.91           3.73000              0.00          137.6375   \n",
       "69995             77.95          71.61875              9.98           18.4100   \n",
       "69996             24.16           0.00000              0.00            0.0000   \n",
       "69997              0.00           0.00000             14.30            8.5600   \n",
       "69998              0.00           0.00000              0.00            0.0000   \n",
       "\n",
       "       std_og_t2m_mou_8  std_og_t2f_mou_6  std_og_t2f_mou_7  std_og_t2f_mou_8  \\\n",
       "0                0.0000               0.0               0.0               0.0   \n",
       "1                0.0000               0.0               0.0               0.0   \n",
       "2                0.0000               0.0               0.0               0.0   \n",
       "3                4.6000               0.0               0.0               0.0   \n",
       "4                0.0000               0.0               0.0               0.0   \n",
       "...                 ...               ...               ...               ...   \n",
       "69994          124.8875               0.0               0.0               0.0   \n",
       "69995            0.5300               0.0               0.0               0.0   \n",
       "69996            0.0000               0.0               0.0               0.0   \n",
       "69997            0.8500               0.0               0.0               0.0   \n",
       "69998            0.0000               0.0               0.0               0.0   \n",
       "\n",
       "       std_og_mou_6  std_og_mou_7  std_og_mou_8  isd_og_mou_6  isd_og_mou_7  \\\n",
       "0             65.09     204.99000          1.01           0.0           0.0   \n",
       "1              0.00       0.00000          0.00           0.0           0.0   \n",
       "2             28.94      84.99000          0.00           0.0           0.0   \n",
       "3             16.16      37.99000          4.60           0.0           0.0   \n",
       "4              4.35       0.00000          0.00           0.0           0.0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "69994          0.00     381.63125        293.88           0.0           0.0   \n",
       "69995        119.34     184.76000        224.09           0.0           0.0   \n",
       "69996          0.00      24.16000          0.00           0.0           0.0   \n",
       "69997         16.45       8.56000          0.85           0.0           0.0   \n",
       "69998          0.00       0.00000          0.00           0.0           0.0   \n",
       "\n",
       "       isd_og_mou_8  spl_og_mou_6  spl_og_mou_7  spl_og_mou_8  og_others_6  \\\n",
       "0               0.0          5.90         0.630          0.00          0.0   \n",
       "1               0.0          0.00         9.225          9.85          0.0   \n",
       "2               0.0          2.89         1.380          0.00          0.0   \n",
       "3               0.0          5.90         9.130          9.85          0.0   \n",
       "4               0.0          0.00         9.225          0.00          0.0   \n",
       "...             ...           ...           ...           ...          ...   \n",
       "69994           0.0          0.00         9.225          1.83          0.0   \n",
       "69995           0.0          0.13         4.010          0.18          0.0   \n",
       "69996           0.0          5.90         4.100          0.00          0.0   \n",
       "69997           0.0          0.00         0.000          0.00          0.0   \n",
       "69998           0.0          0.00         0.000          0.00          0.0   \n",
       "\n",
       "       og_others_7  og_others_8  total_og_mou_6  total_og_mou_7  \\\n",
       "0              0.0          0.0           81.21          221.68   \n",
       "1              0.0          0.0            0.00           30.73   \n",
       "2              0.0          0.0           56.49           99.36   \n",
       "3              0.0          0.0           76.03           95.98   \n",
       "4              0.0          0.0           63.26           42.94   \n",
       "...            ...          ...             ...             ...   \n",
       "69994          0.0          0.0            0.00          496.68   \n",
       "69995          0.0          0.0          166.21          292.74   \n",
       "69996          0.0          0.0          412.68          296.39   \n",
       "69997          0.0          0.0           39.78           24.33   \n",
       "69998          0.0          0.0            0.00            0.00   \n",
       "\n",
       "       total_og_mou_8  loc_ic_t2t_mou_6  loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  \\\n",
       "0                3.63              2.43              3.68              7.79   \n",
       "1               31.66              1.68             19.09             10.53   \n",
       "2                0.00              4.51              6.16              6.49   \n",
       "3               53.84             24.98              4.84             23.88   \n",
       "4               15.76              5.44              1.39              2.66   \n",
       "...               ...               ...               ...               ...   \n",
       "69994          392.58              0.00             26.59             33.84   \n",
       "69995          280.69             30.48             28.48             23.09   \n",
       "69996          342.29             46.41             30.29             86.53   \n",
       "69997           19.28             11.36              3.64              1.04   \n",
       "69998            0.00              2.21              4.31              0.96   \n",
       "\n",
       "       loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  loc_ic_t2f_mou_6  \\\n",
       "0                  0.83             21.08             16.91              0.00   \n",
       "1                  1.41             18.68             11.09              0.35   \n",
       "2                 89.86             25.18             23.51              0.00   \n",
       "3                 53.99             44.23             57.14              7.23   \n",
       "4                 10.58              4.33             19.49              5.51   \n",
       "...                 ...               ...               ...               ...   \n",
       "69994              0.00            172.33            223.91              0.00   \n",
       "69995             21.78             35.18             28.79              2.38   \n",
       "69996            143.94            147.01            177.73             21.35   \n",
       "69997              0.66              1.68              3.94              0.34   \n",
       "69998              2.68             38.71             31.69              0.43   \n",
       "\n",
       "       loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  loc_ic_mou_6  loc_ic_mou_7  \\\n",
       "0                 0.000             0.000        3.2600         24.76   \n",
       "1                 1.660             3.400        3.4400         39.44   \n",
       "2                 0.000             0.000       94.3800         31.34   \n",
       "3                 0.810             0.000       86.2100         49.89   \n",
       "4                 3.630             6.140       21.5400          9.36   \n",
       "...                 ...               ...           ...           ...   \n",
       "69994             1.060             0.000        0.0000        199.99   \n",
       "69995             0.210             0.000       54.6400         63.88   \n",
       "69996            22.075            21.225      482.6175        413.48   \n",
       "69997             4.280             2.810       12.3800          9.61   \n",
       "69998             5.780             0.000        5.3300         48.81   \n",
       "\n",
       "       loc_ic_mou_8  std_ic_t2t_mou_6  std_ic_t2t_mou_7  std_ic_t2t_mou_8  \\\n",
       "0             24.71             0.000           7.61000             0.210   \n",
       "1             25.03             0.000           0.00000             0.000   \n",
       "2             30.01            10.125           0.00000             0.000   \n",
       "3             81.03             0.000           0.00000             0.000   \n",
       "4             28.31             0.000           0.00000             0.000   \n",
       "...             ...               ...               ...               ...   \n",
       "69994        257.76             0.000           0.00000             0.000   \n",
       "69995         51.89            10.125          10.76875            10.075   \n",
       "69996        412.01             0.000           0.00000             0.000   \n",
       "69997          7.81             3.700           4.61000             1.300   \n",
       "69998         32.66             0.000           0.00000             0.000   \n",
       "\n",
       "       std_ic_t2m_mou_6  std_ic_t2m_mou_7  std_ic_t2m_mou_8  std_ic_t2f_mou_6  \\\n",
       "0                  7.46             19.96             14.96               0.0   \n",
       "1                  0.00              0.00              0.00               0.0   \n",
       "2                 18.21              2.48              6.38               0.0   \n",
       "3                  8.89              0.28              2.81               0.0   \n",
       "4                  0.00              0.00              0.00               0.0   \n",
       "...                 ...               ...               ...               ...   \n",
       "69994              0.00             21.99             11.79               0.0   \n",
       "69995              8.96              9.31             17.24               0.0   \n",
       "69996              0.00              0.00              0.00               0.0   \n",
       "69997              2.74              2.01              7.36               0.0   \n",
       "69998              0.00             16.28              0.00               0.0   \n",
       "\n",
       "       std_ic_t2f_mou_7  std_ic_t2f_mou_8  std_ic_mou_6  std_ic_mou_7  \\\n",
       "0                   0.0               0.0          7.46         27.58   \n",
       "1                   0.0               0.0          0.00          0.00   \n",
       "2                   0.0               0.0         29.91          2.48   \n",
       "3                   0.0               0.0          8.89          0.28   \n",
       "4                   0.0               0.0          0.00          0.00   \n",
       "...                 ...               ...           ...           ...   \n",
       "69994               0.0               0.0          0.00         21.99   \n",
       "69995               0.0               0.0         25.59         48.54   \n",
       "69996               0.0               0.0          2.50          0.00   \n",
       "69997               0.0               0.0          6.44          6.63   \n",
       "69998               0.0               0.0          0.00         16.28   \n",
       "\n",
       "       std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  total_ic_mou_8  \\\n",
       "0            15.180           11.84           53.04           40.56   \n",
       "1             0.000            3.44           39.44           25.04   \n",
       "2             6.380          124.29           33.83           36.64   \n",
       "3             2.810           95.11           50.18           83.84   \n",
       "4             0.000           21.54            9.36           28.31   \n",
       "...             ...             ...             ...             ...   \n",
       "69994        11.790            0.00          221.99          269.56   \n",
       "69995        69.215           80.24          112.43          136.01   \n",
       "69996         2.480          542.18          416.58          414.54   \n",
       "69997         9.940           18.83           16.24           17.76   \n",
       "69998         0.000            8.13           65.09           33.58   \n",
       "\n",
       "       spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "0               0.0           0.0           0.0           0.0           0.0   \n",
       "1               0.0           0.0           0.0           0.0           0.0   \n",
       "2               0.0           0.0           0.0           0.0           0.0   \n",
       "3               0.0           0.0           0.0           0.0           0.0   \n",
       "4               0.0           0.0           0.0           0.0           0.0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "69994           0.0           0.0           0.0           0.0           0.0   \n",
       "69995           0.0           0.0           0.0           0.0           0.0   \n",
       "69996           0.0           0.0           0.0           0.0           0.0   \n",
       "69997           0.0           0.0           0.0           0.0           0.0   \n",
       "69998           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "       isd_ic_mou_8  ic_others_6  ic_others_7  ic_others_8  total_rech_num_6  \\\n",
       "0               0.0          0.0          0.0          0.0                 3   \n",
       "1               0.0          0.0          0.0          0.0                 3   \n",
       "2               0.0          0.0          0.0          0.0                 2   \n",
       "3               0.0          0.0          0.0          0.0                 2   \n",
       "4               0.0          0.0          0.0          0.0                13   \n",
       "...             ...          ...          ...          ...               ...   \n",
       "69994           0.0          0.0          0.0          0.0                 1   \n",
       "69995           0.0          0.0          0.0          0.0                 5   \n",
       "69996           0.0          0.0          0.0          0.0                 3   \n",
       "69997           0.0          0.0          0.0          0.0                 5   \n",
       "69998           0.0          0.0          0.0          0.0                 2   \n",
       "\n",
       "       total_rech_num_7  total_rech_num_8  total_rech_amt_6  total_rech_amt_7  \\\n",
       "0                     2                 2              77.0              65.0   \n",
       "1                     4                 5               0.0             145.0   \n",
       "2                     4                 2              70.0             120.0   \n",
       "3                     4                 3             160.0             240.0   \n",
       "4                    10                 8             290.0             136.0   \n",
       "...                 ...               ...               ...               ...   \n",
       "69994                17                13              50.0             397.0   \n",
       "69995                11                 9             200.0             313.0   \n",
       "69996                 1                 4             626.0             250.0   \n",
       "69997                 3                 2             379.0             252.0   \n",
       "69998                 2                 2             198.0              50.0   \n",
       "\n",
       "       total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  max_rech_amt_8  \\\n",
       "0                    10              65              65            10.0   \n",
       "1                    50               0             145            50.0   \n",
       "2                     0              70              70             0.0   \n",
       "3                   130             110             110            50.0   \n",
       "4                   122              50              41            30.0   \n",
       "...                 ...             ...             ...             ...   \n",
       "69994               512              50             110           130.0   \n",
       "69995               308              90              44            44.0   \n",
       "69996               397             246             250           317.5   \n",
       "69997               145             200             252           145.0   \n",
       "69998               198             198              50           198.0   \n",
       "\n",
       "       date_of_last_rech_6  date_of_last_rech_7  date_of_last_rech_8  \\\n",
       "0                      8.0                 16.0                  7.0   \n",
       "1                     18.0                 16.0                  5.0   \n",
       "2                     19.0                  9.0                  7.0   \n",
       "3                     15.0                 10.0                  6.0   \n",
       "4                      5.0                  5.0                  1.0   \n",
       "...                    ...                  ...                  ...   \n",
       "69994                 12.0                  0.0                  0.0   \n",
       "69995                  2.0                  0.0                  4.0   \n",
       "69996                  5.0                  1.0                  2.0   \n",
       "69997                  1.0                 12.0                  5.0   \n",
       "69998                 11.0                  4.0                  6.0   \n",
       "\n",
       "       last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "0                      65                  65                   0   \n",
       "1                       0                   0                   0   \n",
       "2                      70                  50                   0   \n",
       "3                     110                 110                  50   \n",
       "4                      25                  10                  30   \n",
       "...                   ...                 ...                 ...   \n",
       "69994                  50                  20                 130   \n",
       "69995                  50                  30                  42   \n",
       "69996                 260                 250                  48   \n",
       "69997                   0                   0                   0   \n",
       "69998                 198                   0                   0   \n",
       "\n",
       "       vol_2g_mb_6  vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  vol_3g_mb_7  \\\n",
       "0              0.0          0.0          0.0          0.0          0.0   \n",
       "1              0.0          0.0          0.0          0.0          0.0   \n",
       "2              0.0          0.0          0.0          0.0          0.0   \n",
       "3              0.0          0.0          0.0          0.0          0.0   \n",
       "4              0.0          0.0          0.0          0.0          0.0   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "69994          0.0          0.0          0.0          0.0          0.0   \n",
       "69995          0.0          0.0          0.0          0.0          0.0   \n",
       "69996          0.0          0.0          0.0          0.0          0.0   \n",
       "69997          0.0          0.0          0.0          0.0          0.0   \n",
       "69998          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "       vol_3g_mb_8  monthly_2g_6  monthly_2g_7  monthly_2g_8  sachet_2g_6  \\\n",
       "0              0.0             0             0             0            0   \n",
       "1              0.0             0             0             0            0   \n",
       "2              0.0             0             0             0            0   \n",
       "3              0.0             0             0             0            0   \n",
       "4              0.0             0             0             0            0   \n",
       "...            ...           ...           ...           ...          ...   \n",
       "69994          0.0             0             0             0            0   \n",
       "69995          0.0             0             0             0            0   \n",
       "69996          0.0             0             0             0            0   \n",
       "69997          0.0             0             0             0            0   \n",
       "69998          0.0             0             0             0            0   \n",
       "\n",
       "       sachet_2g_7  sachet_2g_8  monthly_3g_6  monthly_3g_7  monthly_3g_8  \\\n",
       "0                0            0             0             0             0   \n",
       "1                0            0             0             0             0   \n",
       "2                0            0             0             0             0   \n",
       "3                0            0             0             0             0   \n",
       "4                0            0             0             0             0   \n",
       "...            ...          ...           ...           ...           ...   \n",
       "69994            0            0             0             0             0   \n",
       "69995            0            0             0             0             0   \n",
       "69996            0            0             0             0             0   \n",
       "69997            0            0             0             0             0   \n",
       "69998            0            0             0             0             0   \n",
       "\n",
       "       sachet_3g_6  sachet_3g_7  sachet_3g_8     aon  aug_vbc_3g  jul_vbc_3g  \\\n",
       "0                0            0            0  1958.0         0.0         0.0   \n",
       "1                0            0            0   710.0         0.0         0.0   \n",
       "2                0            0            0   882.0         0.0         0.0   \n",
       "3                0            0            0   982.0         0.0         0.0   \n",
       "4                0            0            0   647.0         0.0         0.0   \n",
       "...            ...          ...          ...     ...         ...         ...   \n",
       "69994            0            0            0   221.0         0.0         0.0   \n",
       "69995            0            0            0   712.0         0.0         0.0   \n",
       "69996            0            0            0   879.0         0.0         0.0   \n",
       "69997            0            0            0   277.0         0.0         0.0   \n",
       "69998            0            0            0  1876.0         0.0         0.0   \n",
       "\n",
       "       jun_vbc_3g  churn_probability  avg_rech_amt_6_7  days_stayed  \\\n",
       "0             0.0                  0              71.0         -1.0   \n",
       "1             0.0                  0              72.5        -13.0   \n",
       "2             0.0                  0              95.0        -12.0   \n",
       "3             0.0                  0             200.0         -9.0   \n",
       "4             0.0                  0             213.0         -4.0   \n",
       "...           ...                ...               ...          ...   \n",
       "69994         0.0                  0             223.5        -12.0   \n",
       "69995         0.0                  0             256.5          2.0   \n",
       "69996         0.0                  0             438.0         -3.0   \n",
       "69997         0.0                  0             315.5          4.0   \n",
       "69998         0.0                  0             124.0         -5.0   \n",
       "\n",
       "       avg_3g_6_7  avg_2g_6_7  avg_total_6_7  avg_mou_action  avg_arpu_action  \\\n",
       "0             0.0         0.0        151.445         159.455          47.2680   \n",
       "1             0.0         0.0         15.365          63.435          82.8700   \n",
       "2             0.0         0.0         77.925          84.915          51.5880   \n",
       "3             0.0         0.0         86.005         141.920         158.1775   \n",
       "4             0.0         0.0         53.100          48.185         114.8780   \n",
       "...           ...         ...            ...             ...              ...   \n",
       "69994         0.0         0.0        248.340         690.405         370.0300   \n",
       "69995         0.0         0.0        229.475         410.935         277.4505   \n",
       "69996         0.0         0.0        354.535         734.900         269.0780   \n",
       "69997         0.0         0.0         32.055          38.805         195.2380   \n",
       "69998         0.0         0.0          0.000          49.335         105.3880   \n",
       "\n",
       "       diff_arpu  decrease_arpu_action  avg_rech_amt_action  diff_rech_amt  \\\n",
       "0        15.9910                     0                 37.5          -39.5   \n",
       "1        82.8700                     0                 97.5           97.5   \n",
       "2        -9.2180                     1                 60.0          -10.0   \n",
       "3         1.8155                     0                185.0           25.0   \n",
       "4      -125.8300                     1                129.0         -161.0   \n",
       "...          ...                   ...                  ...            ...   \n",
       "69994   354.2700                     0                454.5          404.5   \n",
       "69995   117.3675                     0                310.5          110.5   \n",
       "69996  -103.0100                     1                323.5         -302.5   \n",
       "69997   -43.3370                     1                198.5         -180.5   \n",
       "69998   -62.8810                     1                124.0          -74.0   \n",
       "\n",
       "       decrease_rech_amt_action  total_mou_good  diff_mou  \\\n",
       "0                             1           93.05    66.405   \n",
       "1                             0            3.44    59.995   \n",
       "2                             1          180.78   -95.865   \n",
       "3                             0          171.14   -29.220   \n",
       "4                             1           84.80   -36.615   \n",
       "...                         ...             ...       ...   \n",
       "69994                         0            0.00   690.405   \n",
       "69995                         0          246.45   164.485   \n",
       "69996                         1          954.86  -219.960   \n",
       "69997                         1           58.61   -19.805   \n",
       "69998                         1            8.13    41.205   \n",
       "\n",
       "       decrease_mou_action  High_valued_good  High_valued_action Category  \\\n",
       "0                        0              77.0                37.5      NaN   \n",
       "1                        0               0.0                97.5      NaN   \n",
       "2                        1              70.0                60.0      NaN   \n",
       "3                        1             160.0               185.0      NaN   \n",
       "4                        1             290.0               129.0      NaN   \n",
       "...                    ...               ...                 ...      ...   \n",
       "69994                    0              50.0               454.5      NaN   \n",
       "69995                    0             200.0               310.5      NaN   \n",
       "69996                    1             626.0               323.5      NaN   \n",
       "69997                    1             379.0               198.5      NaN   \n",
       "69998                    0             198.0               124.0      NaN   \n",
       "\n",
       "       avg_rech_num_action  diff_rech_num  decrease_rech_num_action  \n",
       "0                      2.0           -1.0                         1  \n",
       "1                      4.5            1.5                         0  \n",
       "2                      3.0            1.0                         0  \n",
       "3                      3.5            1.5                         0  \n",
       "4                      9.0           -4.0                         1  \n",
       "...                    ...            ...                       ...  \n",
       "69994                 15.0           14.0                         0  \n",
       "69995                 10.0            5.0                         0  \n",
       "69996                  2.5           -0.5                         1  \n",
       "69997                  2.5           -2.5                         1  \n",
       "69998                  2.0            0.0                         0  \n",
       "\n",
       "[61895 rows x 149 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c3326251",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Category'], axis=1,inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da6064e",
   "metadata": {},
   "source": [
    "##### Scaling the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3791ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['churn_probability'], axis=1)\n",
    "y=data['churn_probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d454922d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61895, 147)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_copy=X.copy() ## will use copy data for further analysis.\n",
    "X_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f295d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "280b2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature Scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eb31375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = pd.DataFrame(data=ss.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7326f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2554f4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>avg_rech_amt_6_7</th>\n",
       "      <th>days_stayed</th>\n",
       "      <th>avg_3g_6_7</th>\n",
       "      <th>avg_2g_6_7</th>\n",
       "      <th>avg_total_6_7</th>\n",
       "      <th>avg_mou_action</th>\n",
       "      <th>avg_arpu_action</th>\n",
       "      <th>diff_arpu</th>\n",
       "      <th>decrease_arpu_action</th>\n",
       "      <th>avg_rech_amt_action</th>\n",
       "      <th>diff_rech_amt</th>\n",
       "      <th>decrease_rech_amt_action</th>\n",
       "      <th>total_mou_good</th>\n",
       "      <th>diff_mou</th>\n",
       "      <th>decrease_mou_action</th>\n",
       "      <th>High_valued_good</th>\n",
       "      <th>High_valued_action</th>\n",
       "      <th>avg_rech_num_action</th>\n",
       "      <th>diff_rech_num</th>\n",
       "      <th>decrease_rech_num_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>61895.0</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "      <td>6.189500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.242115e-16</td>\n",
       "      <td>-3.834256e-17</td>\n",
       "      <td>-8.104745e-17</td>\n",
       "      <td>7.657032e-17</td>\n",
       "      <td>1.883837e-16</td>\n",
       "      <td>4.867439e-17</td>\n",
       "      <td>8.862412e-17</td>\n",
       "      <td>2.999100e-16</td>\n",
       "      <td>-5.969500e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.862412e-17</td>\n",
       "      <td>3.730938e-17</td>\n",
       "      <td>-1.145685e-16</td>\n",
       "      <td>-8.360170e-17</td>\n",
       "      <td>-1.134205e-16</td>\n",
       "      <td>-5.097035e-17</td>\n",
       "      <td>-4.632103e-17</td>\n",
       "      <td>-5.165914e-17</td>\n",
       "      <td>8.954250e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.071562e-17</td>\n",
       "      <td>1.377577e-17</td>\n",
       "      <td>-1.090582e-17</td>\n",
       "      <td>1.375281e-16</td>\n",
       "      <td>-7.203580e-17</td>\n",
       "      <td>6.267975e-17</td>\n",
       "      <td>-8.173624e-17</td>\n",
       "      <td>-3.329144e-18</td>\n",
       "      <td>-3.420983e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.701695e-17</td>\n",
       "      <td>-1.721971e-18</td>\n",
       "      <td>-3.306185e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.739904e-19</td>\n",
       "      <td>1.125021e-16</td>\n",
       "      <td>-1.030887e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.116877e-16</td>\n",
       "      <td>9.505281e-17</td>\n",
       "      <td>1.012519e-16</td>\n",
       "      <td>8.460619e-17</td>\n",
       "      <td>-2.047998e-16</td>\n",
       "      <td>3.329144e-18</td>\n",
       "      <td>-8.139184e-17</td>\n",
       "      <td>-1.834473e-16</td>\n",
       "      <td>1.029739e-16</td>\n",
       "      <td>3.535781e-17</td>\n",
       "      <td>1.515335e-17</td>\n",
       "      <td>8.942771e-17</td>\n",
       "      <td>-7.806270e-18</td>\n",
       "      <td>1.666868e-16</td>\n",
       "      <td>-2.321217e-16</td>\n",
       "      <td>-1.578474e-17</td>\n",
       "      <td>9.729138e-17</td>\n",
       "      <td>-1.067622e-17</td>\n",
       "      <td>-8.311381e-17</td>\n",
       "      <td>-3.019190e-17</td>\n",
       "      <td>7.714431e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.529110e-16</td>\n",
       "      <td>2.557127e-17</td>\n",
       "      <td>-6.692728e-17</td>\n",
       "      <td>7.875149e-17</td>\n",
       "      <td>-6.497572e-17</td>\n",
       "      <td>2.468159e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.384030e-17</td>\n",
       "      <td>1.813810e-17</td>\n",
       "      <td>-4.850219e-17</td>\n",
       "      <td>-3.670669e-17</td>\n",
       "      <td>-2.295962e-18</td>\n",
       "      <td>-3.271745e-17</td>\n",
       "      <td>5.811653e-17</td>\n",
       "      <td>-5.051116e-17</td>\n",
       "      <td>-5.326631e-17</td>\n",
       "      <td>2.697755e-18</td>\n",
       "      <td>-7.048602e-17</td>\n",
       "      <td>-6.767347e-17</td>\n",
       "      <td>5.429949e-17</td>\n",
       "      <td>-3.214346e-18</td>\n",
       "      <td>2.938831e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.683762e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.963047e-17</td>\n",
       "      <td>-1.251299e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.362684e-17</td>\n",
       "      <td>5.257752e-17</td>\n",
       "      <td>6.520531e-17</td>\n",
       "      <td>-3.214346e-18</td>\n",
       "      <td>9.000170e-17</td>\n",
       "      <td>-9.872635e-18</td>\n",
       "      <td>1.285739e-17</td>\n",
       "      <td>-2.077845e-17</td>\n",
       "      <td>-1.917128e-17</td>\n",
       "      <td>-1.676052e-17</td>\n",
       "      <td>6.887885e-18</td>\n",
       "      <td>-3.670669e-17</td>\n",
       "      <td>-9.872635e-18</td>\n",
       "      <td>-1.595693e-17</td>\n",
       "      <td>1.928608e-17</td>\n",
       "      <td>-9.367524e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.666070e+00</td>\n",
       "      <td>-2.687852e+00</td>\n",
       "      <td>-2.702873e+00</td>\n",
       "      <td>-8.314304e-01</td>\n",
       "      <td>-8.276309e-01</td>\n",
       "      <td>-8.271412e-01</td>\n",
       "      <td>-9.826769e-01</td>\n",
       "      <td>-9.775988e-01</td>\n",
       "      <td>-9.692114e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.245873e-01</td>\n",
       "      <td>-8.324397e-01</td>\n",
       "      <td>-8.306557e-01</td>\n",
       "      <td>-9.107143e-01</td>\n",
       "      <td>-9.231795e-01</td>\n",
       "      <td>-9.152045e-01</td>\n",
       "      <td>-6.475615e-01</td>\n",
       "      <td>-6.537188e-01</td>\n",
       "      <td>-6.505174e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.287558e-01</td>\n",
       "      <td>-9.412623e-01</td>\n",
       "      <td>-9.343995e-01</td>\n",
       "      <td>-6.435217e-01</td>\n",
       "      <td>-6.461462e-01</td>\n",
       "      <td>-6.414731e-01</td>\n",
       "      <td>-6.894614e-01</td>\n",
       "      <td>-6.881476e-01</td>\n",
       "      <td>-6.874127e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.913001e-01</td>\n",
       "      <td>-6.893241e-01</td>\n",
       "      <td>-6.870157e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.495700e-01</td>\n",
       "      <td>-6.663471e-01</td>\n",
       "      <td>-6.726877e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.661976e-01</td>\n",
       "      <td>-9.597888e-01</td>\n",
       "      <td>-9.574239e-01</td>\n",
       "      <td>-8.696839e-01</td>\n",
       "      <td>-8.863007e-01</td>\n",
       "      <td>-8.828349e-01</td>\n",
       "      <td>-9.903441e-01</td>\n",
       "      <td>-1.013476e+00</td>\n",
       "      <td>-1.005423e+00</td>\n",
       "      <td>-7.066906e-01</td>\n",
       "      <td>-7.105112e-01</td>\n",
       "      <td>-7.117284e-01</td>\n",
       "      <td>-1.015500e+00</td>\n",
       "      <td>-1.041535e+00</td>\n",
       "      <td>-1.033159e+00</td>\n",
       "      <td>-6.421708e-01</td>\n",
       "      <td>-6.462870e-01</td>\n",
       "      <td>-6.425738e-01</td>\n",
       "      <td>-7.221974e-01</td>\n",
       "      <td>-7.226772e-01</td>\n",
       "      <td>-7.216824e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.667049e-01</td>\n",
       "      <td>-7.668715e-01</td>\n",
       "      <td>-7.628069e-01</td>\n",
       "      <td>-1.064639e+00</td>\n",
       "      <td>-1.090587e+00</td>\n",
       "      <td>-1.080941e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.283822e+00</td>\n",
       "      <td>-1.320502e+00</td>\n",
       "      <td>-1.215636e+00</td>\n",
       "      <td>-1.183014e+00</td>\n",
       "      <td>-1.177371e+00</td>\n",
       "      <td>-1.184453e+00</td>\n",
       "      <td>-1.394782e+00</td>\n",
       "      <td>-1.341818e+00</td>\n",
       "      <td>-1.303107e+00</td>\n",
       "      <td>-9.560140e-01</td>\n",
       "      <td>-1.017196e+00</td>\n",
       "      <td>-1.052717e+00</td>\n",
       "      <td>-9.264382e-01</td>\n",
       "      <td>-8.579539e-01</td>\n",
       "      <td>-8.302388e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.123639e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.289479e+00</td>\n",
       "      <td>-3.152894e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.030640e+00</td>\n",
       "      <td>-1.282522e+00</td>\n",
       "      <td>-1.476881e+00</td>\n",
       "      <td>-4.983328e+00</td>\n",
       "      <td>-9.447043e-01</td>\n",
       "      <td>-1.285073e+00</td>\n",
       "      <td>-4.679666e+00</td>\n",
       "      <td>-9.324330e-01</td>\n",
       "      <td>-1.205228e+00</td>\n",
       "      <td>-5.541415e+00</td>\n",
       "      <td>-9.521107e-01</td>\n",
       "      <td>-1.183014e+00</td>\n",
       "      <td>-1.285073e+00</td>\n",
       "      <td>-1.376613e+00</td>\n",
       "      <td>-4.612285e+00</td>\n",
       "      <td>-9.798935e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.732983e-01</td>\n",
       "      <td>-7.737837e-01</td>\n",
       "      <td>-7.695770e-01</td>\n",
       "      <td>-7.512964e-01</td>\n",
       "      <td>-7.504001e-01</td>\n",
       "      <td>-7.529977e-01</td>\n",
       "      <td>-7.634526e-01</td>\n",
       "      <td>-7.643189e-01</td>\n",
       "      <td>-7.643240e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.683298e-01</td>\n",
       "      <td>-7.698022e-01</td>\n",
       "      <td>-7.727395e-01</td>\n",
       "      <td>-7.803460e-01</td>\n",
       "      <td>-7.775730e-01</td>\n",
       "      <td>-7.803326e-01</td>\n",
       "      <td>-6.475615e-01</td>\n",
       "      <td>-6.537188e-01</td>\n",
       "      <td>-6.505174e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.794142e-01</td>\n",
       "      <td>-7.742633e-01</td>\n",
       "      <td>-7.783132e-01</td>\n",
       "      <td>-6.435217e-01</td>\n",
       "      <td>-6.461462e-01</td>\n",
       "      <td>-6.414731e-01</td>\n",
       "      <td>-6.894614e-01</td>\n",
       "      <td>-6.881476e-01</td>\n",
       "      <td>-6.874127e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.913001e-01</td>\n",
       "      <td>-6.893241e-01</td>\n",
       "      <td>-6.870157e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.495700e-01</td>\n",
       "      <td>-6.663471e-01</td>\n",
       "      <td>-6.726877e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.642842e-01</td>\n",
       "      <td>-7.612539e-01</td>\n",
       "      <td>-7.643040e-01</td>\n",
       "      <td>-7.770734e-01</td>\n",
       "      <td>-7.787037e-01</td>\n",
       "      <td>-7.801378e-01</td>\n",
       "      <td>-7.849231e-01</td>\n",
       "      <td>-7.798813e-01</td>\n",
       "      <td>-7.835678e-01</td>\n",
       "      <td>-7.066906e-01</td>\n",
       "      <td>-7.105112e-01</td>\n",
       "      <td>-7.117284e-01</td>\n",
       "      <td>-7.821597e-01</td>\n",
       "      <td>-7.762977e-01</td>\n",
       "      <td>-7.818770e-01</td>\n",
       "      <td>-6.421708e-01</td>\n",
       "      <td>-6.462870e-01</td>\n",
       "      <td>-6.425738e-01</td>\n",
       "      <td>-7.221974e-01</td>\n",
       "      <td>-7.226772e-01</td>\n",
       "      <td>-7.216824e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.645433e-01</td>\n",
       "      <td>-7.628452e-01</td>\n",
       "      <td>-7.594539e-01</td>\n",
       "      <td>-7.736506e-01</td>\n",
       "      <td>-7.709977e-01</td>\n",
       "      <td>-7.731335e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.747658e-01</td>\n",
       "      <td>-7.159629e-01</td>\n",
       "      <td>-8.110321e-01</td>\n",
       "      <td>-7.695782e-01</td>\n",
       "      <td>-7.665723e-01</td>\n",
       "      <td>-7.312047e-01</td>\n",
       "      <td>-8.738298e-01</td>\n",
       "      <td>-8.925908e-01</td>\n",
       "      <td>-8.958531e-01</td>\n",
       "      <td>-7.803075e-01</td>\n",
       "      <td>-8.105984e-01</td>\n",
       "      <td>-8.393787e-01</td>\n",
       "      <td>-7.725829e-01</td>\n",
       "      <td>-8.579539e-01</td>\n",
       "      <td>-8.302388e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.103262e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.777993e-01</td>\n",
       "      <td>-5.374735e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.699308e-01</td>\n",
       "      <td>-7.997085e-01</td>\n",
       "      <td>-7.803437e-01</td>\n",
       "      <td>-4.355441e-01</td>\n",
       "      <td>-9.447043e-01</td>\n",
       "      <td>-7.784071e-01</td>\n",
       "      <td>-4.572163e-01</td>\n",
       "      <td>-9.324330e-01</td>\n",
       "      <td>-8.065288e-01</td>\n",
       "      <td>-3.920468e-01</td>\n",
       "      <td>-9.521107e-01</td>\n",
       "      <td>-7.695782e-01</td>\n",
       "      <td>-7.784071e-01</td>\n",
       "      <td>-7.190976e-01</td>\n",
       "      <td>-5.027307e-01</td>\n",
       "      <td>-9.798935e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.875264e-01</td>\n",
       "      <td>-2.894409e-01</td>\n",
       "      <td>-2.876750e-01</td>\n",
       "      <td>-4.741704e-01</td>\n",
       "      <td>-4.766836e-01</td>\n",
       "      <td>-4.782243e-01</td>\n",
       "      <td>-3.861914e-01</td>\n",
       "      <td>-3.913279e-01</td>\n",
       "      <td>-3.916020e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.561159e-01</td>\n",
       "      <td>-4.542399e-01</td>\n",
       "      <td>-4.528499e-01</td>\n",
       "      <td>-3.989647e-01</td>\n",
       "      <td>-3.959856e-01</td>\n",
       "      <td>-3.993196e-01</td>\n",
       "      <td>-6.475615e-01</td>\n",
       "      <td>-6.537188e-01</td>\n",
       "      <td>-6.505174e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.915564e-01</td>\n",
       "      <td>-3.916078e-01</td>\n",
       "      <td>-3.944602e-01</td>\n",
       "      <td>-6.435217e-01</td>\n",
       "      <td>-6.461462e-01</td>\n",
       "      <td>-6.414731e-01</td>\n",
       "      <td>-6.071367e-01</td>\n",
       "      <td>-6.100943e-01</td>\n",
       "      <td>-6.161012e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.020874e-01</td>\n",
       "      <td>-6.056645e-01</td>\n",
       "      <td>-6.073543e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.495700e-01</td>\n",
       "      <td>-6.663471e-01</td>\n",
       "      <td>-6.726877e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.921139e-01</td>\n",
       "      <td>-4.016292e-01</td>\n",
       "      <td>-3.979748e-01</td>\n",
       "      <td>-4.225152e-01</td>\n",
       "      <td>-4.135838e-01</td>\n",
       "      <td>-4.135586e-01</td>\n",
       "      <td>-3.558265e-01</td>\n",
       "      <td>-3.523810e-01</td>\n",
       "      <td>-3.526206e-01</td>\n",
       "      <td>-5.770435e-01</td>\n",
       "      <td>-5.719806e-01</td>\n",
       "      <td>-5.711650e-01</td>\n",
       "      <td>-3.435242e-01</td>\n",
       "      <td>-3.410298e-01</td>\n",
       "      <td>-3.402228e-01</td>\n",
       "      <td>-6.421708e-01</td>\n",
       "      <td>-6.462870e-01</td>\n",
       "      <td>-6.425738e-01</td>\n",
       "      <td>-5.630755e-01</td>\n",
       "      <td>-5.635580e-01</td>\n",
       "      <td>-5.682613e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.038545e-01</td>\n",
       "      <td>-5.059665e-01</td>\n",
       "      <td>-5.109114e-01</td>\n",
       "      <td>-3.281968e-01</td>\n",
       "      <td>-3.240508e-01</td>\n",
       "      <td>-3.246245e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.687281e-01</td>\n",
       "      <td>-3.129369e-01</td>\n",
       "      <td>-2.041259e-01</td>\n",
       "      <td>-2.809722e-01</td>\n",
       "      <td>-2.810828e-01</td>\n",
       "      <td>-2.556656e-01</td>\n",
       "      <td>1.970165e-01</td>\n",
       "      <td>1.556054e-01</td>\n",
       "      <td>1.037711e-01</td>\n",
       "      <td>-4.288946e-01</td>\n",
       "      <td>-3.974035e-01</td>\n",
       "      <td>-1.993648e-01</td>\n",
       "      <td>-4.648724e-01</td>\n",
       "      <td>-4.093740e-01</td>\n",
       "      <td>-4.302502e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.512863e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.865862e-01</td>\n",
       "      <td>7.791964e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.759471e-01</td>\n",
       "      <td>-2.632302e-01</td>\n",
       "      <td>-2.914210e-01</td>\n",
       "      <td>2.610324e-02</td>\n",
       "      <td>-9.447043e-01</td>\n",
       "      <td>-2.798477e-01</td>\n",
       "      <td>8.098618e-03</td>\n",
       "      <td>-9.324330e-01</td>\n",
       "      <td>-2.744619e-01</td>\n",
       "      <td>-2.220750e-02</td>\n",
       "      <td>-9.521107e-01</td>\n",
       "      <td>-2.809722e-01</td>\n",
       "      <td>-2.798477e-01</td>\n",
       "      <td>-2.807539e-01</td>\n",
       "      <td>1.096357e-02</td>\n",
       "      <td>-9.798935e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.098666e-01</td>\n",
       "      <td>5.055975e-01</td>\n",
       "      <td>5.168175e-01</td>\n",
       "      <td>4.079214e-01</td>\n",
       "      <td>4.092828e-01</td>\n",
       "      <td>4.093914e-01</td>\n",
       "      <td>4.587686e-01</td>\n",
       "      <td>4.523154e-01</td>\n",
       "      <td>4.562246e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.157269e-01</td>\n",
       "      <td>4.253567e-01</td>\n",
       "      <td>4.260962e-01</td>\n",
       "      <td>4.477090e-01</td>\n",
       "      <td>4.534970e-01</td>\n",
       "      <td>4.559127e-01</td>\n",
       "      <td>3.858462e-01</td>\n",
       "      <td>4.047180e-01</td>\n",
       "      <td>4.098200e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.437285e-01</td>\n",
       "      <td>4.530541e-01</td>\n",
       "      <td>4.530204e-01</td>\n",
       "      <td>4.167609e-01</td>\n",
       "      <td>4.235715e-01</td>\n",
       "      <td>4.227819e-01</td>\n",
       "      <td>4.007788e-01</td>\n",
       "      <td>4.090312e-01</td>\n",
       "      <td>4.124313e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.188090e-01</td>\n",
       "      <td>4.239245e-01</td>\n",
       "      <td>4.256709e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.184624e-01</td>\n",
       "      <td>4.398271e-01</td>\n",
       "      <td>4.438977e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.586646e-01</td>\n",
       "      <td>4.645216e-01</td>\n",
       "      <td>4.586118e-01</td>\n",
       "      <td>4.373624e-01</td>\n",
       "      <td>4.324455e-01</td>\n",
       "      <td>4.354771e-01</td>\n",
       "      <td>4.699377e-01</td>\n",
       "      <td>4.735285e-01</td>\n",
       "      <td>4.759848e-01</td>\n",
       "      <td>3.985187e-01</td>\n",
       "      <td>3.977338e-01</td>\n",
       "      <td>4.056202e-01</td>\n",
       "      <td>4.767514e-01</td>\n",
       "      <td>4.738985e-01</td>\n",
       "      <td>4.771985e-01</td>\n",
       "      <td>4.175402e-01</td>\n",
       "      <td>4.154080e-01</td>\n",
       "      <td>4.197861e-01</td>\n",
       "      <td>4.125737e-01</td>\n",
       "      <td>4.166443e-01</td>\n",
       "      <td>4.133430e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.061787e-01</td>\n",
       "      <td>4.120326e-01</td>\n",
       "      <td>4.174557e-01</td>\n",
       "      <td>4.777435e-01</td>\n",
       "      <td>4.737855e-01</td>\n",
       "      <td>4.792702e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.433472e-01</td>\n",
       "      <td>4.931151e-01</td>\n",
       "      <td>6.050824e-01</td>\n",
       "      <td>5.083146e-01</td>\n",
       "      <td>5.106384e-01</td>\n",
       "      <td>5.133702e-01</td>\n",
       "      <td>3.417254e-01</td>\n",
       "      <td>4.006382e-01</td>\n",
       "      <td>4.863433e-01</td>\n",
       "      <td>6.253441e-01</td>\n",
       "      <td>4.289864e-01</td>\n",
       "      <td>4.406492e-01</td>\n",
       "      <td>7.659698e-01</td>\n",
       "      <td>7.868391e-01</td>\n",
       "      <td>9.030452e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.906614e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.116349e-01</td>\n",
       "      <td>5.394645e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.097794e-01</td>\n",
       "      <td>6.019902e-01</td>\n",
       "      <td>5.137023e-01</td>\n",
       "      <td>4.360353e-01</td>\n",
       "      <td>1.058532e+00</td>\n",
       "      <td>5.186580e-01</td>\n",
       "      <td>4.740262e-01</td>\n",
       "      <td>1.072463e+00</td>\n",
       "      <td>6.211075e-01</td>\n",
       "      <td>3.539972e-01</td>\n",
       "      <td>1.050298e+00</td>\n",
       "      <td>5.083146e-01</td>\n",
       "      <td>5.186580e-01</td>\n",
       "      <td>4.863477e-01</td>\n",
       "      <td>5.246578e-01</td>\n",
       "      <td>1.020519e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.380928e+00</td>\n",
       "      <td>2.382962e+00</td>\n",
       "      <td>2.403427e+00</td>\n",
       "      <td>2.104097e+00</td>\n",
       "      <td>2.084283e+00</td>\n",
       "      <td>2.080464e+00</td>\n",
       "      <td>2.248851e+00</td>\n",
       "      <td>2.224520e+00</td>\n",
       "      <td>2.227522e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.180767e+00</td>\n",
       "      <td>2.179503e+00</td>\n",
       "      <td>2.175586e+00</td>\n",
       "      <td>2.273225e+00</td>\n",
       "      <td>2.266750e+00</td>\n",
       "      <td>2.264039e+00</td>\n",
       "      <td>1.984248e+00</td>\n",
       "      <td>1.980560e+00</td>\n",
       "      <td>1.975667e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.263959e+00</td>\n",
       "      <td>2.256762e+00</td>\n",
       "      <td>2.258120e+00</td>\n",
       "      <td>1.887675e+00</td>\n",
       "      <td>1.882189e+00</td>\n",
       "      <td>1.879467e+00</td>\n",
       "      <td>1.970642e+00</td>\n",
       "      <td>1.964460e+00</td>\n",
       "      <td>1.947476e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000192e+00</td>\n",
       "      <td>1.991374e+00</td>\n",
       "      <td>1.977866e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.943595e+00</td>\n",
       "      <td>2.019036e+00</td>\n",
       "      <td>2.036269e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.241963e+00</td>\n",
       "      <td>2.243143e+00</td>\n",
       "      <td>2.231159e+00</td>\n",
       "      <td>2.241382e+00</td>\n",
       "      <td>2.219129e+00</td>\n",
       "      <td>2.223134e+00</td>\n",
       "      <td>2.326243e+00</td>\n",
       "      <td>2.319091e+00</td>\n",
       "      <td>2.327026e+00</td>\n",
       "      <td>2.033869e+00</td>\n",
       "      <td>2.044501e+00</td>\n",
       "      <td>2.050732e+00</td>\n",
       "      <td>2.343110e+00</td>\n",
       "      <td>2.317986e+00</td>\n",
       "      <td>2.332290e+00</td>\n",
       "      <td>1.943269e+00</td>\n",
       "      <td>1.946259e+00</td>\n",
       "      <td>1.936529e+00</td>\n",
       "      <td>2.084848e+00</td>\n",
       "      <td>2.091185e+00</td>\n",
       "      <td>2.066346e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.137620e+00</td>\n",
       "      <td>2.144555e+00</td>\n",
       "      <td>2.138183e+00</td>\n",
       "      <td>2.335178e+00</td>\n",
       "      <td>2.313638e+00</td>\n",
       "      <td>2.325968e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.370517e+00</td>\n",
       "      <td>2.306732e+00</td>\n",
       "      <td>2.223499e+00</td>\n",
       "      <td>2.396965e+00</td>\n",
       "      <td>2.377439e+00</td>\n",
       "      <td>2.385805e+00</td>\n",
       "      <td>2.165058e+00</td>\n",
       "      <td>2.401740e+00</td>\n",
       "      <td>2.615173e+00</td>\n",
       "      <td>2.733821e+00</td>\n",
       "      <td>2.288364e+00</td>\n",
       "      <td>2.360691e+00</td>\n",
       "      <td>3.073799e+00</td>\n",
       "      <td>3.254029e+00</td>\n",
       "      <td>3.502971e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.981177e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.608245e+00</td>\n",
       "      <td>2.539492e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400292e+00</td>\n",
       "      <td>2.890754e+00</td>\n",
       "      <td>2.557814e+00</td>\n",
       "      <td>5.235868e+00</td>\n",
       "      <td>1.058532e+00</td>\n",
       "      <td>2.591682e+00</td>\n",
       "      <td>4.676564e+00</td>\n",
       "      <td>1.072463e+00</td>\n",
       "      <td>2.734357e+00</td>\n",
       "      <td>5.566996e+00</td>\n",
       "      <td>1.050298e+00</td>\n",
       "      <td>2.396965e+00</td>\n",
       "      <td>2.591682e+00</td>\n",
       "      <td>2.458894e+00</td>\n",
       "      <td>4.505788e+00</td>\n",
       "      <td>1.020519e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             arpu_6        arpu_7        arpu_8   onnet_mou_6   onnet_mou_7  \\\n",
       "count  6.189500e+04  6.189500e+04  6.189500e+04  6.189500e+04  6.189500e+04   \n",
       "mean  -1.242115e-16 -3.834256e-17 -8.104745e-17  7.657032e-17  1.883837e-16   \n",
       "std    1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00   \n",
       "min   -2.666070e+00 -2.687852e+00 -2.702873e+00 -8.314304e-01 -8.276309e-01   \n",
       "25%   -7.732983e-01 -7.737837e-01 -7.695770e-01 -7.512964e-01 -7.504001e-01   \n",
       "50%   -2.875264e-01 -2.894409e-01 -2.876750e-01 -4.741704e-01 -4.766836e-01   \n",
       "75%    5.098666e-01  5.055975e-01  5.168175e-01  4.079214e-01  4.092828e-01   \n",
       "max    2.380928e+00  2.382962e+00  2.403427e+00  2.104097e+00  2.084283e+00   \n",
       "\n",
       "        onnet_mou_8  offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  \\\n",
       "count  6.189500e+04  6.189500e+04  6.189500e+04  6.189500e+04        61895.0   \n",
       "mean   4.867439e-17  8.862412e-17  2.999100e-16 -5.969500e-18            0.0   \n",
       "std    1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00            0.0   \n",
       "min   -8.271412e-01 -9.826769e-01 -9.775988e-01 -9.692114e-01            0.0   \n",
       "25%   -7.529977e-01 -7.634526e-01 -7.643189e-01 -7.643240e-01            0.0   \n",
       "50%   -4.782243e-01 -3.861914e-01 -3.913279e-01 -3.916020e-01            0.0   \n",
       "75%    4.093914e-01  4.587686e-01  4.523154e-01  4.562246e-01            0.0   \n",
       "max    2.080464e+00  2.248851e+00  2.224520e+00  2.227522e+00            0.0   \n",
       "\n",
       "       roam_ic_mou_7  roam_ic_mou_8  roam_og_mou_6  roam_og_mou_7  \\\n",
       "count        61895.0        61895.0        61895.0        61895.0   \n",
       "mean             0.0            0.0            0.0            0.0   \n",
       "std              0.0            0.0            0.0            0.0   \n",
       "min              0.0            0.0            0.0            0.0   \n",
       "25%              0.0            0.0            0.0            0.0   \n",
       "50%              0.0            0.0            0.0            0.0   \n",
       "75%              0.0            0.0            0.0            0.0   \n",
       "max              0.0            0.0            0.0            0.0   \n",
       "\n",
       "       roam_og_mou_8  loc_og_t2t_mou_6  loc_og_t2t_mou_7  loc_og_t2t_mou_8  \\\n",
       "count        61895.0      6.189500e+04      6.189500e+04      6.189500e+04   \n",
       "mean             0.0     -8.862412e-17      3.730938e-17     -1.145685e-16   \n",
       "std              0.0      1.000008e+00      1.000008e+00      1.000008e+00   \n",
       "min              0.0     -8.245873e-01     -8.324397e-01     -8.306557e-01   \n",
       "25%              0.0     -7.683298e-01     -7.698022e-01     -7.727395e-01   \n",
       "50%              0.0     -4.561159e-01     -4.542399e-01     -4.528499e-01   \n",
       "75%              0.0      4.157269e-01      4.253567e-01      4.260962e-01   \n",
       "max              0.0      2.180767e+00      2.179503e+00      2.175586e+00   \n",
       "\n",
       "       loc_og_t2m_mou_6  loc_og_t2m_mou_7  loc_og_t2m_mou_8  loc_og_t2f_mou_6  \\\n",
       "count      6.189500e+04      6.189500e+04      6.189500e+04      6.189500e+04   \n",
       "mean      -8.360170e-17     -1.134205e-16     -5.097035e-17     -4.632103e-17   \n",
       "std        1.000008e+00      1.000008e+00      1.000008e+00      1.000008e+00   \n",
       "min       -9.107143e-01     -9.231795e-01     -9.152045e-01     -6.475615e-01   \n",
       "25%       -7.803460e-01     -7.775730e-01     -7.803326e-01     -6.475615e-01   \n",
       "50%       -3.989647e-01     -3.959856e-01     -3.993196e-01     -6.475615e-01   \n",
       "75%        4.477090e-01      4.534970e-01      4.559127e-01      3.858462e-01   \n",
       "max        2.273225e+00      2.266750e+00      2.264039e+00      1.984248e+00   \n",
       "\n",
       "       loc_og_t2f_mou_7  loc_og_t2f_mou_8  loc_og_t2c_mou_6  loc_og_t2c_mou_7  \\\n",
       "count      6.189500e+04      6.189500e+04           61895.0           61895.0   \n",
       "mean      -5.165914e-17      8.954250e-18               0.0               0.0   \n",
       "std        1.000008e+00      1.000008e+00               0.0               0.0   \n",
       "min       -6.537188e-01     -6.505174e-01               0.0               0.0   \n",
       "25%       -6.537188e-01     -6.505174e-01               0.0               0.0   \n",
       "50%       -6.537188e-01     -6.505174e-01               0.0               0.0   \n",
       "75%        4.047180e-01      4.098200e-01               0.0               0.0   \n",
       "max        1.980560e+00      1.975667e+00               0.0               0.0   \n",
       "\n",
       "       loc_og_t2c_mou_8  loc_og_mou_6  loc_og_mou_7  loc_og_mou_8  \\\n",
       "count           61895.0  6.189500e+04  6.189500e+04  6.189500e+04   \n",
       "mean                0.0  7.071562e-17  1.377577e-17 -1.090582e-17   \n",
       "std                 0.0  1.000008e+00  1.000008e+00  1.000008e+00   \n",
       "min                 0.0 -9.287558e-01 -9.412623e-01 -9.343995e-01   \n",
       "25%                 0.0 -7.794142e-01 -7.742633e-01 -7.783132e-01   \n",
       "50%                 0.0 -3.915564e-01 -3.916078e-01 -3.944602e-01   \n",
       "75%                 0.0  4.437285e-01  4.530541e-01  4.530204e-01   \n",
       "max                 0.0  2.263959e+00  2.256762e+00  2.258120e+00   \n",
       "\n",
       "       std_og_t2t_mou_6  std_og_t2t_mou_7  std_og_t2t_mou_8  std_og_t2m_mou_6  \\\n",
       "count      6.189500e+04      6.189500e+04      6.189500e+04      6.189500e+04   \n",
       "mean       1.375281e-16     -7.203580e-17      6.267975e-17     -8.173624e-17   \n",
       "std        1.000008e+00      1.000008e+00      1.000008e+00      1.000008e+00   \n",
       "min       -6.435217e-01     -6.461462e-01     -6.414731e-01     -6.894614e-01   \n",
       "25%       -6.435217e-01     -6.461462e-01     -6.414731e-01     -6.894614e-01   \n",
       "50%       -6.435217e-01     -6.461462e-01     -6.414731e-01     -6.071367e-01   \n",
       "75%        4.167609e-01      4.235715e-01      4.227819e-01      4.007788e-01   \n",
       "max        1.887675e+00      1.882189e+00      1.879467e+00      1.970642e+00   \n",
       "\n",
       "       std_og_t2m_mou_7  std_og_t2m_mou_8  std_og_t2f_mou_6  std_og_t2f_mou_7  \\\n",
       "count      6.189500e+04      6.189500e+04           61895.0           61895.0   \n",
       "mean      -3.329144e-18     -3.420983e-17               0.0               0.0   \n",
       "std        1.000008e+00      1.000008e+00               0.0               0.0   \n",
       "min       -6.881476e-01     -6.874127e-01               0.0               0.0   \n",
       "25%       -6.881476e-01     -6.874127e-01               0.0               0.0   \n",
       "50%       -6.100943e-01     -6.161012e-01               0.0               0.0   \n",
       "75%        4.090312e-01      4.124313e-01               0.0               0.0   \n",
       "max        1.964460e+00      1.947476e+00               0.0               0.0   \n",
       "\n",
       "       std_og_t2f_mou_8  std_og_mou_6  std_og_mou_7  std_og_mou_8  \\\n",
       "count           61895.0  6.189500e+04  6.189500e+04  6.189500e+04   \n",
       "mean                0.0 -8.701695e-17 -1.721971e-18 -3.306185e-17   \n",
       "std                 0.0  1.000008e+00  1.000008e+00  1.000008e+00   \n",
       "min                 0.0 -6.913001e-01 -6.893241e-01 -6.870157e-01   \n",
       "25%                 0.0 -6.913001e-01 -6.893241e-01 -6.870157e-01   \n",
       "50%                 0.0 -6.020874e-01 -6.056645e-01 -6.073543e-01   \n",
       "75%                 0.0  4.188090e-01  4.239245e-01  4.256709e-01   \n",
       "max                 0.0  2.000192e+00  1.991374e+00  1.977866e+00   \n",
       "\n",
       "       isd_og_mou_6  isd_og_mou_7  isd_og_mou_8  spl_og_mou_6  spl_og_mou_7  \\\n",
       "count       61895.0       61895.0       61895.0  6.189500e+04  6.189500e+04   \n",
       "mean            0.0           0.0           0.0 -5.739904e-19  1.125021e-16   \n",
       "std             0.0           0.0           0.0  1.000008e+00  1.000008e+00   \n",
       "min             0.0           0.0           0.0 -6.495700e-01 -6.663471e-01   \n",
       "25%             0.0           0.0           0.0 -6.495700e-01 -6.663471e-01   \n",
       "50%             0.0           0.0           0.0 -6.495700e-01 -6.663471e-01   \n",
       "75%             0.0           0.0           0.0  4.184624e-01  4.398271e-01   \n",
       "max             0.0           0.0           0.0  1.943595e+00  2.019036e+00   \n",
       "\n",
       "       spl_og_mou_8  og_others_6  og_others_7  og_others_8  total_og_mou_6  \\\n",
       "count  6.189500e+04      61895.0      61895.0      61895.0    6.189500e+04   \n",
       "mean  -1.030887e-16          0.0          0.0          0.0    2.116877e-16   \n",
       "std    1.000008e+00          0.0          0.0          0.0    1.000008e+00   \n",
       "min   -6.726877e-01          0.0          0.0          0.0   -9.661976e-01   \n",
       "25%   -6.726877e-01          0.0          0.0          0.0   -7.642842e-01   \n",
       "50%   -6.726877e-01          0.0          0.0          0.0   -3.921139e-01   \n",
       "75%    4.438977e-01          0.0          0.0          0.0    4.586646e-01   \n",
       "max    2.036269e+00          0.0          0.0          0.0    2.241963e+00   \n",
       "\n",
       "       total_og_mou_7  total_og_mou_8  loc_ic_t2t_mou_6  loc_ic_t2t_mou_7  \\\n",
       "count    6.189500e+04    6.189500e+04      6.189500e+04      6.189500e+04   \n",
       "mean     9.505281e-17    1.012519e-16      8.460619e-17     -2.047998e-16   \n",
       "std      1.000008e+00    1.000008e+00      1.000008e+00      1.000008e+00   \n",
       "min     -9.597888e-01   -9.574239e-01     -8.696839e-01     -8.863007e-01   \n",
       "25%     -7.612539e-01   -7.643040e-01     -7.770734e-01     -7.787037e-01   \n",
       "50%     -4.016292e-01   -3.979748e-01     -4.225152e-01     -4.135838e-01   \n",
       "75%      4.645216e-01    4.586118e-01      4.373624e-01      4.324455e-01   \n",
       "max      2.243143e+00    2.231159e+00      2.241382e+00      2.219129e+00   \n",
       "\n",
       "       loc_ic_t2t_mou_8  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  \\\n",
       "count      6.189500e+04      6.189500e+04      6.189500e+04      6.189500e+04   \n",
       "mean       3.329144e-18     -8.139184e-17     -1.834473e-16      1.029739e-16   \n",
       "std        1.000008e+00      1.000008e+00      1.000008e+00      1.000008e+00   \n",
       "min       -8.828349e-01     -9.903441e-01     -1.013476e+00     -1.005423e+00   \n",
       "25%       -7.801378e-01     -7.849231e-01     -7.798813e-01     -7.835678e-01   \n",
       "50%       -4.135586e-01     -3.558265e-01     -3.523810e-01     -3.526206e-01   \n",
       "75%        4.354771e-01      4.699377e-01      4.735285e-01      4.759848e-01   \n",
       "max        2.223134e+00      2.326243e+00      2.319091e+00      2.327026e+00   \n",
       "\n",
       "       loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  loc_ic_mou_6  \\\n",
       "count      6.189500e+04      6.189500e+04      6.189500e+04  6.189500e+04   \n",
       "mean       3.535781e-17      1.515335e-17      8.942771e-17 -7.806270e-18   \n",
       "std        1.000008e+00      1.000008e+00      1.000008e+00  1.000008e+00   \n",
       "min       -7.066906e-01     -7.105112e-01     -7.117284e-01 -1.015500e+00   \n",
       "25%       -7.066906e-01     -7.105112e-01     -7.117284e-01 -7.821597e-01   \n",
       "50%       -5.770435e-01     -5.719806e-01     -5.711650e-01 -3.435242e-01   \n",
       "75%        3.985187e-01      3.977338e-01      4.056202e-01  4.767514e-01   \n",
       "max        2.033869e+00      2.044501e+00      2.050732e+00  2.343110e+00   \n",
       "\n",
       "       loc_ic_mou_7  loc_ic_mou_8  std_ic_t2t_mou_6  std_ic_t2t_mou_7  \\\n",
       "count  6.189500e+04  6.189500e+04      6.189500e+04      6.189500e+04   \n",
       "mean   1.666868e-16 -2.321217e-16     -1.578474e-17      9.729138e-17   \n",
       "std    1.000008e+00  1.000008e+00      1.000008e+00      1.000008e+00   \n",
       "min   -1.041535e+00 -1.033159e+00     -6.421708e-01     -6.462870e-01   \n",
       "25%   -7.762977e-01 -7.818770e-01     -6.421708e-01     -6.462870e-01   \n",
       "50%   -3.410298e-01 -3.402228e-01     -6.421708e-01     -6.462870e-01   \n",
       "75%    4.738985e-01  4.771985e-01      4.175402e-01      4.154080e-01   \n",
       "max    2.317986e+00  2.332290e+00      1.943269e+00      1.946259e+00   \n",
       "\n",
       "       std_ic_t2t_mou_8  std_ic_t2m_mou_6  std_ic_t2m_mou_7  std_ic_t2m_mou_8  \\\n",
       "count      6.189500e+04      6.189500e+04      6.189500e+04      6.189500e+04   \n",
       "mean      -1.067622e-17     -8.311381e-17     -3.019190e-17      7.714431e-17   \n",
       "std        1.000008e+00      1.000008e+00      1.000008e+00      1.000008e+00   \n",
       "min       -6.425738e-01     -7.221974e-01     -7.226772e-01     -7.216824e-01   \n",
       "25%       -6.425738e-01     -7.221974e-01     -7.226772e-01     -7.216824e-01   \n",
       "50%       -6.425738e-01     -5.630755e-01     -5.635580e-01     -5.682613e-01   \n",
       "75%        4.197861e-01      4.125737e-01      4.166443e-01      4.133430e-01   \n",
       "max        1.936529e+00      2.084848e+00      2.091185e+00      2.066346e+00   \n",
       "\n",
       "       std_ic_t2f_mou_6  std_ic_t2f_mou_7  std_ic_t2f_mou_8  std_ic_mou_6  \\\n",
       "count           61895.0           61895.0           61895.0  6.189500e+04   \n",
       "mean                0.0               0.0               0.0  1.529110e-16   \n",
       "std                 0.0               0.0               0.0  1.000008e+00   \n",
       "min                 0.0               0.0               0.0 -7.667049e-01   \n",
       "25%                 0.0               0.0               0.0 -7.645433e-01   \n",
       "50%                 0.0               0.0               0.0 -5.038545e-01   \n",
       "75%                 0.0               0.0               0.0  4.061787e-01   \n",
       "max                 0.0               0.0               0.0  2.137620e+00   \n",
       "\n",
       "       std_ic_mou_7  std_ic_mou_8  total_ic_mou_6  total_ic_mou_7  \\\n",
       "count  6.189500e+04  6.189500e+04    6.189500e+04    6.189500e+04   \n",
       "mean   2.557127e-17 -6.692728e-17    7.875149e-17   -6.497572e-17   \n",
       "std    1.000008e+00  1.000008e+00    1.000008e+00    1.000008e+00   \n",
       "min   -7.668715e-01 -7.628069e-01   -1.064639e+00   -1.090587e+00   \n",
       "25%   -7.628452e-01 -7.594539e-01   -7.736506e-01   -7.709977e-01   \n",
       "50%   -5.059665e-01 -5.109114e-01   -3.281968e-01   -3.240508e-01   \n",
       "75%    4.120326e-01  4.174557e-01    4.777435e-01    4.737855e-01   \n",
       "max    2.144555e+00  2.138183e+00    2.335178e+00    2.313638e+00   \n",
       "\n",
       "       total_ic_mou_8  spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  isd_ic_mou_6  \\\n",
       "count    6.189500e+04       61895.0       61895.0       61895.0       61895.0   \n",
       "mean     2.468159e-17           0.0           0.0           0.0           0.0   \n",
       "std      1.000008e+00           0.0           0.0           0.0           0.0   \n",
       "min     -1.080941e+00           0.0           0.0           0.0           0.0   \n",
       "25%     -7.731335e-01           0.0           0.0           0.0           0.0   \n",
       "50%     -3.246245e-01           0.0           0.0           0.0           0.0   \n",
       "75%      4.792702e-01           0.0           0.0           0.0           0.0   \n",
       "max      2.325968e+00           0.0           0.0           0.0           0.0   \n",
       "\n",
       "       isd_ic_mou_7  isd_ic_mou_8  ic_others_6  ic_others_7  ic_others_8  \\\n",
       "count       61895.0       61895.0      61895.0      61895.0      61895.0   \n",
       "mean            0.0           0.0          0.0          0.0          0.0   \n",
       "std             0.0           0.0          0.0          0.0          0.0   \n",
       "min             0.0           0.0          0.0          0.0          0.0   \n",
       "25%             0.0           0.0          0.0          0.0          0.0   \n",
       "50%             0.0           0.0          0.0          0.0          0.0   \n",
       "75%             0.0           0.0          0.0          0.0          0.0   \n",
       "max             0.0           0.0          0.0          0.0          0.0   \n",
       "\n",
       "       total_rech_num_6  total_rech_num_7  total_rech_num_8  total_rech_amt_6  \\\n",
       "count      6.189500e+04      6.189500e+04      6.189500e+04      6.189500e+04   \n",
       "mean      -5.384030e-17      1.813810e-17     -4.850219e-17     -3.670669e-17   \n",
       "std        1.000008e+00      1.000008e+00      1.000008e+00      1.000008e+00   \n",
       "min       -1.283822e+00     -1.320502e+00     -1.215636e+00     -1.183014e+00   \n",
       "25%       -6.747658e-01     -7.159629e-01     -8.110321e-01     -7.695782e-01   \n",
       "50%       -2.687281e-01     -3.129369e-01     -2.041259e-01     -2.809722e-01   \n",
       "75%        5.433472e-01      4.931151e-01      6.050824e-01      5.083146e-01   \n",
       "max        2.370517e+00      2.306732e+00      2.223499e+00      2.396965e+00   \n",
       "\n",
       "       total_rech_amt_7  total_rech_amt_8  max_rech_amt_6  max_rech_amt_7  \\\n",
       "count      6.189500e+04      6.189500e+04    6.189500e+04    6.189500e+04   \n",
       "mean      -2.295962e-18     -3.271745e-17    5.811653e-17   -5.051116e-17   \n",
       "std        1.000008e+00      1.000008e+00    1.000008e+00    1.000008e+00   \n",
       "min       -1.177371e+00     -1.184453e+00   -1.394782e+00   -1.341818e+00   \n",
       "25%       -7.665723e-01     -7.312047e-01   -8.738298e-01   -8.925908e-01   \n",
       "50%       -2.810828e-01     -2.556656e-01    1.970165e-01    1.556054e-01   \n",
       "75%        5.106384e-01      5.133702e-01    3.417254e-01    4.006382e-01   \n",
       "max        2.377439e+00      2.385805e+00    2.165058e+00    2.401740e+00   \n",
       "\n",
       "       max_rech_amt_8  date_of_last_rech_6  date_of_last_rech_7  \\\n",
       "count    6.189500e+04         6.189500e+04         6.189500e+04   \n",
       "mean    -5.326631e-17         2.697755e-18        -7.048602e-17   \n",
       "std      1.000008e+00         1.000008e+00         1.000008e+00   \n",
       "min     -1.303107e+00        -9.560140e-01        -1.017196e+00   \n",
       "25%     -8.958531e-01        -7.803075e-01        -8.105984e-01   \n",
       "50%      1.037711e-01        -4.288946e-01        -3.974035e-01   \n",
       "75%      4.863433e-01         6.253441e-01         4.289864e-01   \n",
       "max      2.615173e+00         2.733821e+00         2.288364e+00   \n",
       "\n",
       "       date_of_last_rech_8  last_day_rch_amt_6  last_day_rch_amt_7  \\\n",
       "count         6.189500e+04        6.189500e+04        6.189500e+04   \n",
       "mean         -6.767347e-17        5.429949e-17       -3.214346e-18   \n",
       "std           1.000008e+00        1.000008e+00        1.000008e+00   \n",
       "min          -1.052717e+00       -9.264382e-01       -8.579539e-01   \n",
       "25%          -8.393787e-01       -7.725829e-01       -8.579539e-01   \n",
       "50%          -1.993648e-01       -4.648724e-01       -4.093740e-01   \n",
       "75%           4.406492e-01        7.659698e-01        7.868391e-01   \n",
       "max           2.360691e+00        3.073799e+00        3.254029e+00   \n",
       "\n",
       "       last_day_rch_amt_8  vol_2g_mb_6  vol_2g_mb_7  vol_2g_mb_8  vol_3g_mb_6  \\\n",
       "count        6.189500e+04      61895.0      61895.0      61895.0      61895.0   \n",
       "mean         2.938831e-17          0.0          0.0          0.0          0.0   \n",
       "std          1.000008e+00          0.0          0.0          0.0          0.0   \n",
       "min         -8.302388e-01          0.0          0.0          0.0          0.0   \n",
       "25%         -8.302388e-01          0.0          0.0          0.0          0.0   \n",
       "50%         -4.302502e-01          0.0          0.0          0.0          0.0   \n",
       "75%          9.030452e-01          0.0          0.0          0.0          0.0   \n",
       "max          3.502971e+00          0.0          0.0          0.0          0.0   \n",
       "\n",
       "       vol_3g_mb_7  vol_3g_mb_8  monthly_2g_6  monthly_2g_7  monthly_2g_8  \\\n",
       "count      61895.0      61895.0       61895.0       61895.0       61895.0   \n",
       "mean           0.0          0.0           0.0           0.0           0.0   \n",
       "std            0.0          0.0           0.0           0.0           0.0   \n",
       "min            0.0          0.0           0.0           0.0           0.0   \n",
       "25%            0.0          0.0           0.0           0.0           0.0   \n",
       "50%            0.0          0.0           0.0           0.0           0.0   \n",
       "75%            0.0          0.0           0.0           0.0           0.0   \n",
       "max            0.0          0.0           0.0           0.0           0.0   \n",
       "\n",
       "       sachet_2g_6  sachet_2g_7  sachet_2g_8  monthly_3g_6  monthly_3g_7  \\\n",
       "count      61895.0      61895.0      61895.0       61895.0       61895.0   \n",
       "mean           0.0          0.0          0.0           0.0           0.0   \n",
       "std            0.0          0.0          0.0           0.0           0.0   \n",
       "min            0.0          0.0          0.0           0.0           0.0   \n",
       "25%            0.0          0.0          0.0           0.0           0.0   \n",
       "50%            0.0          0.0          0.0           0.0           0.0   \n",
       "75%            0.0          0.0          0.0           0.0           0.0   \n",
       "max            0.0          0.0          0.0           0.0           0.0   \n",
       "\n",
       "       monthly_3g_8  sachet_3g_6  sachet_3g_7  sachet_3g_8           aon  \\\n",
       "count       61895.0      61895.0      61895.0      61895.0  6.189500e+04   \n",
       "mean            0.0          0.0          0.0          0.0  4.683762e-17   \n",
       "std             0.0          0.0          0.0          0.0  1.000008e+00   \n",
       "min             0.0          0.0          0.0          0.0 -1.123639e+00   \n",
       "25%             0.0          0.0          0.0          0.0 -8.103262e-01   \n",
       "50%             0.0          0.0          0.0          0.0 -3.512863e-01   \n",
       "75%             0.0          0.0          0.0          0.0  6.906614e-01   \n",
       "max             0.0          0.0          0.0          0.0  2.981177e+00   \n",
       "\n",
       "       aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  avg_rech_amt_6_7   days_stayed  \\\n",
       "count     61895.0     61895.0     61895.0      6.189500e+04  6.189500e+04   \n",
       "mean          0.0         0.0         0.0     -1.963047e-17 -1.251299e-17   \n",
       "std           0.0         0.0         0.0      1.000008e+00  1.000008e+00   \n",
       "min           0.0         0.0         0.0     -1.289479e+00 -3.152894e+00   \n",
       "25%           0.0         0.0         0.0     -7.777993e-01 -5.374735e-01   \n",
       "50%           0.0         0.0         0.0     -2.865862e-01  7.791964e-02   \n",
       "75%           0.0         0.0         0.0      5.116349e-01  5.394645e-01   \n",
       "max           0.0         0.0         0.0      2.608245e+00  2.539492e+00   \n",
       "\n",
       "       avg_3g_6_7  avg_2g_6_7  avg_total_6_7  avg_mou_action  avg_arpu_action  \\\n",
       "count     61895.0     61895.0   6.189500e+04    6.189500e+04     6.189500e+04   \n",
       "mean          0.0         0.0  -6.362684e-17    5.257752e-17     6.520531e-17   \n",
       "std           0.0         0.0   1.000008e+00    1.000008e+00     1.000008e+00   \n",
       "min           0.0         0.0  -1.030640e+00   -1.282522e+00    -1.476881e+00   \n",
       "25%           0.0         0.0  -7.699308e-01   -7.997085e-01    -7.803437e-01   \n",
       "50%           0.0         0.0  -3.759471e-01   -2.632302e-01    -2.914210e-01   \n",
       "75%           0.0         0.0   5.097794e-01    6.019902e-01     5.137023e-01   \n",
       "max           0.0         0.0   2.400292e+00    2.890754e+00     2.557814e+00   \n",
       "\n",
       "          diff_arpu  decrease_arpu_action  avg_rech_amt_action  diff_rech_amt  \\\n",
       "count  6.189500e+04          6.189500e+04         6.189500e+04   6.189500e+04   \n",
       "mean  -3.214346e-18          9.000170e-17        -9.872635e-18   1.285739e-17   \n",
       "std    1.000008e+00          1.000008e+00         1.000008e+00   1.000008e+00   \n",
       "min   -4.983328e+00         -9.447043e-01        -1.285073e+00  -4.679666e+00   \n",
       "25%   -4.355441e-01         -9.447043e-01        -7.784071e-01  -4.572163e-01   \n",
       "50%    2.610324e-02         -9.447043e-01        -2.798477e-01   8.098618e-03   \n",
       "75%    4.360353e-01          1.058532e+00         5.186580e-01   4.740262e-01   \n",
       "max    5.235868e+00          1.058532e+00         2.591682e+00   4.676564e+00   \n",
       "\n",
       "       decrease_rech_amt_action  total_mou_good      diff_mou  \\\n",
       "count              6.189500e+04    6.189500e+04  6.189500e+04   \n",
       "mean              -2.077845e-17   -1.917128e-17 -1.676052e-17   \n",
       "std                1.000008e+00    1.000008e+00  1.000008e+00   \n",
       "min               -9.324330e-01   -1.205228e+00 -5.541415e+00   \n",
       "25%               -9.324330e-01   -8.065288e-01 -3.920468e-01   \n",
       "50%               -9.324330e-01   -2.744619e-01 -2.220750e-02   \n",
       "75%                1.072463e+00    6.211075e-01  3.539972e-01   \n",
       "max                1.072463e+00    2.734357e+00  5.566996e+00   \n",
       "\n",
       "       decrease_mou_action  High_valued_good  High_valued_action  \\\n",
       "count         6.189500e+04      6.189500e+04        6.189500e+04   \n",
       "mean          6.887885e-18     -3.670669e-17       -9.872635e-18   \n",
       "std           1.000008e+00      1.000008e+00        1.000008e+00   \n",
       "min          -9.521107e-01     -1.183014e+00       -1.285073e+00   \n",
       "25%          -9.521107e-01     -7.695782e-01       -7.784071e-01   \n",
       "50%          -9.521107e-01     -2.809722e-01       -2.798477e-01   \n",
       "75%           1.050298e+00      5.083146e-01        5.186580e-01   \n",
       "max           1.050298e+00      2.396965e+00        2.591682e+00   \n",
       "\n",
       "       avg_rech_num_action  diff_rech_num  decrease_rech_num_action  \n",
       "count         6.189500e+04   6.189500e+04              6.189500e+04  \n",
       "mean         -1.595693e-17   1.928608e-17             -9.367524e-17  \n",
       "std           1.000008e+00   1.000008e+00              1.000008e+00  \n",
       "min          -1.376613e+00  -4.612285e+00             -9.798935e-01  \n",
       "25%          -7.190976e-01  -5.027307e-01             -9.798935e-01  \n",
       "50%          -2.807539e-01   1.096357e-02             -9.798935e-01  \n",
       "75%           4.863477e-01   5.246578e-01              1.020519e+00  \n",
       "max           2.458894e+00   4.505788e+00              1.020519e+00  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e393d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abee4b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that data has been transformed.\n",
    "# we can start building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21cbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3907da1f",
   "metadata": {},
   "source": [
    "### 6.  Part One: Model Building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9a9296",
   "metadata": {},
   "source": [
    "#####  Principle Component Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "30f474a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "#pca = PCA(n_components=0.9)  # Retain 90% of the variance\n",
    "pca = PCA(n_components=20)\n",
    "\n",
    "pca_X=pca.fit_transform(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "429b5fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: [0.28809375 0.13410854 0.08748821 0.05539019 0.04769006 0.03336921\n",
      " 0.02495133 0.02219626 0.02043209 0.01988915 0.01762515 0.01661246\n",
      " 0.01562233 0.01354772 0.01039507 0.00996603 0.00919721 0.00871519\n",
      " 0.00860421 0.00834747]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "      <th>PC16</th>\n",
       "      <th>PC17</th>\n",
       "      <th>PC18</th>\n",
       "      <th>PC19</th>\n",
       "      <th>PC20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.477312</td>\n",
       "      <td>2.109031</td>\n",
       "      <td>-1.040653</td>\n",
       "      <td>1.290590</td>\n",
       "      <td>1.294056</td>\n",
       "      <td>1.034757</td>\n",
       "      <td>-0.654845</td>\n",
       "      <td>0.199836</td>\n",
       "      <td>1.656470</td>\n",
       "      <td>-0.609686</td>\n",
       "      <td>-0.107534</td>\n",
       "      <td>0.533183</td>\n",
       "      <td>1.441458</td>\n",
       "      <td>-1.220336</td>\n",
       "      <td>-1.336978</td>\n",
       "      <td>-0.060803</td>\n",
       "      <td>0.737416</td>\n",
       "      <td>-0.392967</td>\n",
       "      <td>0.017347</td>\n",
       "      <td>0.765836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.162526</td>\n",
       "      <td>0.638221</td>\n",
       "      <td>2.195263</td>\n",
       "      <td>-0.701236</td>\n",
       "      <td>0.096208</td>\n",
       "      <td>0.132083</td>\n",
       "      <td>-0.171159</td>\n",
       "      <td>-0.171164</td>\n",
       "      <td>-0.974367</td>\n",
       "      <td>0.406116</td>\n",
       "      <td>-1.566560</td>\n",
       "      <td>-0.706380</td>\n",
       "      <td>2.840648</td>\n",
       "      <td>-0.716970</td>\n",
       "      <td>-1.292058</td>\n",
       "      <td>-0.051714</td>\n",
       "      <td>1.003995</td>\n",
       "      <td>-0.741382</td>\n",
       "      <td>-0.607067</td>\n",
       "      <td>-0.281680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.110070</td>\n",
       "      <td>0.571621</td>\n",
       "      <td>-1.234513</td>\n",
       "      <td>1.029887</td>\n",
       "      <td>0.785849</td>\n",
       "      <td>-0.037900</td>\n",
       "      <td>-1.278962</td>\n",
       "      <td>-0.710960</td>\n",
       "      <td>-1.034361</td>\n",
       "      <td>0.787345</td>\n",
       "      <td>-2.067671</td>\n",
       "      <td>0.235526</td>\n",
       "      <td>0.949847</td>\n",
       "      <td>-1.034159</td>\n",
       "      <td>-0.000846</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>-0.661764</td>\n",
       "      <td>0.155610</td>\n",
       "      <td>-0.717810</td>\n",
       "      <td>-0.204999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.539139</td>\n",
       "      <td>-0.050362</td>\n",
       "      <td>0.600367</td>\n",
       "      <td>-0.817883</td>\n",
       "      <td>0.761061</td>\n",
       "      <td>-0.534239</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>-0.571254</td>\n",
       "      <td>-0.607228</td>\n",
       "      <td>0.805272</td>\n",
       "      <td>-2.066394</td>\n",
       "      <td>-0.895327</td>\n",
       "      <td>4.051514</td>\n",
       "      <td>-0.124470</td>\n",
       "      <td>0.310493</td>\n",
       "      <td>0.598093</td>\n",
       "      <td>0.139353</td>\n",
       "      <td>0.439431</td>\n",
       "      <td>0.200315</td>\n",
       "      <td>0.132024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.006985</td>\n",
       "      <td>-0.153446</td>\n",
       "      <td>-1.984606</td>\n",
       "      <td>-1.993786</td>\n",
       "      <td>-0.954506</td>\n",
       "      <td>-1.407373</td>\n",
       "      <td>1.663400</td>\n",
       "      <td>1.248871</td>\n",
       "      <td>-1.228543</td>\n",
       "      <td>-1.565474</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>-0.650457</td>\n",
       "      <td>-0.207061</td>\n",
       "      <td>-1.167575</td>\n",
       "      <td>-0.269275</td>\n",
       "      <td>-1.730851</td>\n",
       "      <td>-0.954775</td>\n",
       "      <td>-0.530443</td>\n",
       "      <td>0.254778</td>\n",
       "      <td>-0.092090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0 -5.477312  2.109031 -1.040653  1.290590  1.294056  1.034757 -0.654845   \n",
       "1 -7.162526  0.638221  2.195263 -0.701236  0.096208  0.132083 -0.171159   \n",
       "2 -6.110070  0.571621 -1.234513  1.029887  0.785849 -0.037900 -1.278962   \n",
       "3 -4.539139 -0.050362  0.600367 -0.817883  0.761061 -0.534239  0.174118   \n",
       "4 -5.006985 -0.153446 -1.984606 -1.993786 -0.954506 -1.407373  1.663400   \n",
       "\n",
       "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
       "0  0.199836  1.656470 -0.609686 -0.107534  0.533183  1.441458 -1.220336   \n",
       "1 -0.171164 -0.974367  0.406116 -1.566560 -0.706380  2.840648 -0.716970   \n",
       "2 -0.710960 -1.034361  0.787345 -2.067671  0.235526  0.949847 -1.034159   \n",
       "3 -0.571254 -0.607228  0.805272 -2.066394 -0.895327  4.051514 -0.124470   \n",
       "4  1.248871 -1.228543 -1.565474  0.427083 -0.650457 -0.207061 -1.167575   \n",
       "\n",
       "       PC15      PC16      PC17      PC18      PC19      PC20  \n",
       "0 -1.336978 -0.060803  0.737416 -0.392967  0.017347  0.765836  \n",
       "1 -1.292058 -0.051714  1.003995 -0.741382 -0.607067 -0.281680  \n",
       "2 -0.000846  0.004726 -0.661764  0.155610 -0.717810 -0.204999  \n",
       "3  0.310493  0.598093  0.139353  0.439431  0.200315  0.132024  \n",
       "4 -0.269275 -1.730851 -0.954775 -0.530443  0.254778 -0.092090  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Convert the PCA results to a DataFrame if needed\n",
    "columns = [f'PC{i+1}' for i in range(pca_X.shape[1])]\n",
    "\n",
    "pca_X = pd.DataFrame(pca_X, columns=columns)\n",
    " #Check the explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(f\"Explained Variance Ratio: {explained_variance_ratio}\")\n",
    "pca_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f464b7",
   "metadata": {},
   "source": [
    "##### Commulative Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a0b86a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# commulative variance\n",
    "cum_sum_eigenvalues = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Create the visualization plot\n",
    "plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(1, len(cum_sum_eigenvalues) + 1), cum_sum_eigenvalues, where='mid', label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9934d992",
   "metadata": {},
   "source": [
    "###### Correlation matrix among PCs to check multi-collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e8d29",
   "metadata": {
    "papermill": {
     "duration": 0.036844,
     "end_time": "2021-08-13T07:16:41.198447",
     "exception": false,
     "start_time": "2021-08-13T07:16:41.161603",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cbd5d726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T07:16:41.557516Z",
     "iopub.status.busy": "2021-08-13T07:16:41.556428Z",
     "iopub.status.idle": "2021-08-13T07:16:41.578390Z",
     "shell.execute_reply": "2021-08-13T07:16:41.577859Z"
    },
    "papermill": {
     "duration": 0.064419,
     "end_time": "2021-08-13T07:16:41.578526",
     "exception": false,
     "start_time": "2021-08-13T07:16:41.514107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlation matix for multi varients analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Correlation matrix\n",
    "correlation_matrix = pca_X.corr()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7aa82dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see tha there is no multi collinearity among componets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9639c",
   "metadata": {},
   "source": [
    "##### Building Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f360b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a395aa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43326, 20)\n",
      "(18569, 20)\n",
      "(43326,)\n",
      "(18569,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into train and test \n",
    "# splitting the data into test and train data\n",
    "pc_X_train, pc_X_test, y_train, y_test = train_test_split(pca_X, y, test_size=0.30, random_state=72,stratify=y)\n",
    "print(pc_X_train.shape)\n",
    "print(pc_X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "25dd7433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81586, 20)\n"
     ]
    }
   ],
   "source": [
    "# Using Combined sampling to handle imbalanced dataset\n",
    "from imblearn.combine import SMOTETomek\n",
    "smt = SMOTETomek(random_state=71, sampling_strategy=1, n_jobs=-1)\n",
    "pc_X_train, y_train = smt.fit_resample(pc_X_train, y_train)\n",
    "print(pc_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e1207b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81586, 20)\n"
     ]
    }
   ],
   "source": [
    "print(pc_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ceba6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'device': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'multi_strategy': None,\n",
       " 'n_estimators': None,\n",
       " 'n_jobs': -1,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cfl = xgb.XGBClassifier(n_jobs = -1,objective = 'binary:logistic')\n",
    "xgb_cfl.get_params() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3840d37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Set: 0.9470\n",
      "Accuracy on Test Set: 0.8758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train the classifier on the training data\n",
    "xgb_cfl.fit(pc_X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = xgb_cfl.predict(pc_X_train)\n",
    "\n",
    "\n",
    "# Calculate accuracy on the training set\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "## Make predictions on the test set\n",
    "y_test_pred = xgb_cfl.predict(pc_X_test)\n",
    "#Calculate accuracy on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy on Training Set: {accuracy_train:.4f}\")\n",
    "print(f\"Accuracy on Test Set: {accuracy_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e036a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We we can see that train and test accuracy is very good. We can also imporve the performance by using GridsearchCV and hyperparameterr tunning\n",
    "## Lets check some other matirx.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609e111e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31688344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that accuracy is 94 % which is quite good on test data.\n",
    "# Lets check other matirx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e438312e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37635,  3158],\n",
       "       [ 1163, 39630]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2ba8d115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25666534023079984"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_test_pred)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7d20ae1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5950184501845018"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y_test, y_test_pred)\n",
    "recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "49b997bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here recall and percesion is not very good score\n",
    "#We can see a high amount of type 2 error. Due to class imbalance, the model is clearly trying to predict majority of the cases as class 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281df567",
   "metadata": {},
   "source": [
    "##### Hyper Parameters tunning - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "16795ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# A parameter grid for XGBoost\n",
    "\n",
    "xgb_lg = xgb.XGBClassifier(n_jobs = -1,objective = 'binary:logistic')\n",
    "params = {\n",
    "        'n_estimators' : [100, 200, 500,760], # no of trees \n",
    "        'learning_rate' : [0.01, 0.02, 0.05, 0.1, 0.25,0.35, 0.45],  # eta\n",
    "        'min_child_weight': [1, 5, 7, 10,15,20],\n",
    "        'gamma': [0.3,0.05,0.8,0.1, 0.5, 1, 1.5, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0,1.5, 2.0,2.5],\n",
    "        'colsample_bytree': [0.1,0.3,0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5, 10, 12,16,18,20],\n",
    "         'scale_pos_weight': [1,2,3,4, 5, 10,20, 30,40], \n",
    "        }\n",
    "\n",
    "folds = 5\n",
    "param_comb = 800\n",
    "random_search = RandomizedSearchCV(xgb_lg, param_distributions=params, n_iter=param_comb, scoring='accuracy', n_jobs=-1, cv=5, verbose=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7b981820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.02, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.881 total time=  34.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.786 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.891 total time=  14.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=0.8;, score=0.872 total time=  40.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.815 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.810 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.814 total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.809 total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.886 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.781 total time=   3.5s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.788 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=40, subsample=0.8;, score=0.691 total time=  17.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.954 total time=   8.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.01, max_depth=20, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=0.6;, score=0.772 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.954 total time=  31.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.911 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=4, subsample=1.0;, score=0.960 total time=   5.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=0.6;, score=0.934 total time=   8.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=10, subsample=0.8;, score=0.957 total time=  13.9s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.886 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=0.8;, score=0.950 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.886 total time=  14.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.957 total time=  12.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=0.8;, score=0.836 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=0.8;, score=0.836 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.872 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.932 total time=   2.7s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.933 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.35, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.853 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=0.6;, score=0.927 total time=   2.8s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.941 total time=  27.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=5, subsample=0.8;, score=0.918 total time=  27.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.844 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.896 total time=  10.8s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=30, subsample=0.6;, score=0.837 total time=18.1min\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=1.0;, score=0.921 total time=  20.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.838 total time=  18.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.952 total time=   6.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.952 total time=   6.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.02, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.02, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.883 total time=  33.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.787 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.889 total time=  14.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.927 total time=   6.5s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.926 total time=   8.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=0.8;, score=0.888 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.02, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.589 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.02, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.591 total time=   3.5s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.838 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.25, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.927 total time=   6.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.620 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.25, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.948 total time=   6.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.865 total time=  21.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=40, subsample=0.8;, score=0.690 total time=  16.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.01, max_depth=20, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=0.6;, score=0.779 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.956 total time=  31.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.948 total time=  10.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=10, subsample=0.8;, score=0.960 total time=  15.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=0.8;, score=0.886 total time=  21.1s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.958 total time=  15.6s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.949 total time=   5.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.798 total time=   8.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.935 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.933 total time=   6.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=20, subsample=1.0;, score=0.930 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=0.6;, score=0.928 total time=   2.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=0.8;, score=0.836 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.766 total time=   8.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.765 total time=   8.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.02, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=3, subsample=0.8;, score=0.927 total time=  12.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.626 total time=   2.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.625 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.624 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=1.0;, score=0.963 total time=   7.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=1.0;, score=0.961 total time=   6.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.961 total time=   4.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.898 total time=  10.7s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=30, subsample=0.6;, score=0.838 total time=18.1min\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=1.0;, score=0.920 total time=  21.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.809 total time=  14.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.949 total time=   7.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.886 total time=  35.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=4, min_child_weight=20, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=4, min_child_weight=20, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=0.8;, score=0.871 total time=  42.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.25, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.926 total time=   6.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.812 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.25, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.946 total time=   6.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.863 total time=  21.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.955 total time=   9.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.853 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.860 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.611 total time=   4.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.954 total time=  31.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.947 total time=  10.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=10, subsample=0.8;, score=0.956 total time=  14.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=0.8;, score=0.887 total time=  21.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.958 total time=  15.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=1.0;, score=0.850 total time=   5.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.795 total time=   8.6s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.869 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=10, subsample=0.8;, score=0.951 total time=   6.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.932 total time=   6.4s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=0.8;, score=0.839 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.939 total time=  26.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.02, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=3, subsample=0.8;, score=0.928 total time=  12.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=1.0;, score=0.961 total time=   7.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=1.0;, score=0.960 total time=   6.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.961 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.895 total time=  10.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.962 total time=17.8min\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.968 total time=  19.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=1.0;, score=0.922 total time=  21.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.809 total time=  14.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.911 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=20, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.872 total time=  10.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=1.0;, score=0.959 total time=   9.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.02, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.02, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.02, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.02, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.02, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.949 total time=  43.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=100, scale_pos_weight=10, subsample=1.0;, score=0.755 total time=  14.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.934 total time=   6.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.934 total time=   6.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=760, scale_pos_weight=5, subsample=0.6;, score=0.910 total time=   6.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=16, min_child_weight=1, n_estimators=200, scale_pos_weight=1, subsample=1.0;, score=0.947 total time=  45.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=30, subsample=0.6;, score=0.887 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.853 total time=  10.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=0.6;, score=0.918 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=0.6;, score=0.912 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=0.6;, score=0.912 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.45, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.859 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.45, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.859 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=4, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.877 total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=4, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.879 total time=   4.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.940 total time=   3.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.933 total time=   5.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.02, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.884 total time=  34.9s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.893 total time=  14.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=0.8;, score=0.874 total time=  40.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.812 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.809 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.25, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.949 total time=   6.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.884 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.889 total time=   3.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.792 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.788 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=40, subsample=0.8;, score=0.691 total time=  17.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.857 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.610 total time=   4.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=0.6;, score=0.779 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.954 total time=  31.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.909 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.908 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=0.6;, score=0.940 total time=   7.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=10, subsample=0.8;, score=0.955 total time=  14.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.890 total time=   6.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.887 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=0.8;, score=0.954 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.960 total time=  16.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=1.0;, score=0.846 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.947 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.868 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.875 total time=   2.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=10, subsample=0.8;, score=0.949 total time=   6.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=20, subsample=1.0;, score=0.933 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.35, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.849 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=0.6;, score=0.928 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.939 total time=  26.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=5, subsample=0.8;, score=0.916 total time=  27.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.846 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.897 total time=  10.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.960 total time=17.8min\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.968 total time=  19.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=1.0;, score=0.921 total time=  21.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.806 total time=  14.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.910 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.955 total time=   6.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.955 total time=   6.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.35, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.35, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=40, subsample=0.6;, score=0.944 total time=   5.6s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.867 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.946 total time=  43.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.45, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.864 total time=  10.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=1.0;, score=0.825 total time=   3.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.921 total time=  14.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=16, min_child_weight=1, n_estimators=200, scale_pos_weight=1, subsample=1.0;, score=0.949 total time=  45.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.948 total time=   6.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.880 total time=  35.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=4, min_child_weight=20, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=0.8;, score=0.872 total time=  44.8s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.622 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.621 total time=   3.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.809 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.863 total time=  20.8s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=40, subsample=0.8;, score=0.691 total time=  17.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.607 total time=   5.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.948 total time=   9.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.874 total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.878 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.880 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.02, max_depth=20, min_child_weight=10, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.946 total time=  10.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=4, subsample=1.0;, score=0.957 total time=   5.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=0.6;, score=0.938 total time=   8.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=0.8;, score=0.890 total time=  21.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=0.8;, score=0.951 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.888 total time=  14.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=1.0;, score=0.850 total time=   5.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.944 total time=   6.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=0.8;, score=0.833 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=0.8;, score=0.834 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=0.8;, score=0.837 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.872 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=10, subsample=0.8;, score=0.953 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.936 total time=   6.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=0.8;, score=0.836 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=0.8;, score=0.833 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.767 total time=   8.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.02, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=3, subsample=0.8;, score=0.927 total time=  13.0s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.02, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=3, subsample=0.8;, score=0.926 total time=  12.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.624 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.624 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=1.0;, score=0.958 total time=   7.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.965 total time=   4.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.963 total time=   4.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.844 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.960 total time=  13.1s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.972 total time=17.9min\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.969 total time=  18.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.844 total time=  19.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.805 total time=  14.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.953 total time=   6.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.35, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.35, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=40, subsample=0.6;, score=0.944 total time=   5.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.947 total time=   7.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.710 total time=  19.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.710 total time=  15.6s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.895 total time=  13.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.925 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=0.8;, score=0.891 total time=   4.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=0.8;, score=0.890 total time=   3.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.02, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.596 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.02, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.592 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.840 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.25, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.927 total time=   6.7s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.619 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.25, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.946 total time=   6.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.859 total time=  21.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.955 total time=   9.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.861 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.608 total time=   4.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.01, max_depth=20, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.959 total time=  31.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.911 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.907 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=4, subsample=1.0;, score=0.957 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=10, subsample=0.8;, score=0.955 total time=  14.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.890 total time=   6.9s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.890 total time=   5.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.886 total time=  14.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.958 total time=  13.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.801 total time=   8.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.934 total time=   2.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=10, subsample=0.8;, score=0.948 total time=   6.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=20, subsample=1.0;, score=0.933 total time=   2.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.35, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.850 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=0.6;, score=0.925 total time=   2.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.942 total time=  26.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=5, subsample=0.8;, score=0.922 total time=  27.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.846 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.896 total time=  10.9s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=30, subsample=0.6;, score=0.835 total time=18.1min\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.970 total time=  18.6s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.837 total time=  19.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.906 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=20, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.874 total time=  10.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=1.0;, score=0.959 total time=  10.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.868 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.944 total time=  43.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=100, scale_pos_weight=10, subsample=1.0;, score=0.759 total time=  14.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.923 total time=  14.0s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=760, scale_pos_weight=5, subsample=0.6;, score=0.911 total time=   7.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.926 total time=   3.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.930 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.948 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.823 total time=   6.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.950 total time=   7.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.710 total time=  19.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.25, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.25, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.25, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.25, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.25, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.790 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.789 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.791 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.891 total time=  14.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.925 total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.925 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=0.8;, score=0.893 total time=   4.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=0.8;, score=0.889 total time=   3.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.02, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.592 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.841 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.839 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.839 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.25, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.930 total time=   6.7s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.620 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.25, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.946 total time=   6.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.861 total time=  21.4s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.958 total time=   9.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.854 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.614 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.01, max_depth=20, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=0.6;, score=0.777 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.948 total time=  10.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.949 total time=   8.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.880 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.02, max_depth=20, min_child_weight=10, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.02, max_depth=20, min_child_weight=10, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.950 total time=  10.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=4, subsample=1.0;, score=0.956 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=0.6;, score=0.938 total time=   8.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=0.8;, score=0.893 total time=  21.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=0.8;, score=0.950 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.884 total time=  14.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=1.0;, score=0.851 total time=   5.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.947 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.796 total time=   8.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.932 total time=   2.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=10, subsample=0.8;, score=0.951 total time=   6.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=20, subsample=1.0;, score=0.933 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.35, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.849 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=0.6;, score=0.926 total time=   2.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.944 total time=  26.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=5, subsample=0.8;, score=0.916 total time=  26.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.962 total time=   4.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.961 total time=  13.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=30, subsample=0.6;, score=0.836 total time=18.1min\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=1.0;, score=0.923 total time=  21.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.810 total time=  14.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.910 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=20, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.872 total time=   9.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=1.0;, score=0.959 total time=  10.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.02, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.948 total time=   7.1s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.713 total time=  19.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.709 total time=  15.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=4, min_child_weight=20, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=4, min_child_weight=20, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=0.8;, score=0.871 total time=  44.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.25, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.929 total time=   6.4s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.810 total time=   3.9s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.805 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.890 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.891 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.788 total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=40, subsample=0.8;, score=0.689 total time=  17.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.954 total time=   8.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.01, max_depth=20, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=0.6;, score=0.779 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.953 total time=  11.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.951 total time=   8.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.880 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.02, max_depth=20, min_child_weight=10, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.02, max_depth=20, min_child_weight=10, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.947 total time=  10.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=4, subsample=1.0;, score=0.957 total time=   5.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=0.6;, score=0.937 total time=   8.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=0.8;, score=0.891 total time=  21.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=0.8;, score=0.954 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.887 total time=  14.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=1.0;, score=0.852 total time=   5.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.947 total time=   6.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.797 total time=   8.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.933 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.933 total time=   6.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=20, subsample=1.0;, score=0.928 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.35, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.852 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=0.8;, score=0.832 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.762 total time=   7.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.763 total time=   8.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.02, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=3, subsample=0.8;, score=0.925 total time=  12.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=5, subsample=0.8;, score=0.918 total time=  26.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.848 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.965 total time=  12.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=30, subsample=0.6;, score=0.835 total time=18.1min\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.838 total time=  17.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.840 total time=  18.7s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=20, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.874 total time=   9.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=1.0;, score=0.959 total time=  10.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=40, subsample=0.6;, score=0.943 total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=0.6;, score=0.913 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=1.0;, score=0.796 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=1.0;, score=0.799 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.942 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.937 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=0.6;, score=0.858 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.25, max_depth=10, min_child_weight=5, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.953 total time=   3.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.25, max_depth=10, min_child_weight=5, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.954 total time=   4.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=100, scale_pos_weight=10, subsample=1.0;, score=0.762 total time=  17.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.45, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.863 total time=   5.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.936 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=760, scale_pos_weight=5, subsample=0.6;, score=0.914 total time=   6.9s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=16, min_child_weight=1, n_estimators=200, scale_pos_weight=1, subsample=1.0;, score=0.948 total time=  45.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=30, subsample=0.6;, score=0.889 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=30, subsample=0.6;, score=0.888 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.856 total time=  11.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.854 total time=   9.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=0.6;, score=0.911 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.45, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.857 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.45, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.860 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.909 total time=   1.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=20, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.872 total time=  10.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=1.0;, score=0.960 total time=  10.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=40, subsample=0.6;, score=0.943 total time=   5.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=0.6;, score=0.911 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=0.6;, score=0.915 total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=1.0;, score=0.800 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.940 total time=   5.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=0.6;, score=0.865 total time=   3.4s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=0.6;, score=0.864 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=0.6;, score=0.864 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.25, max_depth=10, min_child_weight=5, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.953 total time=   3.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=100, scale_pos_weight=10, subsample=1.0;, score=0.756 total time=  11.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.45, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.861 total time=  10.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=1.0;, score=0.823 total time=   4.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.920 total time=  14.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=16, min_child_weight=1, n_estimators=200, scale_pos_weight=1, subsample=1.0;, score=0.952 total time=  44.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=30, subsample=0.8;, score=0.916 total time= 1.1min\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=5, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.952 total time=  24.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.920 total time=   8.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.635 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.632 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.830 total time=   7.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=4, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.776 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=4, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.777 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=4, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.775 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=4, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.770 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.893 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.02, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.845 total time=   7.4s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.865 total time=  33.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.937 total time=  10.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.934 total time=  10.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.803 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.925 total time=   7.0s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=0.6;, score=0.836 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=2, subsample=0.6;, score=0.775 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.758 total time=  14.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.548 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.02, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.872 total time=  23.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.919 total time=  38.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=10, subsample=0.8;, score=0.880 total time=   6.8s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=0.8;, score=0.920 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=0.8;, score=0.921 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.45, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.955 total time=   9.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.870 total time=  10.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.867 total time=   5.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.05, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=0.8;, score=0.777 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.1, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.915 total time=   4.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.827 total time=   6.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.857 total time=   4.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.853 total time=   4.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=30, subsample=0.8;, score=0.914 total time= 1.1min\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=5, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.948 total time=  24.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.920 total time=   8.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.633 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.835 total time=   7.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.835 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=4, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.776 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.898 total time=   4.8s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.934 total time= 1.0min\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.932 total time=   8.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.924 total time=   6.9s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=16, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.614 total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.02, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=0.6;, score=0.845 total time=  11.5s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.550 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.02, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.874 total time=  23.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.929 total time=  12.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.948 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.25, max_depth=18, min_child_weight=10, n_estimators=200, scale_pos_weight=1, subsample=0.8;, score=0.961 total time=   5.0s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.25, max_depth=18, min_child_weight=10, n_estimators=200, scale_pos_weight=1, subsample=0.8;, score=0.961 total time=   4.7s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.05, max_depth=20, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=0.8;, score=0.921 total time=   6.7s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.05, max_depth=20, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=0.8;, score=0.922 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.956 total time=  14.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.687 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.684 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.870 total time=  10.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.900 total time=   9.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=5, subsample=0.6;, score=0.893 total time=   4.4s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.622 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.619 total time=   2.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=0.8;, score=0.945 total time=   5.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=0.8;, score=0.946 total time=   5.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=0.8;, score=0.944 total time=   5.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.840 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=4, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.957 total time=  13.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.943 total time=  25.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.915 total time=   4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.35, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=40, subsample=0.6;, score=0.948 total time=   5.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.863 total time=   2.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.945 total time=  43.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.45, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.862 total time=  10.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=1.0;, score=0.822 total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.920 total time=  14.0s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=760, scale_pos_weight=5, subsample=0.6;, score=0.915 total time=   7.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.923 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.955 total time=   6.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.948 total time=   6.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.829 total time=   6.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.828 total time=   6.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.854 total time=   4.4s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=30, subsample=0.8;, score=0.915 total time= 1.1min\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=18, min_child_weight=5, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.831 total time=   5.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.904 total time=   5.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.900 total time=   6.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.921 total time=   8.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.929 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=5, subsample=0.8;, score=0.952 total time=  19.7s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.500 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.500 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.02, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.846 total time=   6.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.933 total time= 1.1min\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.803 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.922 total time=   7.1s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=0.6;, score=0.829 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=0.6;, score=0.837 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=2, subsample=0.6;, score=0.776 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.750 total time=  14.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.02, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.874 total time=  23.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.915 total time=  38.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=10, subsample=0.8;, score=0.881 total time=   7.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=0.8;, score=0.919 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.45, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.960 total time=  10.0s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.871 total time=  10.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.870 total time=   5.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=5, subsample=0.6;, score=0.893 total time=   4.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.616 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.883 total time=  11.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.915 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.931 total time=   5.4s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.659 total time=   3.5s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=5, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=18, min_child_weight=5, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.835 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.834 total time=   4.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.901 total time=   6.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.02, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.02, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.02, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.02, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.02, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.917 total time=   8.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.929 total time=   2.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.638 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.633 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.837 total time=   7.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.836 total time=   6.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.35, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.902 total time=   4.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.02, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.842 total time=   7.5s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.863 total time=  32.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.868 total time=  28.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.804 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=16, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.615 total time=   8.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=2, subsample=0.6;, score=0.782 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.753 total time=  13.9s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.549 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.952 total time=   4.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.948 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.949 total time=   4.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.931 total time=  11.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.915 total time=  37.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.955 total time=  13.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.45, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.959 total time=  10.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=10, min_child_weight=10, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=10, min_child_weight=10, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.900 total time=   9.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.867 total time=   5.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.05, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=0.8;, score=0.779 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.1, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.917 total time=   4.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.881 total time=  11.4s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=0.8;, score=0.946 total time=   5.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=0.8;, score=0.946 total time=   4.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.01, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.869 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=0.6;, score=0.916 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=0.6;, score=0.915 total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=1.0;, score=0.799 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=1.0;, score=0.795 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.939 total time=   5.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.942 total time=   5.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=0.6;, score=0.862 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.25, max_depth=10, min_child_weight=5, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.956 total time=   4.0s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.25, max_depth=10, min_child_weight=5, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.957 total time=   4.4s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=100, scale_pos_weight=10, subsample=1.0;, score=0.758 total time=  18.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=1.0;, score=0.820 total time=   3.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.921 total time=  14.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=16, min_child_weight=1, n_estimators=200, scale_pos_weight=1, subsample=1.0;, score=0.950 total time=  45.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=30, subsample=0.8;, score=0.916 total time= 1.1min\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=5, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=18, min_child_weight=5, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.950 total time=  25.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.726 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.729 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.929 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=5, subsample=0.8;, score=0.951 total time=  20.1s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.500 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.02, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.840 total time=   6.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.932 total time= 1.1min\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.810 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.926 total time=   7.0s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=16, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.612 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.02, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=0.6;, score=0.845 total time=  11.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.02, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=0.6;, score=0.843 total time=  11.9s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.950 total time=   4.1s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.929 total time=  11.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.953 total time=   5.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.949 total time=   4.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.950 total time=   4.9s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.25, max_depth=18, min_child_weight=10, n_estimators=200, scale_pos_weight=1, subsample=0.8;, score=0.961 total time=   4.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.05, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.05, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.05, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.05, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.05, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.05, max_depth=20, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=0.8;, score=0.915 total time=   6.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.05, max_depth=20, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=0.8;, score=0.919 total time=   6.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=10, subsample=0.8;, score=0.881 total time=   6.8s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.957 total time=  10.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.871 total time=  10.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.872 total time=   5.6s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.868 total time=   5.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.05, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=0.8;, score=0.776 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.1, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.919 total time=   5.1s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.881 total time=  11.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.913 total time=   2.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=0.8;, score=0.945 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=0.8;, score=0.945 total time=   4.4s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.01, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.532 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.535 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.727 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.938 total time=   4.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.934 total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.25, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=1, subsample=0.6;, score=0.944 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.25, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=1, subsample=0.6;, score=0.946 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.719 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=1.0;, score=0.930 total time=   6.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=30, subsample=0.6;, score=0.891 total time=   3.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=30, subsample=0.6;, score=0.890 total time=   3.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.856 total time=  11.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.856 total time=   9.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=0.6;, score=0.913 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.45, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.858 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=4, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.874 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.943 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.945 total time=   3.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.942 total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.933 total time=   5.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.658 total time=   3.4s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.658 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.948 total time=  25.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.729 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.932 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=5, subsample=0.8;, score=0.950 total time=  19.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.902 total time=   4.8s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.931 total time= 1.1min\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.933 total time=   8.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=16, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.611 total time=   7.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=2, subsample=0.6;, score=0.774 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=15, n_estimators=200, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.02, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=0.6;, score=0.846 total time=  11.6s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.551 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.02, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.873 total time=  24.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.916 total time=  38.7s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.959 total time=  14.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.45, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.959 total time=  10.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.901 total time=   9.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=16, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=16, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=16, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=5, subsample=0.6;, score=0.893 total time=   4.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.05, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=0.8;, score=0.777 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.1, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.915 total time=   5.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=0.8;, score=0.947 total time=   5.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=0.8;, score=0.946 total time=   5.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.916 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.820 total time=   8.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.843 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.954 total time=  13.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.940 total time=  25.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.894 total time=  15.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.02, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.854 total time=  11.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.864 total time=   5.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.880 total time=  13.6s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.1, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.905 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.891 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=4, subsample=1.0;, score=0.675 total time=   7.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=12, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.879 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.886 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.911 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.911 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.933 total time=   8.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.877 total time=  12.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.916 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.890 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.890 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.890 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.951 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.934 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.952 total time=   6.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=4, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.899 total time=   5.0s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=0.8;, score=0.812 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=1.0;, score=0.916 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.938 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=10, subsample=0.6;, score=0.907 total time=   4.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.864 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.944 total time=  43.1s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.45, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.857 total time=  10.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=1.0;, score=0.821 total time=   3.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.935 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.939 total time=   6.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=760, scale_pos_weight=5, subsample=0.6;, score=0.912 total time=   6.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.925 total time=   3.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.924 total time=   3.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.947 total time=   6.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.949 total time=   6.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.827 total time=   6.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.860 total time=   4.6s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.857 total time=   4.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.01, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=30, subsample=0.8;, score=0.917 total time= 1.1min\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.655 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=18, min_child_weight=5, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=20, subsample=0.6;, score=0.948 total time=  25.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.732 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.731 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.926 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=5, subsample=0.8;, score=0.949 total time=  19.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.899 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.932 total time= 1.1min\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.932 total time=   8.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=16, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=0.6;, score=0.614 total time=   7.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.752 total time=  13.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.02, max_depth=10, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=0.6;, score=0.844 total time=  11.8s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.949 total time=   4.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.932 total time=  11.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.915 total time=  37.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=10, subsample=0.8;, score=0.880 total time=   6.8s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=0.8;, score=0.920 total time=   2.9s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=0.8;, score=0.919 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.45, max_depth=18, min_child_weight=7, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.957 total time=  10.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.05, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.05, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.05, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.05, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.05, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=10, min_child_weight=10, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=10, min_child_weight=10, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=10, min_child_weight=10, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.902 total time=   9.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=16, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=16, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=5, subsample=0.6;, score=0.893 total time=   4.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.05, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=0.8;, score=0.782 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.1, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.913 total time=   4.9s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.882 total time=  11.5s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.814 total time=   8.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.845 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.956 total time=  14.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.938 total time=  24.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.893 total time=  14.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.890 total time=   4.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=12, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.502 total time=   3.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=12, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.503 total time=   3.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.863 total time=   5.5s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=20, subsample=0.8;, score=0.725 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.881 total time=  13.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=0.8;, score=0.862 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.883 total time=  11.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.913 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.815 total time=   8.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.01, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.01, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.01, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.01, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.01, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=4, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=4, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=4, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=4, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.958 total time=  14.0s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.940 total time=  25.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.916 total time=   4.6s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.916 total time=   4.5s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.934 total time=   5.4s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.02, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.855 total time=  12.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.864 total time=   5.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.537 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.900 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.898 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=1, subsample=0.6;, score=0.854 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=0.8;, score=0.861 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.1, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.905 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.882 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.500 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.624 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=12, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.35, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=0.6;, score=0.934 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.962 total time=  11.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.875 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.877 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.877 total time=  11.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.912 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.910 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.885 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.949 total time=   3.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.931 total time=   3.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.951 total time=   6.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=4, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.874 total time=   4.0s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=4, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.878 total time=   4.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.946 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.938 total time=   5.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.933 total time=   5.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.661 total time=   3.5s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=5, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=18, min_child_weight=5, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.833 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.836 total time=   4.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.903 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=15, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.901 total time=   6.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.919 total time=   8.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=5, subsample=0.8;, score=0.956 total time=  20.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.500 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.500 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.02, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.843 total time=   6.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.866 total time=  34.5s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=1, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.865 total time=  30.6s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.805 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.924 total time=   7.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=0.6;, score=0.836 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=0.6;, score=0.836 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=2, subsample=0.6;, score=0.778 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.752 total time=  13.8s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=3, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.554 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.25, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.02, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.875 total time=  23.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.931 total time=  13.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.951 total time=   4.7s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.25, max_depth=18, min_child_weight=10, n_estimators=200, scale_pos_weight=1, subsample=0.8;, score=0.961 total time=   4.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.25, max_depth=18, min_child_weight=10, n_estimators=200, scale_pos_weight=1, subsample=0.8;, score=0.962 total time=   4.9s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.05, max_depth=20, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=0.8;, score=0.919 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=10, subsample=0.8;, score=0.884 total time=   4.9s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.956 total time=  14.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.684 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.689 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.687 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.874 total time=  10.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.902 total time=   9.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=5, subsample=0.6;, score=0.893 total time=   4.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.618 total time=   2.9s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.618 total time=   3.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=0.8;, score=0.944 total time=   5.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.917 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.817 total time=   8.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.844 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.953 total time=  14.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.942 total time=  25.4s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.918 total time=   4.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.45, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.915 total time=   4.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.931 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.891 total time=   4.5s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=12, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.502 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.864 total time=   5.7s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.942 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=20, subsample=0.8;, score=0.719 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.881 total time=  13.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.1, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.905 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=4, subsample=1.0;, score=0.677 total time=   7.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.625 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.35, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=0.6;, score=0.937 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.966 total time=  11.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.813 total time=   8.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=3, subsample=1.0;, score=0.844 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.01, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.01, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.01, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.532 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.45, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.45, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.45, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.45, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.45, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.731 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.721 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.936 total time=   4.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.938 total time=   4.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.25, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=1, subsample=0.6;, score=0.943 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.726 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.722 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.723 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=1.0;, score=0.932 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.898 total time=  16.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.935 total time=   5.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.02, max_depth=16, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.890 total time=   4.1s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.02, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.855 total time=  12.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.942 total time=   2.8s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=20, subsample=0.8;, score=0.720 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.880 total time=  13.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.1, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.903 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.884 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=4, subsample=1.0;, score=0.672 total time=   7.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.895 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.910 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.35, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.935 total time=   8.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.876 total time=  11.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.914 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.918 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.885 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.948 total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.933 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=0.6;, score=0.850 total time=   7.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=4, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.898 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.540 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.533 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.729 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.722 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.935 total time=   4.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=10, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=10, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=10, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=10, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=10, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.25, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=1, subsample=0.6;, score=0.945 total time=   3.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.25, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=1, subsample=0.6;, score=0.943 total time=   3.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.25, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.727 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=1.0;, score=0.936 total time=   6.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=1.0;, score=0.932 total time=   6.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.893 total time=  15.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.935 total time=   5.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.02, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.853 total time=  12.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.941 total time=   2.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=20, subsample=0.8;, score=0.721 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.880 total time=  13.5s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.1, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.903 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=4, subsample=1.0;, score=0.677 total time=   7.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.626 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=12, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.890 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.964 total time=  11.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.869 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.873 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.824 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.826 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.825 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.911 total time=  12.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.951 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=0.6;, score=0.845 total time=   7.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=4, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.900 total time=   4.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.915 total time=   4.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.941 total time=   4.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.938 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.02, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.02, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.45, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=0.6;, score=0.851 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.913 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=20, subsample=1.0;, score=0.528 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.964 total time=  18.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.934 total time=   5.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.02, max_depth=16, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.02, max_depth=16, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.889 total time=   4.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=12, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.502 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.02, max_depth=12, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.502 total time=   4.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.865 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.943 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.541 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.537 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.902 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=1, subsample=0.6;, score=0.857 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=1, subsample=0.6;, score=0.856 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=0.8;, score=0.861 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=0.8;, score=0.863 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.886 total time=   2.6s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.500 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.500 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.632 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=12, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.35, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=0.6;, score=0.935 total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.962 total time=  11.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.930 total time=   8.0s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.825 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.749 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.751 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.750 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.911 total time=  12.1s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.932 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=0.6;, score=0.848 total time=   7.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=4, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.901 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=0.8;, score=0.810 total time=   3.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=1.0;, score=0.915 total time=   6.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.937 total time=   3.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=10, subsample=0.6;, score=0.907 total time=   4.0s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.906 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.887 total time=  39.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=30, subsample=0.6;, score=0.940 total time= 2.5min\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.787 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.02, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=1.0;, score=0.813 total time=   4.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=5, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=4, min_child_weight=10, n_estimators=200, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.45, max_depth=10, min_child_weight=15, n_estimators=500, scale_pos_weight=5, subsample=0.8;, score=0.891 total time=   5.4s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.35, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, scale_pos_weight=1, subsample=0.6;, score=0.835 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.928 total time=  14.6s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=20, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=0.6;, score=0.927 total time=   4.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=1.0;, score=0.933 total time=   6.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.897 total time=  15.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.02, max_depth=16, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.02, max_depth=16, min_child_weight=15, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=0.8;, score=0.886 total time=   4.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.02, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.852 total time=  12.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.940 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=20, subsample=0.8;, score=0.717 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.537 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.538 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.897 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.901 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=1, subsample=0.6;, score=0.861 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=1, subsample=0.6;, score=0.858 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.25, max_depth=3, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=0.8;, score=0.862 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.45, max_depth=12, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.45, max_depth=12, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.45, max_depth=12, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.45, max_depth=12, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.45, max_depth=12, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=4, subsample=1.0;, score=0.678 total time=   8.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.625 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.35, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=0.6;, score=0.932 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.962 total time=  11.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.934 total time=   8.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=4, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.823 total time=   2.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.754 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.753 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.915 total time=  12.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.948 total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=0.6;, score=0.849 total time=   7.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.951 total time=   4.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=0.8;, score=0.813 total time=   2.9s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.918 total time=   5.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.937 total time=   4.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=10, subsample=0.6;, score=0.908 total time=   4.0s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.45, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=0.6;, score=0.849 total time=   3.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.02, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.02, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.02, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.889 total time=  40.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.920 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.35, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.856 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.35, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.855 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.893 total time= 2.0min\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.699 total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.699 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.700 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.696 total time=   4.1s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.698 total time=   4.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.783 total time=   4.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.790 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.953 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.02, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=1.0;, score=0.814 total time=   4.6s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.734 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=4, min_child_weight=1, n_estimators=100, scale_pos_weight=10, subsample=1.0;, score=0.791 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=4, min_child_weight=1, n_estimators=100, scale_pos_weight=10, subsample=1.0;, score=0.789 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.05, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.929 total time=  13.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.963 total time=  26.9s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.0;, score=0.899 total time=   5.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.0;, score=0.899 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=1.0;, score=0.802 total time=  13.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=0.6;, score=0.887 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.500 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.01, max_depth=3, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.500 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=12, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.35, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=0.6;, score=0.938 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.895 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.913 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.35, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.913 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.936 total time=   8.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.877 total time=  12.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.911 total time=  12.1s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.934 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.951 total time=   6.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=4, min_child_weight=1, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.899 total time=   4.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.921 total time=   4.7s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=1.0;, score=0.911 total time=   6.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.937 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=10, subsample=0.6;, score=0.908 total time=   4.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.913 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.886 total time=  40.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.35, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.849 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.35, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.853 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.889 total time= 2.0min\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.891 total time=  30.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.954 total time=   6.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=5, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=4, min_child_weight=10, n_estimators=200, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.737 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.740 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.734 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=4, min_child_weight=1, n_estimators=100, scale_pos_weight=10, subsample=1.0;, score=0.800 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=4, min_child_weight=1, n_estimators=100, scale_pos_weight=10, subsample=1.0;, score=0.786 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.05, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.05, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.925 total time=  14.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=20, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=0.6;, score=0.927 total time=   4.8s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.855 total time=   3.4s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.850 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.790 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=1.0;, score=0.910 total time=  16.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.881 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.882 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=1.0;, score=0.808 total time=  13.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=5, n_estimators=200, scale_pos_weight=2, subsample=1.0;, score=0.907 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.886 total time=   9.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.02, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.675 total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.965 total time=  16.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.920 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=30, subsample=0.6;, score=0.939 total time= 2.5min\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.787 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.02, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=1.0;, score=0.815 total time=   4.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=4, min_child_weight=10, n_estimators=200, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.45, max_depth=10, min_child_weight=15, n_estimators=500, scale_pos_weight=5, subsample=0.8;, score=0.891 total time=   5.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.35, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, scale_pos_weight=1, subsample=0.6;, score=0.835 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.966 total time=  25.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.850 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.836 total time=   6.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=1.0;, score=0.903 total time=  15.6s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=1.0;, score=0.810 total time=  13.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=5, n_estimators=200, scale_pos_weight=2, subsample=1.0;, score=0.905 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.890 total time=   9.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.02, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.675 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.05, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=18, min_child_weight=5, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.896 total time=  22.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.767 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.824 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.757 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=3, subsample=1.0;, score=0.808 total time=   7.0s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=0.6;, score=0.783 total time=   4.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.45, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.950 total time=   3.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.45, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.952 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.865 total time=   7.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=16, min_child_weight=5, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=16, min_child_weight=5, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=16, min_child_weight=5, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=16, min_child_weight=5, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=16, min_child_weight=5, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.527 total time=  14.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.933 total time=  23.5s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.921 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.921 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.919 total time=   3.5s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.919 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.921 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.808 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=10, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.852 total time=   3.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=18, min_child_weight=5, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=0.8;, score=0.816 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.05, max_depth=18, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=1.0;, score=0.916 total time=   5.6s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.937 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=10, subsample=0.6;, score=0.911 total time=   4.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.45, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=0.6;, score=0.848 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.02, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.890 total time=  39.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.917 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=30, subsample=0.6;, score=0.941 total time= 2.5min\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.02, max_depth=3, min_child_weight=15, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.785 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.02, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=1.0;, score=0.818 total time=   4.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=5, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.45, max_depth=10, min_child_weight=15, n_estimators=500, scale_pos_weight=5, subsample=0.8;, score=0.891 total time=   5.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.35, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, scale_pos_weight=1, subsample=0.6;, score=0.837 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.962 total time=  25.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.791 total time=   3.4s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.836 total time=   7.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=1.0;, score=0.904 total time=  15.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.907 total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.912 total time=   3.9s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.02, max_depth=10, min_child_weight=5, n_estimators=200, scale_pos_weight=1, subsample=0.6;, score=0.906 total time=   6.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.889 total time=   9.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.05, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.894 total time=   6.9s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.554 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.05, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.942 total time=  11.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.05, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.940 total time=   9.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=5, subsample=0.6;, score=0.949 total time=   6.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=3, subsample=1.0;, score=0.808 total time=   7.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=4, subsample=1.0;, score=0.905 total time=  25.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.01, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.931 total time=  23.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=0.8;, score=0.820 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=0.8;, score=0.820 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=0.8;, score=0.824 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=0.8;, score=0.821 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=0.6;, score=0.948 total time=  42.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.952 total time=   9.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.939 total time=  10.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.932 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.787 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.790 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.0;, score=0.745 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.0;, score=0.748 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.729 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.725 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.914 total time=   4.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=1.0;, score=0.916 total time=   6.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.937 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.02, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.02, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.45, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=0.6;, score=0.849 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.919 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=20, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=20, subsample=1.0;, score=0.532 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.02, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=20, subsample=1.0;, score=0.526 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.968 total time=  19.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.857 total time=   3.4s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.848 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.851 total time=   3.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.850 total time=   3.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.851 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.919 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.35, max_depth=3, min_child_weight=7, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.856 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.893 total time= 2.0min\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.891 total time=  30.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.953 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.25, max_depth=5, min_child_weight=5, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=18, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=4, min_child_weight=10, n_estimators=200, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.45, max_depth=10, min_child_weight=15, n_estimators=500, scale_pos_weight=5, subsample=0.8;, score=0.894 total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.35, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.05, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.05, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.926 total time=  14.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.965 total time=  27.0s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.0;, score=0.902 total time=   5.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.880 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.876 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=1.0;, score=0.808 total time=  13.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=5, n_estimators=200, scale_pos_weight=2, subsample=1.0;, score=0.902 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.886 total time=   9.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.02, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.674 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.05, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.05, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=18, min_child_weight=5, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.891 total time=  22.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.764 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.826 total time=   2.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=5, subsample=0.6;, score=0.952 total time=   6.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=3, subsample=1.0;, score=0.811 total time=   7.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=4, subsample=1.0;, score=0.908 total time=  25.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.01, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.01, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.931 total time=  22.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=20, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.702 total time=  24.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.805 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.805 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.805 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=10, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.859 total time=   3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.871 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.02, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.877 total time=  12.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=0.8;, score=0.909 total time=  12.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=0.6;, score=0.849 total time=   7.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.951 total time=   4.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=0.8;, score=0.816 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=7, n_estimators=200, scale_pos_weight=30, subsample=1.0;, score=0.917 total time=   5.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.35, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.937 total time=   4.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.936 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.02, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=2, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.45, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=0.6;, score=0.853 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.902 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=1.0;, score=0.888 total time=  40.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=30, subsample=0.6;, score=0.945 total time= 2.5min\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.954 total time=   6.5s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.02, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=4, subsample=1.0;, score=0.813 total time=   4.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=30, subsample=0.8;, score=0.737 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=4, min_child_weight=1, n_estimators=100, scale_pos_weight=10, subsample=1.0;, score=0.786 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.01, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.35, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=200, scale_pos_weight=1, subsample=0.6;, score=0.835 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.963 total time=  25.6s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.05, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.795 total time=   3.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.837 total time=   7.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.02, max_depth=20, min_child_weight=7, n_estimators=100, scale_pos_weight=3, subsample=1.0;, score=0.906 total time=  15.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.912 total time=   4.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.25, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.25, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.25, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.25, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.25, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.02, max_depth=10, min_child_weight=5, n_estimators=200, scale_pos_weight=1, subsample=0.6;, score=0.907 total time=   6.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.02, max_depth=10, min_child_weight=5, n_estimators=200, scale_pos_weight=1, subsample=0.6;, score=0.907 total time=   7.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.05, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.891 total time=   6.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=18, min_child_weight=5, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.891 total time=  23.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.817 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.802 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.805 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.760 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=5, subsample=0.6;, score=0.950 total time=   6.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=0.6;, score=0.781 total time=   4.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=4, subsample=1.0;, score=0.907 total time=  25.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.01, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.01, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.25, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.45, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.929 total time=  23.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=20, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.705 total time=  27.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.802 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=10, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.857 total time=   3.5s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=10, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.861 total time=   3.4s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.25, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.929 total time=   4.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.35, max_depth=20, min_child_weight=5, n_estimators=100, scale_pos_weight=10, subsample=0.6;, score=0.928 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.45, max_depth=3, min_child_weight=20, n_estimators=500, scale_pos_weight=10, subsample=0.8;, score=0.851 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.788 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=200, scale_pos_weight=2, subsample=0.8;, score=0.836 total time=   7.6s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.0;, score=0.900 total time=   5.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.0;, score=0.897 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.878 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.45, max_depth=18, min_child_weight=1, n_estimators=500, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=1.0;, score=0.812 total time=  13.8s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.02, max_depth=10, min_child_weight=5, n_estimators=200, scale_pos_weight=1, subsample=0.6;, score=0.909 total time=   7.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.05, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.893 total time=   6.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=18, min_child_weight=5, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.890 total time=  22.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.768 total time=   2.9s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.804 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.805 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.755 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=3, subsample=1.0;, score=0.815 total time=   7.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=0.6;, score=0.780 total time=   4.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.45, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.951 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=1, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.866 total time=   7.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.870 total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.528 total time=  14.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.732 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.724 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=18, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.02, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.02, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=20, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.703 total time=  13.4s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=0.6;, score=0.952 total time=  42.1s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.926 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.939 total time=  11.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.45, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.931 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.837 total time=   3.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.936 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.792 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.791 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.0;, score=0.748 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.730 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.727 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=1.0;, score=0.926 total time=   4.6s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.909 total time=  17.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.35, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.832 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.955 total time=   4.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.934 total time=  10.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.853 total time=   5.0s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.944 total time=   8.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.859 total time=   3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=5, min_child_weight=5, n_estimators=200, scale_pos_weight=2, subsample=1.0;, score=0.902 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.887 total time=  10.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.02, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.671 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.02, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.673 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.02, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=3, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.05, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.05, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.05, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.05, max_depth=5, min_child_weight=20, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.560 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.555 total time=   2.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.05, max_depth=12, min_child_weight=20, n_estimators=760, scale_pos_weight=2, subsample=0.8;, score=0.941 total time=  11.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.771 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.826 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.805 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.761 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=500, scale_pos_weight=5, subsample=0.6;, score=0.951 total time=   6.7s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.25, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=30, subsample=0.6;, score=0.783 total time=   4.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.02, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=16, min_child_weight=7, n_estimators=760, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.45, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.956 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.45, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.950 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.870 total time=   7.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.45, max_depth=20, min_child_weight=7, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.869 total time=   5.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.531 total time=  14.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.6;, score=0.930 total time=  23.5s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=0.6;, score=0.951 total time=  37.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.954 total time=   9.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.45, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.932 total time=   3.5s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.835 total time=   4.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.945 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.934 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.786 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.0;, score=0.754 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.0;, score=0.746 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.35, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.728 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.05, max_depth=4, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=0.8;, score=0.801 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.910 total time=  16.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.942 total time=  15.4s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=0.6;, score=0.689 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.852 total time=   5.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.946 total time=   8.0s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.946 total time=   3.9s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.859 total time=   4.6s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=4, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=0.6;, score=0.875 total time=  10.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.950 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.956 total time=   6.1s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=4, subsample=1.0;, score=0.894 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.45, max_depth=3, min_child_weight=15, n_estimators=200, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.05, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.05, max_depth=16, min_child_weight=7, n_estimators=100, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=18, min_child_weight=5, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.890 total time=  22.6s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.769 total time=   2.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.825 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=10, subsample=1.0;, score=0.757 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.01, max_depth=5, min_child_weight=7, n_estimators=760, scale_pos_weight=3, subsample=1.0;, score=0.808 total time=   7.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=760, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=4, subsample=1.0;, score=0.909 total time=  25.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.526 total time=  14.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.722 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.35, max_depth=3, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=1.0;, score=0.720 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.02, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.02, max_depth=20, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=15, n_estimators=760, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=20, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=0.8;, score=0.708 total time=  13.7s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=0.6;, score=0.950 total time=  42.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.957 total time=   9.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.935 total time=  10.5s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.936 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.949 total time=   8.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.05, max_depth=4, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=0.8;, score=0.805 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.05, max_depth=4, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=0.8;, score=0.801 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.910 total time=  17.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.35, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.835 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.604 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.601 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.935 total time=  10.1s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.853 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=1.0;, score=0.636 total time=   4.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.946 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.860 total time=   3.8s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.889 total time=  10.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=5, n_estimators=200, scale_pos_weight=5, subsample=0.6;, score=0.747 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.954 total time=   5.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.956 total time=   6.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=4, subsample=1.0;, score=0.896 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=4, subsample=1.0;, score=0.900 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.874 total time=   7.8s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.871 total time=   6.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=12, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.949 total time=  15.6s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.45, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.45, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.45, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.45, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.45, max_depth=3, min_child_weight=7, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.801 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.802 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.943 total time=  18.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=12, min_child_weight=7, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.872 total time=  20.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.25, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.931 total time=   4.0s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.25, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.927 total time=   4.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=4, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.505 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=4, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.505 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.922 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.953 total time=   9.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.45, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.933 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.840 total time=   4.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.945 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.949 total time=   8.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=1.0;, score=0.924 total time=   4.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.908 total time=  17.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.35, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.834 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.954 total time=   4.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.600 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=0.6;, score=0.685 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=0.6;, score=0.686 total time=   3.5s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=500, scale_pos_weight=5, subsample=0.6;, score=0.685 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.949 total time=   3.5s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.943 total time=   7.9s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.944 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.883 total time=  11.0s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=0.6;, score=0.874 total time=   7.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.955 total time=   6.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=0.6;, score=0.945 total time=  25.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.877 total time=   3.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.664 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.666 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=10, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=10, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=10, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=20, n_estimators=100, scale_pos_weight=2, subsample=0.8;, score=0.903 total time=   2.7s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.506 total time=   8.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.500 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01, max_depth=4, min_child_weight=20, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.500 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.812 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.45, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=12, min_child_weight=7, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.877 total time=  20.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.941 total time=   5.0s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.890 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=10, subsample=0.8;, score=0.941 total time= 6.6min\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=10, subsample=0.8;, score=0.945 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.02, max_depth=16, min_child_weight=15, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.556 total time=  13.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=16, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01, max_depth=16, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=1, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.938 total time=  19.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.585 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.958 total time=   7.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.955 total time=   7.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.869 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.869 total time=   4.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.45, max_depth=16, min_child_weight=10, n_estimators=760, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.01, max_depth=16, min_child_weight=20, n_estimators=760, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.05, max_depth=4, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=0.8;, score=0.793 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.05, max_depth=4, min_child_weight=15, n_estimators=100, scale_pos_weight=1, subsample=0.8;, score=0.804 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.909 total time=  17.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.35, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.958 total time=   4.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.600 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.942 total time=  10.1s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.846 total time=   4.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.943 total time=   8.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.945 total time=   4.0s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.882 total time=  11.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.25, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.25, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.25, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=5, n_estimators=200, scale_pos_weight=5, subsample=0.6;, score=0.750 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=5, n_estimators=200, scale_pos_weight=5, subsample=0.6;, score=0.747 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.958 total time=   6.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.898 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=0.6;, score=0.943 total time=  26.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=10, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=10, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=10, min_child_weight=15, n_estimators=500, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.25, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.25, max_depth=12, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.872 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.25, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=0.6;, score=0.874 total time=   3.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.664 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=20, n_estimators=100, scale_pos_weight=2, subsample=0.8;, score=0.902 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.506 total time=   8.7s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.945 total time=  16.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.05, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=1.0;, score=0.899 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.927 total time=   3.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.925 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.945 total time=   5.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=10, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.847 total time=   5.4s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.808 total time=  17.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.811 total time= 5.9min\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.05, learning_rate=0.01, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.505 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.847 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.848 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.891 total time=   8.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.887 total time=   6.9s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.960 total time=  22.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=40, subsample=0.6;, score=0.735 total time=   4.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=40, subsample=0.6;, score=0.732 total time=   3.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.586 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.02, max_depth=16, min_child_weight=5, n_estimators=760, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.35, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=1.0;, score=0.933 total time= 1.8min\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=0.8;, score=0.798 total time=   7.8s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.05, max_depth=4, min_child_weight=20, n_estimators=760, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.915 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=2, subsample=0.6;, score=0.808 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.885 total time=  11.0s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=0.6;, score=0.875 total time=   7.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=16, min_child_weight=15, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.954 total time=   6.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=4, subsample=1.0;, score=0.897 total time=   3.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=500, scale_pos_weight=4, subsample=1.0;, score=0.895 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=7, n_estimators=500, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.877 total time=   7.9s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=12, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.950 total time=  16.4s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.05, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.665 total time=   3.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=20, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=10, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=10, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=15, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=3, min_child_weight=1, n_estimators=200, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=20, n_estimators=100, scale_pos_weight=2, subsample=0.8;, score=0.903 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.803 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.943 total time=  18.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.45, max_depth=12, min_child_weight=10, n_estimators=100, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.05, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=1.0;, score=0.901 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.05, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=1.0;, score=0.901 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.05, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=1.0;, score=0.897 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.922 total time=   3.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.35, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=3, subsample=0.6;, score=0.941 total time=   5.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=10, subsample=0.8;, score=0.940 total time= 6.6min\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.02, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.35, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=10, subsample=0.8;, score=0.944 total time=   3.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.02, max_depth=16, min_child_weight=15, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.556 total time=  13.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.960 total time=  13.4s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=40, subsample=0.6;, score=0.734 total time=   4.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=20, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.25, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.25, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.25, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.584 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.35, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.35, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=1.0;, score=0.932 total time= 1.9min\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=15, n_estimators=100, scale_pos_weight=2, subsample=0.6;, score=0.778 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.0;, score=0.714 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=5, learning_rate=0.05, max_depth=4, min_child_weight=7, n_estimators=100, scale_pos_weight=5, subsample=1.0;, score=0.718 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=4, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=0.8;, score=0.567 total time=   2.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.914 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=2, subsample=0.6;, score=0.812 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.25, max_depth=18, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=0.8;, score=0.946 total time=   3.4s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.45, max_depth=12, min_child_weight=15, n_estimators=200, scale_pos_weight=1, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=4, subsample=0.8;, score=0.796 total time=   3.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.906 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.25, max_depth=10, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.943 total time=   7.3s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.02, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=3, subsample=0.6;, score=0.726 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.05, max_depth=4, min_child_weight=10, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.580 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=16, min_child_weight=1, n_estimators=200, scale_pos_weight=3, subsample=1.0;, score=0.951 total time=   4.9s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.02, max_depth=3, min_child_weight=5, n_estimators=500, scale_pos_weight=40, subsample=0.8;, score=0.586 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.01, max_depth=12, min_child_weight=15, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.630 total time=   5.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.35, max_depth=16, min_child_weight=5, n_estimators=200, scale_pos_weight=2, subsample=0.6;, score=0.963 total time=   4.7s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=7, n_estimators=500, scale_pos_weight=2, subsample=0.8;, score=0.843 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=100, scale_pos_weight=40, subsample=1.0;, score=0.849 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.25, max_depth=20, min_child_weight=1, n_estimators=760, scale_pos_weight=1, subsample=0.8;, score=0.965 total time=   7.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.02, max_depth=3, min_child_weight=20, n_estimators=100, scale_pos_weight=1, subsample=0.6;, score=0.794 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.35, max_depth=18, min_child_weight=1, n_estimators=760, scale_pos_weight=30, subsample=1.0;, score=0.930 total time=  16.7s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.35, max_depth=16, min_child_weight=10, n_estimators=100, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.01, max_depth=3, min_child_weight=10, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=12, min_child_weight=15, n_estimators=760, scale_pos_weight=40, subsample=1.0;, score=0.944 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.25, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=20, subsample=0.8;, score=0.917 total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=10, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.856 total time=   3.3s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.25, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.928 total time=   4.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.25, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=0.8;, score=0.931 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.922 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.02, max_depth=4, min_child_weight=5, n_estimators=100, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=10, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.935 total time=  12.1s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.840 total time=   4.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.35, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=5, subsample=0.6;, score=0.945 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=760, scale_pos_weight=10, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.946 total time=   8.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.5, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=100, scale_pos_weight=10, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=100, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=1.0;, score=0.926 total time=   4.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.944 total time=  16.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.838 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.955 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.935 total time=  10.1s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=16, min_child_weight=5, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.853 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=5, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.01, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.25, max_depth=12, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.943 total time=   7.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.45, max_depth=18, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.946 total time=   3.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.25, max_depth=20, min_child_weight=15, n_estimators=100, scale_pos_weight=4, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=760, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.883 total time=  11.1s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.25, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.25, max_depth=16, min_child_weight=20, n_estimators=500, scale_pos_weight=4, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=5, min_child_weight=1, n_estimators=760, scale_pos_weight=30, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=5, n_estimators=200, scale_pos_weight=5, subsample=0.6;, score=0.744 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=5, n_estimators=200, scale_pos_weight=5, subsample=0.6;, score=0.745 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.949 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.893 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=0.6;, score=0.943 total time=  26.1s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=12, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.952 total time=  15.6s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.805 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.947 total time=  18.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.01, max_depth=12, min_child_weight=7, n_estimators=500, scale_pos_weight=10, subsample=0.6;, score=0.873 total time=  20.7s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=18, min_child_weight=20, n_estimators=100, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=10, subsample=0.8;, score=0.941 total time= 6.6min\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.45, max_depth=16, min_child_weight=1, n_estimators=200, scale_pos_weight=40, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.02, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.02, max_depth=5, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.45, max_depth=10, min_child_weight=20, n_estimators=100, scale_pos_weight=20, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.35, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.35, max_depth=5, min_child_weight=15, n_estimators=500, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.45, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=10, subsample=0.8;, score=0.943 total time=   3.4s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.962 total time=  21.8s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=40, subsample=0.6;, score=0.934 total time=  19.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.25, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=5, subsample=1.0;, score=0.956 total time=   7.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.862 total time=   5.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=760, scale_pos_weight=2, subsample=0.6;, score=0.866 total time=   4.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1, learning_rate=0.1, max_depth=3, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=18, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=4, min_child_weight=15, n_estimators=760, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=500, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=500, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.35, max_depth=4, min_child_weight=20, n_estimators=500, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.02, max_depth=18, min_child_weight=10, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=4, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=0.6;, score=0.747 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.02, max_depth=4, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=0.6;, score=0.751 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.01, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=1.0;, score=0.941 total time=  52.9s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1, learning_rate=0.01, max_depth=18, min_child_weight=10, n_estimators=760, scale_pos_weight=2, subsample=1.0;, score=0.941 total time=  42.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=4, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.503 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=4, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.504 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1, learning_rate=0.01, max_depth=4, min_child_weight=10, n_estimators=100, scale_pos_weight=30, subsample=1.0;, score=0.506 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.45, max_depth=5, min_child_weight=5, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.927 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=200, scale_pos_weight=5, subsample=0.8;, score=0.951 total time=  10.0s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.25, max_depth=16, min_child_weight=20, n_estimators=200, scale_pos_weight=5, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=5, learning_rate=0.01, max_depth=20, min_child_weight=20, n_estimators=500, scale_pos_weight=2, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.45, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=20, subsample=0.8;, score=0.930 total time=   3.5s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=12, min_child_weight=1, n_estimators=760, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, min_child_weight=20, n_estimators=200, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=16, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.837 total time=   4.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.1, max_depth=12, min_child_weight=5, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.936 total time=   3.0s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=500, scale_pos_weight=2, subsample=0.6;, score=0.947 total time=   8.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.02, max_depth=18, min_child_weight=15, n_estimators=200, scale_pos_weight=40, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.45, max_depth=20, min_child_weight=5, n_estimators=760, scale_pos_weight=40, subsample=1.0;, score=0.925 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=760, scale_pos_weight=20, subsample=0.6;, score=0.947 total time=  16.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.25, max_depth=3, min_child_weight=10, n_estimators=760, scale_pos_weight=30, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=500, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=760, scale_pos_weight=2, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.35, max_depth=12, min_child_weight=20, n_estimators=500, scale_pos_weight=40, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=5, min_child_weight=20, n_estimators=200, scale_pos_weight=4, subsample=0.8;, score=0.836 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=5, subsample=1.0;, score=0.953 total time=   4.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, scale_pos_weight=5, subsample=0.8;, score=0.602 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.8, learning_rate=0.1, max_depth=16, min_child_weight=1, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.938 total time=   9.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.949 total time=   3.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=1.5, learning_rate=0.25, max_depth=20, min_child_weight=10, n_estimators=760, scale_pos_weight=1, subsample=1.0;, score=0.949 total time=   3.6s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=0.05, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=760, scale_pos_weight=4, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=1.0;, score=0.644 total time=   4.3s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.01, max_depth=4, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=1.0;, score=0.639 total time=   4.5s\n",
      "[CV 3/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.45, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=2, subsample=1.0;, score=0.851 total time=   4.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=4, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.5, learning_rate=0.05, max_depth=4, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=2.5;, score=nan total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.35, max_depth=20, min_child_weight=7, n_estimators=500, scale_pos_weight=5, subsample=0.6;, score=0.877 total time=  10.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.1, max_depth=16, min_child_weight=5, n_estimators=500, scale_pos_weight=1, subsample=1.0;, score=0.952 total time=   5.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.8, learning_rate=0.25, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=4, subsample=0.6;, score=0.896 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.05, max_depth=16, min_child_weight=1, n_estimators=760, scale_pos_weight=10, subsample=0.6;, score=0.946 total time=  25.9s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.02, max_depth=12, min_child_weight=7, n_estimators=760, scale_pos_weight=1, subsample=0.6;, score=0.948 total time=  15.6s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.25, max_depth=3, min_child_weight=10, n_estimators=200, scale_pos_weight=4, subsample=1.0;, score=0.804 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.01, max_depth=12, min_child_weight=5, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.506 total time=   8.7s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=10, n_estimators=760, scale_pos_weight=20, subsample=0.8;, score=0.944 total time=  16.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.05, learning_rate=0.05, max_depth=10, min_child_weight=5, n_estimators=100, scale_pos_weight=3, subsample=1.0;, score=0.902 total time=   3.8s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.8, learning_rate=0.35, max_depth=3, min_child_weight=10, n_estimators=500, scale_pos_weight=5, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.926 total time=   3.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.45, max_depth=4, min_child_weight=7, n_estimators=500, scale_pos_weight=3, subsample=0.6;, score=0.927 total time=   3.5s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.6, gamma=1.5, learning_rate=0.35, max_depth=18, min_child_weight=10, n_estimators=100, scale_pos_weight=1, subsample=2.0;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.888 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=5, learning_rate=0.25, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=0.6;, score=0.887 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=10, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.841 total time=   5.3s\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=5, learning_rate=0.05, max_depth=10, min_child_weight=15, n_estimators=500, scale_pos_weight=2, subsample=1.0;, score=0.845 total time=   5.9s\n",
      "[CV 2/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.811 total time=  20.4s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=0.3, learning_rate=0.1, max_depth=16, min_child_weight=7, n_estimators=200, scale_pos_weight=10, subsample=1.0;, score=0.809 total time= 5.8min\n",
      "[CV 3/5] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=200, scale_pos_weight=3, subsample=0.6;, score=0.849 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=100, scale_pos_weight=10, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.889 total time=   8.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.05, max_depth=12, min_child_weight=7, n_estimators=500, scale_pos_weight=30, subsample=1.0;, score=0.888 total time=   6.9s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.05, max_depth=12, min_child_weight=1, n_estimators=500, scale_pos_weight=1, subsample=0.8;, score=0.961 total time=  21.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.05, max_depth=5, min_child_weight=15, n_estimators=100, scale_pos_weight=5, subsample=2.0;, score=nan total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=40, subsample=0.6;, score=0.740 total time=   4.2s\n",
      "[CV 4/5] END colsample_bytree=0.6, gamma=0.8, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=760, scale_pos_weight=40, subsample=0.6;, score=0.732 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.25, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, gamma=1.5, learning_rate=0.25, max_depth=10, min_child_weight=15, n_estimators=200, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=5, learning_rate=0.01, max_depth=10, min_child_weight=15, n_estimators=100, scale_pos_weight=40, subsample=0.6;, score=0.584 total time=   2.8s\n",
      "[CV 2/5] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.35, max_depth=3, min_child_weight=15, n_estimators=500, scale_pos_weight=20, subsample=1.5;, score=nan total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.6, gamma=1, learning_rate=0.01, max_depth=20, min_child_weight=5, n_estimators=760, scale_pos_weight=20, subsample=1.0;, score=0.937 total time= 1.8min\n",
      "[CV 4/5] END colsample_bytree=0.1, gamma=0.1, learning_rate=0.05, max_depth=20, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=0.8;, score=0.795 total time=   8.2s\n",
      "[CV 5/5] END colsample_bytree=0.1, gamma=1.5, learning_rate=0.02, max_depth=4, min_child_weight=20, n_estimators=500, scale_pos_weight=20, subsample=0.8;, score=0.568 total time=   2.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=200, scale_pos_weight=2, subsample=0.6;, score=0.806 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=4, min_child_weight=15, n_estimators=100, scale_pos_weight=3, subsample=0.8;, score=0.841 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.3, gamma=0.8, learning_rate=0.45, max_depth=4, min_child_weight=15, n_estimators=100, scale_pos_weight=3, subsample=0.8;, score=0.842 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1, learning_rate=0.35, max_depth=18, min_child_weight=7, n_estimators=100, scale_pos_weight=20, subsample=2.5;, score=nan total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=1.5, learning_rate=0.25, max_depth=18, min_child_weight=20, n_estimators=200, scale_pos_weight=3, subsample=0.8;, score=0.949 total time=   3.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.1, 0.3, 0.6, 0.8,\n",
       "                                                             1.0],\n",
       "                                        &#x27;gamma&#x27;: [0.3, 0.05, 0.8, 0.1, 0.5, 1,\n",
       "                                                  1.5, 5],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.02, 0.05, 0.1,\n",
       "                                                          0.25, 0.35, 0.45],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5, 10, 12, 16, 18,\n",
       "                                                      20],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 5, 7, 10, 15,\n",
       "                                                             20],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 500, 760],\n",
       "                                        &#x27;scale_pos_weight&#x27;: [1, 2, 3, 4, 5, 10,\n",
       "                                                             20, 30, 40],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0, 1.5, 2.0,\n",
       "                                                      2.5]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.1, 0.3, 0.6, 0.8,\n",
       "                                                             1.0],\n",
       "                                        &#x27;gamma&#x27;: [0.3, 0.05, 0.8, 0.1, 0.5, 1,\n",
       "                                                  1.5, 5],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.02, 0.05, 0.1,\n",
       "                                                          0.25, 0.35, 0.45],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5, 10, 12, 16, 18,\n",
       "                                                      20],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 5, 7, 10, 15,\n",
       "                                                             20],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 500, 760],\n",
       "                                        &#x27;scale_pos_weight&#x27;: [1, 2, 3, 4, 5, 10,\n",
       "                                                             20, 30, 40],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0, 1.5, 2.0,\n",
       "                                                      2.5]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                   param_distributions={'colsample_bytree': [0.1, 0.3, 0.6, 0.8,\n",
       "                                                             1.0],\n",
       "                                        'gamma': [0.3, 0.05, 0.8, 0.1, 0.5, 1,\n",
       "                                                  1.5, 5],\n",
       "                                        'learning_rate': [0.01, 0.02, 0.05, 0.1,\n",
       "                                                          0.25, 0.35, 0.45],\n",
       "                                        'max_depth': [3, 4, 5, 10, 12, 16, 18,\n",
       "                                                      20],\n",
       "                                        'min_child_weight': [1, 5, 7, 10, 15,\n",
       "                                                             20],\n",
       "                                        'n_estimators': [100, 200, 500, 760],\n",
       "                                        'scale_pos_weight': [1, 2, 3, 4, 5, 10,\n",
       "                                                             20, 30, 40],\n",
       "                                        'subsample': [0.6, 0.8, 1.0, 1.5, 2.0,\n",
       "                                                      2.5]},\n",
       "                   random_state=42, scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(pc_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "165fcbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=0.1, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=16, max_leaves=None,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=760, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "\n",
      " Best accuracy for 5-fold search with 800 parameter combinations:\n",
      "0.9694310006708236\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 0.6, 'scale_pos_weight': 1, 'n_estimators': 760, 'min_child_weight': 1, 'max_depth': 16, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best accuracy for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ )\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8fad02a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=16, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=760, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=71, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=16, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=760, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=71, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=16, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=760, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=71, ...)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets build the model using best parameters\n",
    "params = random_search.best_params_\n",
    "model = xgb.XGBClassifier(**params, random_state=71)\n",
    "model.fit(pc_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0033be97",
   "metadata": {},
   "source": [
    "##### Testing the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6cca4e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Set: 1.0000\n",
      "Accuracy on Test Set: 0.9254\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the classifier on the training data\n",
    "#model.fit(pc_X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_ran = model.predict(pc_X_train)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate accuracy on the training set\n",
    "accuracy_train_ran = accuracy_score(y_train, y_train_pred_ran)\n",
    "\n",
    "## Make predictions on the test set\n",
    "y_test_pred_ran = model.predict(pc_X_test)\n",
    "\n",
    "#Calculate accuracy on the test set\n",
    "accuracy_test_ran = accuracy_score(y_test, y_test_pred_ran)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy on Training Set: {accuracy_train_ran:.4f}\")\n",
    "print(f\"Accuracy on Test Set: {accuracy_test_ran:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5141a39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9560766371175293\n",
      "Sensitivity (Recall): 0.42988929889298894\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_ran).ravel()\n",
    "\n",
    "# Calculate specificity and sensitivity (recall)\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# Print the results\n",
    "print('Specificity:', specificity)\n",
    "print('Sensitivity (Recall):', sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f647fd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16717,   768],\n",
       "       [  618,   466]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred_ran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "59342f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37763371150729336"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_test_pred_ran)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "02778d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42988929889298894"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y_test, y_test_pred_ran)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d62b8c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81586,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4b6765af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81586, 20)\n",
      "(18569, 20)\n",
      "(81586,)\n",
      "(18569,)\n"
     ]
    }
   ],
   "source": [
    "print(pc_X_train.shape)\n",
    "print(pc_X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1e244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0ab9578",
   "metadata": {},
   "source": [
    "### 7.  Creating Submission File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ae79c1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  churn_probability\n",
       "0  69999                  0\n",
       "1  70000                  0\n",
       "2  70001                  0\n",
       "3  70002                  0\n",
       "4  70003                  0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the sample results\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "72db7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets prepare the test data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35d80800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 147)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30000, 1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids=pd.DataFrame(test['id'])\n",
    "test=test[X.columns]\n",
    "print(test.shape)\n",
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "618e5968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "days_stayed                 0.112667\n",
       "date_of_last_rech_8         0.105500\n",
       "date_of_last_rech_6         0.096967\n",
       "date_of_last_rech_7         0.096133\n",
       "spl_ic_mou_8                0.055833\n",
       "                              ...   \n",
       "vol_3g_mb_7                 0.000000\n",
       "vol_3g_mb_8                 0.000000\n",
       "monthly_2g_6                0.000000\n",
       "monthly_2g_7                0.000000\n",
       "decrease_rech_num_action    0.000000\n",
       "Length: 147, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = test.isna().sum()\n",
    "percentage_missing = (missing_values / len(test)).sort_values(ascending=False)\n",
    "percentage_missing \n",
    "# Display the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9ef62570",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_percent_test = test.isnull().any()\n",
    "impute_cols_test = missing_data_percent_test[missing_data_percent_test.gt(0)].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "17410e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['onnet_mou_6', 'onnet_mou_7', 'onnet_mou_8', 'offnet_mou_6',\n",
       "       'offnet_mou_7', 'offnet_mou_8', 'roam_ic_mou_6', 'roam_ic_mou_7',\n",
       "       'roam_ic_mou_8', 'roam_og_mou_6', 'roam_og_mou_7', 'roam_og_mou_8',\n",
       "       'loc_og_t2t_mou_6', 'loc_og_t2t_mou_7', 'loc_og_t2t_mou_8',\n",
       "       'loc_og_t2m_mou_6', 'loc_og_t2m_mou_7', 'loc_og_t2m_mou_8',\n",
       "       'loc_og_t2f_mou_6', 'loc_og_t2f_mou_7', 'loc_og_t2f_mou_8',\n",
       "       'loc_og_t2c_mou_6', 'loc_og_t2c_mou_7', 'loc_og_t2c_mou_8',\n",
       "       'loc_og_mou_6', 'loc_og_mou_7', 'loc_og_mou_8', 'std_og_t2t_mou_6',\n",
       "       'std_og_t2t_mou_7', 'std_og_t2t_mou_8', 'std_og_t2m_mou_6',\n",
       "       'std_og_t2m_mou_7', 'std_og_t2m_mou_8', 'std_og_t2f_mou_6',\n",
       "       'std_og_t2f_mou_7', 'std_og_t2f_mou_8', 'std_og_mou_6', 'std_og_mou_7',\n",
       "       'std_og_mou_8', 'isd_og_mou_6', 'isd_og_mou_7', 'isd_og_mou_8',\n",
       "       'spl_og_mou_6', 'spl_og_mou_7', 'spl_og_mou_8', 'og_others_6',\n",
       "       'og_others_7', 'og_others_8', 'loc_ic_t2t_mou_6', 'loc_ic_t2t_mou_7',\n",
       "       'loc_ic_t2t_mou_8', 'loc_ic_t2m_mou_6', 'loc_ic_t2m_mou_7',\n",
       "       'loc_ic_t2m_mou_8', 'loc_ic_t2f_mou_6', 'loc_ic_t2f_mou_7',\n",
       "       'loc_ic_t2f_mou_8', 'loc_ic_mou_6', 'loc_ic_mou_7', 'loc_ic_mou_8',\n",
       "       'std_ic_t2t_mou_6', 'std_ic_t2t_mou_7', 'std_ic_t2t_mou_8',\n",
       "       'std_ic_t2m_mou_6', 'std_ic_t2m_mou_7', 'std_ic_t2m_mou_8',\n",
       "       'std_ic_t2f_mou_6', 'std_ic_t2f_mou_7', 'std_ic_t2f_mou_8',\n",
       "       'std_ic_mou_6', 'std_ic_mou_7', 'std_ic_mou_8', 'spl_ic_mou_6',\n",
       "       'spl_ic_mou_7', 'spl_ic_mou_8', 'isd_ic_mou_6', 'isd_ic_mou_7',\n",
       "       'isd_ic_mou_8', 'ic_others_6', 'ic_others_7', 'ic_others_8',\n",
       "       'date_of_last_rech_6', 'date_of_last_rech_7', 'date_of_last_rech_8',\n",
       "       'days_stayed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_cols_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d61b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4fd8b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value treatment\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputer for numerical columns\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "test[impute_cols_test] = num_imputer.fit_transform(test[impute_cols_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a9d7f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arpu_6                      0.0\n",
       "vol_3g_mb_8                 0.0\n",
       "total_rech_amt_7            0.0\n",
       "total_rech_amt_8            0.0\n",
       "max_rech_amt_6              0.0\n",
       "                           ... \n",
       "og_others_7                 0.0\n",
       "og_others_8                 0.0\n",
       "total_og_mou_6              0.0\n",
       "total_og_mou_7              0.0\n",
       "decrease_rech_num_action    0.0\n",
       "Length: 147, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test.isna().sum()*100/len(test)).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c09c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3836d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f0b1fc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -6.19112922,  -1.51931849,  -1.4264827 , ...,  -4.194273  ,\n",
       "         -2.99714633,   0.30849492],\n",
       "       [  5.34133968,  -5.60637352,   0.40653122, ...,  -3.72043325,\n",
       "         -4.06585784,   0.04190667],\n",
       "       [ -1.97847759,   1.09938122,   3.15599181, ...,  -4.18549719,\n",
       "         -3.2086835 ,  -1.06637482],\n",
       "       ...,\n",
       "       [ -6.89206829,  -0.06925705,  -0.31718187, ...,  -4.08804837,\n",
       "         -3.55834206,  -1.04626202],\n",
       "       [ 14.76822036,  17.75563915, -18.37077428, ...,   3.69244693,\n",
       "         -7.91659853,   2.3981529 ],\n",
       "       [  1.27920104,   4.92514817,   4.17342678, ...,   2.34485807,\n",
       "         -4.73998832,  -2.41224829]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Fit and transform the test data using the previously fitted StandardScaler\n",
    "test_scaled = pd.DataFrame(data=ss.transform(test), columns=test.columns)\n",
    "\n",
    "# Apply PCA on the test data\n",
    "pca_test = pca.transform(test_scaled)\n",
    "pca_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4966f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b8085e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 20)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c510cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the PCA results to a DataFrame\n",
    "pca_test_df = pd.DataFrame(data=pca_test, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "41de442d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec73f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b9e8181b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  churn_probability\n",
       "0  69999                  0\n",
       "1  70000                  0\n",
       "2  70001                  0\n",
       "3  70002                  0\n",
       "4  70003                  0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result using xgboost model\n",
    "xgb_result = pd.DataFrame(pd.DataFrame(model.predict(pca_test_df),columns=['churn_probability']))\n",
    "output = pd.concat([ids, xgb_result],axis=1 )\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1fec229f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  churn_probability\n",
       "0  69999                  0\n",
       "1  70000                  0\n",
       "2  70001                  0\n",
       "3  70002                  0\n",
       "4  70003                  0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.concat([ids, xgb_result],axis=1 )\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f1625ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 2)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.to_csv('Submission.csv',index=False)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c3510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b1431d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc7a02",
   "metadata": {},
   "source": [
    "###  8. Part two: Important Features Selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "688eb6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48911, 147)\n",
      "(18569, 147)\n",
      "(48911,)\n",
      "(18569,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into train and test \n",
    "# splitting the data into test and train data\n",
    "X_train_test, X_test_test, y_train_test, y_test_test = train_test_split(X_scaled, y, test_size=0.30, random_state=42,stratify=y)                                                                       \n",
    "# Using Combined sampling to handle imbalanced dataset\n",
    "smt = SMOTETomek(random_state=40, sampling_strategy=0.2, n_jobs=-1)\n",
    "X_train_test, y_train_test = smt.fit_resample(X_train_test, y_train_test)\n",
    "print(X_train_test.shape)\n",
    "print(X_test_test.shape)\n",
    "print(y_train_test.shape)\n",
    "print(y_test_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1a723617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>total_ic_mou_8</td>\n",
       "      <td>21.589979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "      <td>7.093407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>date_of_last_rech_8</td>\n",
       "      <td>3.512749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>decrease_arpu_action</td>\n",
       "      <td>2.639903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>decrease_mou_action</td>\n",
       "      <td>2.444579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>total_rech_num_7</td>\n",
       "      <td>2.263006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "      <td>2.233981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>total_rech_num_8</td>\n",
       "      <td>2.081431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>total_rech_num_6</td>\n",
       "      <td>1.942904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>decrease_rech_num_action</td>\n",
       "      <td>1.807736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>date_of_last_rech_6</td>\n",
       "      <td>1.721616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>last_day_rch_amt_7</td>\n",
       "      <td>1.604200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>std_og_mou_7</td>\n",
       "      <td>1.512674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>max_rech_amt_8</td>\n",
       "      <td>1.501661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>spl_og_mou_7</td>\n",
       "      <td>1.469272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>std_og_t2t_mou_8</td>\n",
       "      <td>1.396161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>total_mou_good</td>\n",
       "      <td>1.320330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>last_day_rch_amt_6</td>\n",
       "      <td>1.292057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>spl_og_mou_8</td>\n",
       "      <td>0.994087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>loc_og_mou_8</td>\n",
       "      <td>0.950224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>date_of_last_rech_7</td>\n",
       "      <td>0.925981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>total_ic_mou_7</td>\n",
       "      <td>0.920507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>std_og_t2t_mou_7</td>\n",
       "      <td>0.896852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>onnet_mou_6</td>\n",
       "      <td>0.854539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>std_ic_t2m_mou_7</td>\n",
       "      <td>0.853822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>days_stayed</td>\n",
       "      <td>0.853262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>spl_og_mou_6</td>\n",
       "      <td>0.848860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>loc_og_t2f_mou_8</td>\n",
       "      <td>0.837826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>std_ic_mou_7</td>\n",
       "      <td>0.837041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>total_og_mou_8</td>\n",
       "      <td>0.817745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>std_og_t2m_mou_6</td>\n",
       "      <td>0.780753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>total_rech_amt_7</td>\n",
       "      <td>0.768410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>std_ic_t2t_mou_6</td>\n",
       "      <td>0.754241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>max_rech_amt_7</td>\n",
       "      <td>0.747237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>onnet_mou_8</td>\n",
       "      <td>0.743633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>onnet_mou_7</td>\n",
       "      <td>0.736694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>total_og_mou_7</td>\n",
       "      <td>0.668283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>loc_ic_mou_7</td>\n",
       "      <td>0.648094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>loc_og_t2t_mou_7</td>\n",
       "      <td>0.644190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>std_ic_t2t_mou_8</td>\n",
       "      <td>0.623657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>std_ic_t2m_mou_6</td>\n",
       "      <td>0.598489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>loc_ic_t2f_mou_6</td>\n",
       "      <td>0.587254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>std_og_t2m_mou_7</td>\n",
       "      <td>0.574415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>max_rech_amt_6</td>\n",
       "      <td>0.567402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>loc_ic_t2m_mou_8</td>\n",
       "      <td>0.561062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>std_og_mou_8</td>\n",
       "      <td>0.560986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>aon</td>\n",
       "      <td>0.555486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>total_rech_amt_8</td>\n",
       "      <td>0.553916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>diff_mou</td>\n",
       "      <td>0.531887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>std_og_mou_6</td>\n",
       "      <td>0.521978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>total_og_mou_6</td>\n",
       "      <td>0.520872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arpu_7</td>\n",
       "      <td>0.515203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>loc_og_mou_7</td>\n",
       "      <td>0.509259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>avg_rech_amt_6_7</td>\n",
       "      <td>0.507208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>offnet_mou_6</td>\n",
       "      <td>0.505529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>std_ic_mou_8</td>\n",
       "      <td>0.504292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>loc_og_t2m_mou_8</td>\n",
       "      <td>0.499823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>loc_og_t2f_mou_6</td>\n",
       "      <td>0.484934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>avg_rech_num_action</td>\n",
       "      <td>0.476003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>std_ic_t2t_mou_7</td>\n",
       "      <td>0.475878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>loc_og_mou_6</td>\n",
       "      <td>0.472718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>avg_mou_action</td>\n",
       "      <td>0.461210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arpu_8</td>\n",
       "      <td>0.459712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>diff_rech_amt</td>\n",
       "      <td>0.454706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>avg_total_6_7</td>\n",
       "      <td>0.452881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>loc_ic_t2m_mou_7</td>\n",
       "      <td>0.450139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>loc_og_t2t_mou_6</td>\n",
       "      <td>0.441444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>loc_ic_t2t_mou_6</td>\n",
       "      <td>0.441005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>loc_ic_t2t_mou_7</td>\n",
       "      <td>0.435841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>std_ic_mou_6</td>\n",
       "      <td>0.431095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>diff_arpu</td>\n",
       "      <td>0.425818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>diff_rech_num</td>\n",
       "      <td>0.423321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>std_og_t2m_mou_8</td>\n",
       "      <td>0.422425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>total_ic_mou_6</td>\n",
       "      <td>0.398938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "      <td>0.396767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>std_og_t2t_mou_6</td>\n",
       "      <td>0.394144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>loc_og_t2m_mou_7</td>\n",
       "      <td>0.394006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arpu_6</td>\n",
       "      <td>0.388921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>loc_ic_t2t_mou_8</td>\n",
       "      <td>0.375793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>offnet_mou_8</td>\n",
       "      <td>0.375217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>loc_ic_t2f_mou_7</td>\n",
       "      <td>0.372552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>avg_arpu_action</td>\n",
       "      <td>0.364826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>loc_ic_t2m_mou_6</td>\n",
       "      <td>0.357822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>loc_og_t2f_mou_7</td>\n",
       "      <td>0.354808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>avg_rech_amt_action</td>\n",
       "      <td>0.350970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>loc_ic_mou_6</td>\n",
       "      <td>0.350455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>loc_og_t2t_mou_8</td>\n",
       "      <td>0.347305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>offnet_mou_7</td>\n",
       "      <td>0.346188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>loc_og_t2m_mou_6</td>\n",
       "      <td>0.328752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>total_rech_amt_6</td>\n",
       "      <td>0.315973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>std_ic_t2m_mou_8</td>\n",
       "      <td>0.268784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature  importance\n",
       "80             total_ic_mou_8   21.589979\n",
       "65               loc_ic_mou_8    7.093407\n",
       "101       date_of_last_rech_8    3.512749\n",
       "135      decrease_arpu_action    2.639903\n",
       "141       decrease_mou_action    2.444579\n",
       "91           total_rech_num_7    2.263006\n",
       "104        last_day_rch_amt_8    2.233981\n",
       "92           total_rech_num_8    2.081431\n",
       "90           total_rech_num_6    1.942904\n",
       "146  decrease_rech_num_action    1.807736\n",
       "99        date_of_last_rech_6    1.721616\n",
       "103        last_day_rch_amt_7    1.604200\n",
       "40               std_og_mou_7    1.512674\n",
       "98             max_rech_amt_8    1.501661\n",
       "46               spl_og_mou_7    1.469272\n",
       "32           std_og_t2t_mou_8    1.396161\n",
       "139            total_mou_good    1.320330\n",
       "102        last_day_rch_amt_6    1.292057\n",
       "47               spl_og_mou_8    0.994087\n",
       "29               loc_og_mou_8    0.950224\n",
       "100       date_of_last_rech_7    0.925981\n",
       "79             total_ic_mou_7    0.920507\n",
       "31           std_og_t2t_mou_7    0.896852\n",
       "3                 onnet_mou_6    0.854539\n",
       "70           std_ic_t2m_mou_7    0.853822\n",
       "128               days_stayed    0.853262\n",
       "45               spl_og_mou_6    0.848860\n",
       "23           loc_og_t2f_mou_8    0.837826\n",
       "76               std_ic_mou_7    0.837041\n",
       "53             total_og_mou_8    0.817745\n",
       "33           std_og_t2m_mou_6    0.780753\n",
       "94           total_rech_amt_7    0.768410\n",
       "66           std_ic_t2t_mou_6    0.754241\n",
       "97             max_rech_amt_7    0.747237\n",
       "5                 onnet_mou_8    0.743633\n",
       "4                 onnet_mou_7    0.736694\n",
       "52             total_og_mou_7    0.668283\n",
       "64               loc_ic_mou_7    0.648094\n",
       "16           loc_og_t2t_mou_7    0.644190\n",
       "68           std_ic_t2t_mou_8    0.623657\n",
       "69           std_ic_t2m_mou_6    0.598489\n",
       "60           loc_ic_t2f_mou_6    0.587254\n",
       "34           std_og_t2m_mou_7    0.574415\n",
       "96             max_rech_amt_6    0.567402\n",
       "59           loc_ic_t2m_mou_8    0.561062\n",
       "41               std_og_mou_8    0.560986\n",
       "123                       aon    0.555486\n",
       "95           total_rech_amt_8    0.553916\n",
       "140                  diff_mou    0.531887\n",
       "39               std_og_mou_6    0.521978\n",
       "51             total_og_mou_6    0.520872\n",
       "1                      arpu_7    0.515203\n",
       "28               loc_og_mou_7    0.509259\n",
       "127          avg_rech_amt_6_7    0.507208\n",
       "6                offnet_mou_6    0.505529\n",
       "77               std_ic_mou_8    0.504292\n",
       "20           loc_og_t2m_mou_8    0.499823\n",
       "21           loc_og_t2f_mou_6    0.484934\n",
       "144       avg_rech_num_action    0.476003\n",
       "67           std_ic_t2t_mou_7    0.475878\n",
       "27               loc_og_mou_6    0.472718\n",
       "132            avg_mou_action    0.461210\n",
       "2                      arpu_8    0.459712\n",
       "137             diff_rech_amt    0.454706\n",
       "131             avg_total_6_7    0.452881\n",
       "58           loc_ic_t2m_mou_7    0.450139\n",
       "15           loc_og_t2t_mou_6    0.441444\n",
       "54           loc_ic_t2t_mou_6    0.441005\n",
       "55           loc_ic_t2t_mou_7    0.435841\n",
       "75               std_ic_mou_6    0.431095\n",
       "134                 diff_arpu    0.425818\n",
       "145             diff_rech_num    0.423321\n",
       "35           std_og_t2m_mou_8    0.422425\n",
       "78             total_ic_mou_6    0.398938\n",
       "62           loc_ic_t2f_mou_8    0.396767\n",
       "30           std_og_t2t_mou_6    0.394144\n",
       "19           loc_og_t2m_mou_7    0.394006\n",
       "0                      arpu_6    0.388921\n",
       "56           loc_ic_t2t_mou_8    0.375793\n",
       "8                offnet_mou_8    0.375217\n",
       "61           loc_ic_t2f_mou_7    0.372552\n",
       "133           avg_arpu_action    0.364826\n",
       "57           loc_ic_t2m_mou_6    0.357822\n",
       "22           loc_og_t2f_mou_7    0.354808\n",
       "136       avg_rech_amt_action    0.350970\n",
       "63               loc_ic_mou_6    0.350455\n",
       "17           loc_og_t2t_mou_8    0.347305\n",
       "7                offnet_mou_7    0.346188\n",
       "18           loc_og_t2m_mou_6    0.328752\n",
       "93           total_rech_amt_6    0.315973\n",
       "71           std_ic_t2m_mou_8    0.268784"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract feature importanceImp\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "imp_feature_model = XGBClassifier(random_state=80)\n",
    "imp_feature_model.fit(X_train_test, y_train_test)\n",
    "importance = imp_feature_model.feature_importances_\n",
    "# summarize feature importance\n",
    "feature_imp=pd.DataFrame({\"feature\":X_train_test.columns,\"importance\":importance/np.sum(importance)*100})\n",
    "feature_imp.sort_values(by='importance',ascending=False,inplace=True)\n",
    "feature_imp=feature_imp[feature_imp.importance>0]\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1ca786ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>total_ic_mou_8</td>\n",
       "      <td>21.589979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "      <td>7.093407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>date_of_last_rech_8</td>\n",
       "      <td>3.512749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>decrease_arpu_action</td>\n",
       "      <td>2.639903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>decrease_mou_action</td>\n",
       "      <td>2.444579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>total_rech_num_7</td>\n",
       "      <td>2.263006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "      <td>2.233981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>total_rech_num_8</td>\n",
       "      <td>2.081431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>total_rech_num_6</td>\n",
       "      <td>1.942904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>decrease_rech_num_action</td>\n",
       "      <td>1.807736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature  importance\n",
       "80             total_ic_mou_8   21.589979\n",
       "65               loc_ic_mou_8    7.093407\n",
       "101       date_of_last_rech_8    3.512749\n",
       "135      decrease_arpu_action    2.639903\n",
       "141       decrease_mou_action    2.444579\n",
       "91           total_rech_num_7    2.263006\n",
       "104        last_day_rch_amt_8    2.233981\n",
       "92           total_rech_num_8    2.081431\n",
       "90           total_rech_num_6    1.942904\n",
       "146  decrease_rech_num_action    1.807736"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the datails on most 20 important feature\n",
    "feature_imp_10=feature_imp.head(10)\n",
    "print(feature_imp_10.shape)\n",
    "feature_imp_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24064e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e15c51c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x2000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i in range(1,11):\n",
    "    plt.subplot(5,4,i)\n",
    "    sns.distplot(data[data['churn_probability']==1][feature_imp_10.feature.values[i-1]],label='Churn')\n",
    "    sns.distplot(data[data['churn_probability']==0][feature_imp_10.feature.values[i-1]],label='No Churn')\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492737e2",
   "metadata": {},
   "source": [
    "### 9. Conclusions:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e319170",
   "metadata": {},
   "source": [
    "1. If total_ic_mou_8 i.e total incoming calls of cutomer in the month august is less higlhy likely to churn. From fr 1st graph from above we can intepret.If not doing any local calls in the action month he is more likely to churn\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecf417d5",
   "metadata": {},
   "source": [
    "2. If he is not doing any outgoing calls he is most likey to churn.We can see  from the above graph.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7613fcdc",
   "metadata": {},
   "source": [
    "3. if total number of recharge is less in july month, customer is high likey to churn.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8cc825dc",
   "metadata": {},
   "source": [
    "4. if customer is doing less amount of recharge, during the action month , is most likely to churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb076f8",
   "metadata": {},
   "source": [
    "#### Recomendatations:\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3e37080",
   "metadata": {},
   "source": [
    "1. Aim for customer who are not making any local calls and having less recharge activity, becuse these customers are most likey to chrun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b917e14a",
   "metadata": {},
   "source": [
    "2. Aim for the customer doing less times of recharge and less amount of recharge during the action phase, as they are most likey to churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86cceaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 57.533667,
   "end_time": "2021-08-13T07:17:27.204430",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-13T07:16:29.670763",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
